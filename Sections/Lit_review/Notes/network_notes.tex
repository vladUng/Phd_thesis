\section{Notes - literature review}

There are two main goals here:
\begin{itemize}
    \item Introduce the reader to some of the concepts used in the project. The information that will come here will depend on the examiners and their background, but it is very likely that there are going to be two streams:
    \begin{itemize}
        \item Genetics: gene expression, mutations, transcription factors, pathways etc
        \item Computational methods: clustering, dimension reduction (PCA, non-matrix factorisation etc), graphs etc 
    \end{itemize}
    \item Present the previous work done in the field(s):
    \begin{itemize}
        \item Stratification using RNAseq/Mutations
        \item Integrative approaches such as iCluster
        \item Network approaches in molecular biology  
    \end{itemize}
\end{itemize}

This section will be a combination of:
\begin{itemize}
    \item Literature Review -- which is covering the stratification based on RNAseq or Mutations and some work done on multi-omics
    \item Notes on the network approaches and multi-omics
\end{itemize}


\subsection{Data Integration notes}

\subsubsection{Overview}

There are multiple studies \citet{Menyhart2021-ef, Subramanian2020-tk, Picard2021-qr, Reel2021-sg} which are reviewing the work done in integrating multiple data types in the -omics realm. A particular good work is of \citet{Menyhart2021-ef} which classifies the different approaches undertaken in the field for disease stratification:
\begin{itemize}
    \item Multivariate methods for data integration
        \begin{itemize}
            \item Non-matrix factorisation (NMF) - my understanding of this is that it's a dimension reduction technique which preserves the non-linear aspect of the data better than PCA. Also, it's been used in conjunction with Bayesian approaches by \citet{Robertson2017-mg}
            \item Joint and Individual Variation Explained (JIVE) - similar to PCA
            \item MoCluster \cite{Meng2016-ui} - not sure about this one
        \end{itemize}
    \item Statistical methods for data integration
        \begin{itemize}
            \item iCluster family \citet{Shen2009-ew, Mo2013-zi, Mo2018-el}
            \item A probabilitisc graphical model - PARADIGM. \textbf{This may needs further exploration as it may be closer to what we want}
            \item Usupervised Bayesian Consensus Clustering (BCG). This is based on \textit{Dirichlet mixture model}
        \end{itemize}
    \item Network-based integration
        \begin{itemize}
            \item iOmicsPASS - supervised approach
        \end{itemize}
    \item Fusion-based integration
        \begin{itemize}
            \item Pattern Fusion Analysis (PFA) - comparable with iCluster, maybe worth exploring
        \end{itemize}
    \item Similarity-based integration
        \begin{itemize}
            \item Similarity network fusion - networks are created per omics which are then combined for clustering.
        \end{itemize}
    \item Correlation-based integration
        \begin{itemize}
            \item Using Canonical correrlation analysis (CCA) to assess correlation across different data types.
        \end{itemize}
\end{itemize}

A nice overview of all the models reviewed by \citet{Menyhart2021-ef} is provided in the paper and gives an appreciation of the methods applied and to which cancer types. Arguably \citet{Subramanian2020-tk} also provides a table with the methods used in subtyping but it feels less comprehensive. Nevertheless, the approaches used so far can be summarised to the following:
\begin{itemize}
    \item Matrix factorisation
    \item Bayesian
    \item network based / similarity 
    \item others (fusion, correlation, PCA, multi-step)
\end{itemize}

\subsubsection{A sequential approach}

In this class of algorithms the approach of the problem is almost sequential in the sense of:

\begin{itemize}
    \item Authors pre-process the data in numerous ways depending on the next step, but usually it involves normalisation and filtering out the genes that are not biologically significant (this is done by some arbitrary rules)
    
    \item Represent the data in a latent space, like this only the relevant features are kept. 
    \begin{itemize}
        \item The construction of the latent space can be done separately for each dataset type as well as combined for all (e.g. iCluster family)
        \item \textbf{Note:} I don't understand the biology good enough but it seams that there usually might me mean that some of the data might be missed. For instance, when a gene is filtered out it needs to be relative to the sample
    \end{itemize}
    
    \item After this apply a clustering technique to find the subgroups
\end{itemize}

For finding the latent space there are several approaches used:

\begin{itemize}
    \item PCA
    \item Bayesian approaches, like Bayesian NMF from the consensus 
    \item iCluster approach where they have used another Bayesian method to find the posterior probability describing the data
    \item Autoencoders
    
\end{itemize}

\newpage


\subsection{Network previous work}

So far in my literature review of the graphs/network approaches to biological networks, I found out that the processing steps are common across the solutions propsosed. Overall, the workflow is:
\begin{itemize}
    \item Reducing the data - This comes in different shapes and forms but all have the same goal, create a smaller adjacent matrix from which a network can then be created.
    \begin{itemize}
        \item In PCGNA - the median of the spearman correlation is used to reduce all the correlation across the datasets.
        \item In WCGNA - another correlation
        \item The Graph NN - embedding space
        \item The encoder - another embedding space
    \end{itemize}
    \item Do some pruning on the the edges
    \item The most aggressive being PGCNA 
    \item Apply some clustering to find the communities or the genes correlated 
\end{itemize}



\subsubsection{Network Metrics}

\paragraph{Integrate Value of Influence}

The central focus of the paper is to identify the most influential nodes in the network. This can mean the nodes that play an important role, have lots of connections w/ the other nodes. 

The paper is relevant to my work for several reasons:
\begin{itemize}
    \item it offers a good review of the metrics used to identify the most influential nodes
    \item  It justifies how the integration is done, but thought the explanation of addition/multiplication was a bit too much and unnecessary
\end{itemize}

--- 
Some ways to look at the influence of a node: 

\begin{itemize}
    \item They talk a lot about \textbf{centrality} as a way to measure influence.
    \item Mention of \textbf{betweenness} = "defined as the tendency of a node to be on the shortest path between nodes in a graph".
    \item \textbf{Collective influence} =  "is a novel global centrality metric that measures the collective number of nodes that can be reached from a given node" 
    \item\textbf{ Neighbourhood connectivity} = "is a semi-local centrality measure of a network that deals with the connectivity (number of neighbours) of nodes. "

\end{itemize}

Their novel part or what are the limitations that they are addressing through the Integrated Value of Influence (IVI):

\begin{enumerate}
    \item degree centrality 
    \item ClusterRank
    \item Neighbourhood connectivity - This is used to overcome the issue of positional bias of betweenness centrality
    \item local H index
    \item Betweenness centrality  
    \item Collective influence 
\end{enumerate}


They say that each of the metrics captures a different topological dim of the graph, including local, semi-local and global topology. Another advantage of their work is that: \textit{None of them requires a fully connected graph or module to be calculated}.


% \import{Sections/Network_I/}{miscellaneous.tex}

\newpage


 


