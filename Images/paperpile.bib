% Generated by Paperpile. Check out https://paperpile.com for more information.
% BibTeX export options can be customized via Settings -> BibTeX.

@ARTICLE{Lindskrog2021-ov,
  title     = "An integrated multi-omics analysis identifies prognostic
               molecular subtypes of non-muscle-invasive bladder cancer",
  author    = "Lindskrog, Sia Viborg and Prip, Frederik and Lamy, Philippe and
               Taber, Ann and Groeneveld, Clarice S and
               Birkenkamp-Demtr{\"o}der, Karin and Jensen, J{\o}rgen Bjerggaard
               and Strandgaard, Trine and Nordentoft, Iver and Christensen,
               Emil and Sokac, Mateo and Birkbak, Nicolai J and Maretty, Lasse
               and Hermann, Gregers G and Petersen, Astrid C and Weyerer,
               Veronika and Grimm, Marc-Oliver and Horstmann, Marcus and
               Sj{\"o}dahl, Gottfrid and H{\"o}glund, Mattias and Steiniche,
               Torben and Mogensen, Karin and de Reyni{\`e}s, Aur{\'e}lien and
               Nawroth, Roman and Jordan, Brian and Lin, Xiaoqi and Dragicevic,
               Dejan and Ward, Douglas G and Goel, Anshita and Hurst, Carolyn D
               and Raman, Jay D and Warrick, Joshua I and Segersten, Ulrika and
               Sikic, Danijel and van Kessel, Kim E M and Maurer, Tobias and
               Meeks, Joshua J and DeGraff, David J and Bryan, Richard T and
               Knowles, Margaret A and Simic, Tatjana and Hartmann, Arndt and
               Zwarthoff, Ellen C and Malmstr{\"o}m, Per-Uno and Malats,
               N{\'u}ria and Real, Francisco X and Dyrskj{\o}t, Lars",
  abstract  = "The molecular landscape in non-muscle-invasive bladder cancer
               (NMIBC) is characterized by large biological heterogeneity with
               variable clinical outcomes. Here, we perform an integrative
               multi-omics analysis of patients diagnosed with NMIBC (n = 834).
               Transcriptomic analysis identifies four classes (1, 2a, 2b and
               3) reflecting tumor biology and disease aggressiveness. Both
               transcriptome-based subtyping and the level of chromosomal
               instability provide independent prognostic value beyond
               established prognostic clinicopathological parameters. High
               chromosomal instability, p53-pathway disruption and
               APOBEC-related mutations are significantly associated with
               transcriptomic class 2a and poor outcome. RNA-derived immune
               cell infiltration is associated with chromosomally unstable
               tumors and enriched in class 2b. Spatial proteomics analysis
               confirms the higher infiltration of class 2b tumors and
               demonstrates an association between higher immune cell
               infiltration and lower recurrence rates. Finally, the
               independent prognostic value of the transcriptomic classes is
               documented in 1228 validation samples using a single sample
               classification tool. The classifier provides a framework for
               biomarker discovery and for optimizing treatment and
               surveillance in next-generation clinical trials.",
  journal   = "Nat. Commun.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  12,
  number    =  1,
  pages     = "2301",
  month     =  "16~" # apr,
  year      =  2021,
  copyright = "https://creativecommons.org/licenses/by/4.0",
  language  = "en",
  issn      = "2041-1723",
  pmid      = "33863885",
  doi       = "10.1038/s41467-021-22465-w",
  pmc       = "PMC8052448"
}

@MISC{The_European_Genome-phenome_Archive_undated-pz,
  title        = "{UROMOL} 2020 - {RNA-seq} data - {EGA} European
                  {Genome-Phenome} Archive",
  author       = "{The European Genome-phenome Archive}",
  howpublished = "\url{https://ega-archive.org/studies/EGAS00001004693}",
  note         = "Accessed: 2021-7-19"
}

@MISC{Scikit-learn_undated-ax,
  title        = "2.3. Clustering --- scikit-learn 0.24.2 documentation",
  author       = "{Scikit-learn}",
  howpublished = "\url{https://scikit-learn.org/stable/modules/clustering.html}",
  note         = "Accessed: 2021-7-16"
}

@ARTICLE{Barnett2021-kk,
  title         = "Dynamical independence: discovering emergent macroscopic
                   processes in complex dynamical systems",
  author        = "Barnett, Lionel and Seth, Anil K",
  abstract      = "We introduce a notion of emergence for coarse-grained
                   macroscopic variables associated with highly-multivariate
                   microscopic dynamical processes, in the context of a coupled
                   dynamical environment. Dynamical independence instantiates
                   the intuition of an emergent macroscopic process as one
                   possessing the characteristics of a dynamical system ``in
                   its own right'', with its own dynamical laws distinct from
                   those of the underlying microscopic dynamics. We quantify
                   (departure from) dynamical independence by a
                   transformation-invariant Shannon information-based measure
                   of dynamical dependence. We emphasise the data-driven
                   discovery of dynamically-independent macroscopic variables,
                   and introduce the idea of a multiscale ``emergence
                   portrait'' for complex systems. We show how dynamical
                   dependence may be computed explicitly for linear systems via
                   state-space modelling, in both time and frequency domains,
                   facilitating discovery of emergent phenomena at all
                   spatiotemporal scales. We discuss application of the
                   state-space operationalisation to inference of the emergence
                   portrait for neural systems from neurophysiological
                   time-series data. We also examine dynamical independence for
                   discrete- and continuous-time deterministic dynamics, with
                   potential application to Hamiltonian mechanics and classical
                   complex systems such as flocking and cellular automata.",
  month         =  "11~" # jun,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2106.06511",
  primaryClass  = "nlin.AO",
  arxivid       = "2106.06511"
}

@ARTICLE{Shadmehr2020-rd,
  title    = "Population coding in the cerebellum: a machine learning
              perspective",
  author   = "Shadmehr, Reza",
  abstract = "The cere resembles a feedforward, three-layer network of neurons
              in which the ``hidden layer'' consists of Purkinje cells
              (P-cells) and the output layer consists of deep cerebellar
              nucleus (DCN) neurons. In this analogy, the output of each DCN
              neuron is a prediction that is compared with the actual
              observation, resulting in an error signal that originates in the
              inferior olive. Efficient learning requires that the error signal
              reach the DCN neurons, as well as the P-cells that project onto
              them. However, this basic rule of learning is violated in the
              cerebellum: the olivary projections to the DCN are weak,
              particularly in adulthood. Instead, an extraordinarily strong
              signal is sent from the olive to the P-cells, producing complex
              spikes. Curiously, P-cells are grouped into small populations
              that converge onto single DCN neurons. Why are the P-cells
              organized in this way, and what is the membership criterion of
              each population? Here, I apply elementary mathematics from
              machine learning and consider the fact that P-cells that form a
              population exhibit a special property: they can synchronize their
              complex spikes, which in turn suppress activity of DCN neuron
              they project to. Thus complex spikes cannot only act as a
              teaching signal for a P-cell, but through complex spike
              synchrony, a P-cell population may act as a surrogate teacher for
              the DCN neuron that produced the erroneous output. It appears
              that grouping of P-cells into small populations that share a
              preference for error satisfies a critical requirement of
              efficient learning: providing error information to the output
              layer neuron (DCN) that was responsible for the error, as well as
              the hidden layer neurons (P-cells) that contributed to it. This
              population coding may account for several remarkable features of
              behavior during learning, including multiple timescales,
              protection from erasure, and spontaneous recovery of memory.",
  journal  = "J. Neurophysiol.",
  volume   =  124,
  number   =  6,
  pages    = "2022--2051",
  month    =  "1~" # dec,
  year     =  2020,
  keywords = "eyeblink conditioning; motor learning; neural encoding; saccades;
              smooth pursuit",
  language = "en",
  issn     = "0022-3077, 1522-1598",
  pmid     = "33112717",
  doi      = "10.1152/jn.00449.2020",
  pmc      = "PMC7814897"
}

@ARTICLE{Version_undated-dh,
  title  = "King's Research Portal",
  author = "Version, Document Version Peer",
  doi    = "10.1177/2F1745691621990638"
}

@ARTICLE{Bode2021-om,
  title    = "Exploiting {Single-Cell} Tools in Gene and Cell Therapy",
  author   = "Bode, Daniel and Cull, Alyssa H and Rubio-Lara, Juan A and Kent,
              David G",
  abstract = "Single-cell molecular tools have been developed at an incredible
              pace over the last five years as sequencing costs continue to
              drop and numerous molecular assays have been coupled to
              sequencing readouts. This rapid period of technological
              development has facilitated the delineation of individual
              molecular characteristics including the genome, transcriptome,
              epigenome, and proteome of individual cells, leading to an
              unprecedented resolution of the molecular networks governing
              complex biological systems. The immense power of single-cell
              molecular screens has been particularly highlighted through work
              in systems where cellular heterogeneity is a key feature, such as
              stem cell biology, immunology, and tumor cell biology.
              Single-cell-omics technologies have already contributed to the
              identification of novel disease biomarkers, cellular subsets,
              therapeutic targets and diagnostics, many of which would have
              been undetectable by bulk sequencing approaches. More recently,
              efforts to integrate single-cell multi-omics with single cell
              functional output and/or physical location have been challenging
              but have led to substantial advances. Perhaps most excitingly,
              there are emerging opportunities to reach beyond the description
              of static cellular states with recent advances in modulation of
              cells through CRISPR technology, in particular with the
              development of base editors which greatly raises the prospect of
              cell and gene therapies. In this review, we provide a brief
              overview of emerging single-cell technologies and discuss current
              developments in integrating single-cell molecular screens and
              performing single-cell multi-omics for clinical applications. We
              also discuss how single-cell molecular assays can be usefully
              combined with functional data to unpick the mechanism of cellular
              decision-making. Finally, we reflect upon the introduction of
              spatial transcriptomics and proteomics, its complementary role
              with single-cell RNA sequencing (scRNA-seq) and potential
              application in cellular and gene therapy.",
  journal  = "Front. Immunol.",
  volume   =  12,
  pages    = "2775",
  year     =  2021,
  issn     = "1664-3224",
  doi      = "10.3389/fimmu.2021.702636"
}

@PHDTHESIS{Vlad2020-cg,
  title    = "Literature review",
  author   = "Vlad, Ungureanu and Smith, S and Halliday, D and Mason, A",
  year     =  2020,
  keywords = "Misc"
}

@MISC{Cancer_Research_UK2015-cf,
  title        = "Bladder cancer statistics",
  author       = "{Cancer Research UK}",
  abstract     = "The latest bladder cancer statistics for the UK for Health
                  Professionals. See data for incidence, mortality, survival,
                  risk and more.",
  month        =  "14~" # may,
  year         =  2015,
  howpublished = "\url{https://www.cancerresearchuk.org/health-professional/cancer-statistics/statistics-by-cancer-type/bladder-cancer}",
  note         = "Accessed: 2021-7-13"
}

@ARTICLE{Roser2015-qb,
  title    = "Cancer",
  author   = "Roser, Max and Ritchie, Hannah",
  abstract = "Cancers are one of the leading causes of death globally. Are we
              making progress against cancer?",
  journal  = "Our World in Data",
  month    =  "3~" # jul,
  year     =  2015
}

@MISC{World_in_Data_undated-no,
  title        = "Life expectancy",
  author       = "{World in Data}",
  abstract     = "An interactive visualization from Our World in Data.",
  howpublished = "\url{https://ourworldindata.org/grapher/life-expectancy?time=1845..2015}",
  note         = "Accessed: 2021-7-12"
}

@MISC{World_in_Data_undated-gc,
  title        = "Is the world making progress against cancer?",
  author       = "{World in Data}",
  abstract     = "Adjusted for both population growth and aging, mortality from
                  cancer is falling globally.",
  howpublished = "\url{https://ourworldindata.org/progress-against-cancer}",
  note         = "Accessed: 2021-7-12"
}

@ARTICLE{Clough2016-zc,
  title    = "The Gene Expression Omnibus Database",
  author   = "Clough, Emily and Barrett, Tanya",
  abstract = "The Gene Expression Omnibus (GEO) database is an international
              public repository that archives and freely distributes
              high-throughput gene expression and other functional genomics
              data sets. Created in 2000 as a worldwide resource for gene
              expression studies, GEO has evolved with rapidly changing
              technologies and now accepts high-throughput data for many other
              data applications, including those that examine genome
              methylation, chromatin structure, and genome-protein
              interactions. GEO supports community-derived reporting standards
              that specify provision of several critical study elements
              including raw data, processed data, and descriptive metadata. The
              database not only provides access to data for tens of thousands
              of studies, but also offers various Web-based tools and
              strategies that enable users to locate data relevant to their
              specific interests, as well as to visualize and analyze the data.
              This chapter includes detailed descriptions of methods to query
              and download GEO data and use the analysis and visualization
              tools. The GEO homepage is at http://www.ncbi.nlm.nih.gov/geo/.",
  journal  = "Methods Mol. Biol.",
  volume   =  1418,
  pages    = "93--110",
  year     =  2016,
  keywords = "Data mining; Database; Functional genomics; Gene expression;
              High-throughput sequencing; Microarray",
  language = "en",
  issn     = "1064-3745, 1940-6029",
  pmid     = "27008011",
  doi      = "10.1007/978-1-4939-3578-9\_5",
  pmc      = "PMC4944384"
}

@ARTICLE{Barrett2005-ep,
  title    = "{NCBI} {GEO}: mining millions of expression profiles--database
              and tools",
  author   = "Barrett, Tanya and Suzek, Tugba O and Troup, Dennis B and
              Wilhite, Stephen E and Ngau, Wing-Chi and Ledoux, Pierre and
              Rudnev, Dmitry and Lash, Alex E and Fujibuchi, Wataru and Edgar,
              Ron",
  abstract = "The Gene Expression Omnibus (GEO) at the National Center for
              Biotechnology Information (NCBI) is the largest fully public
              repository for high-throughput molecular abundance data,
              primarily gene expression data. The database has a flexible and
              open design that allows the submission, storage and retrieval of
              many data types. These data include microarray-based experiments
              measuring the abundance of mRNA, genomic DNA and protein
              molecules, as well as non-array-based technologies such as serial
              analysis of gene expression (SAGE) and mass spectrometry
              proteomic technology. GEO currently holds over 30,000 submissions
              representing approximately half a billion individual molecular
              abundance measurements, for over 100 organisms. Here, we describe
              recent database developments that facilitate effective mining and
              visualization of these data. Features are provided to examine
              data from both experiment- and gene-centric perspectives using
              user-friendly Web-based interfaces accessible to those without
              computational or microarray-related analytical expertise. The GEO
              database is publicly accessible through the World Wide Web at
              http://www.ncbi.nlm.nih.gov/geo.",
  journal  = "Nucleic Acids Res.",
  volume   =  33,
  number   = "Database issue",
  pages    = "D562--6",
  month    =  "1~" # jan,
  year     =  2005,
  language = "en",
  issn     = "0305-1048, 1362-4962",
  pmid     = "15608262",
  doi      = "10.1093/nar/gki022",
  pmc      = "PMC539976"
}

@ARTICLE{Hanahan2011-px,
  title    = "Hallmarks of cancer: the next generation",
  author   = "Hanahan, Douglas and Weinberg, Robert A",
  abstract = "The hallmarks of cancer comprise six biological capabilities
              acquired during the multistep development of human tumors. The
              hallmarks constitute an organizing principle for rationalizing
              the complexities of neoplastic disease. They include sustaining
              proliferative signaling, evading growth suppressors, resisting
              cell death, enabling replicative immortality, inducing
              angiogenesis, and activating invasion and metastasis. Underlying
              these hallmarks are genome instability, which generates the
              genetic diversity that expedites their acquisition, and
              inflammation, which fosters multiple hallmark functions.
              Conceptual progress in the last decade has added two emerging
              hallmarks of potential generality to this list-reprogramming of
              energy metabolism and evading immune destruction. In addition to
              cancer cells, tumors exhibit another dimension of complexity:
              they contain a repertoire of recruited, ostensibly normal cells
              that contribute to the acquisition of hallmark traits by creating
              the ``tumor microenvironment.'' Recognition of the widespread
              applicability of these concepts will increasingly affect the
              development of new means to treat human cancer.",
  journal  = "Cell",
  volume   =  144,
  number   =  5,
  pages    = "646--674",
  month    =  "4~" # mar,
  year     =  2011,
  language = "en",
  issn     = "0092-8674, 1097-4172",
  pmid     = "21376230",
  doi      = "10.1016/j.cell.2011.02.013"
}

@ARTICLE{Curtis2012-ff,
  title    = "The genomic and transcriptomic architecture of 2,000 breast
              tumours reveals novel subgroups",
  author   = "Curtis, Christina and Shah, Sohrab P and Chin, Suet-Feung and
              Turashvili, Gulisa and Rueda, Oscar M and Dunning, Mark J and
              Speed, Doug and Lynch, Andy G and Samarajiwa, Shamith and Yuan,
              Yinyin and Gr{\"a}f, Stefan and Ha, Gavin and Haffari, Gholamreza
              and Bashashati, Ali and Russell, Roslin and McKinney, Steven and
              {METABRIC Group} and Langer{\o}d, Anita and Green, Andrew and
              Provenzano, Elena and Wishart, Gordon and Pinder, Sarah and
              Watson, Peter and Markowetz, Florian and Murphy, Leigh and Ellis,
              Ian and Purushotham, Arnie and B{\o}rresen-Dale, Anne-Lise and
              Brenton, James D and Tavar{\'e}, Simon and Caldas, Carlos and
              Aparicio, Samuel",
  abstract = "The elucidation of breast cancer subgroups and their molecular
              drivers requires integrated views of the genome and transcriptome
              from representative numbers of patients. We present an integrated
              analysis of copy number and gene expression in a discovery and
              validation set of 997 and 995 primary breast tumours,
              respectively, with long-term clinical follow-up. Inherited
              variants (copy number variants and single nucleotide
              polymorphisms) and acquired somatic copy number aberrations
              (CNAs) were associated with expression in ~40\% of genes, with
              the landscape dominated by cis- and trans-acting CNAs. By
              delineating expression outlier genes driven in cis by CNAs, we
              identified putative cancer genes, including deletions in PPP2R2A,
              MTAP and MAP2K4. Unsupervised analysis of paired DNA--RNA
              profiles revealed novel subgroups with distinct clinical
              outcomes, which reproduced in the validation cohort. These
              include a high-risk, oestrogen-receptor-positive 11q13/14
              cis-acting subgroup and a favourable prognosis subgroup devoid of
              CNAs. Trans-acting aberration hotspots were found to modulate
              subgroup-specific gene networks, including a TCR
              deletion-mediated adaptive immune response in the `CNA-devoid'
              subgroup and a basal-specific chromosome 5 deletion-associated
              mitotic network. Our results provide a novel molecular
              stratification of the breast cancer population, derived from the
              impact of somatic CNAs on the transcriptome.",
  journal  = "Nature",
  volume   =  486,
  number   =  7403,
  pages    = "346--352",
  month    =  "18~" # apr,
  year     =  2012,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "22522925",
  doi      = "10.1038/nature10983",
  pmc      = "PMC3440846"
}

@ARTICLE{Shah2012-om,
  title    = "The clonal and mutational evolution spectrum of primary
              triple-negative breast cancers",
  author   = "Shah, Sohrab P and Roth, Andrew and Goya, Rodrigo and Oloumi,
              Arusha and Ha, Gavin and Zhao, Yongjun and Turashvili, Gulisa and
              Ding, Jiarui and Tse, Kane and Haffari, Gholamreza and
              Bashashati, Ali and Prentice, Leah M and Khattra, Jaswinder and
              Burleigh, Angela and Yap, Damian and Bernard, Virginie and
              McPherson, Andrew and Shumansky, Karey and Crisan, Anamaria and
              Giuliany, Ryan and Heravi-Moussavi, Alireza and Rosner, Jamie and
              Lai, Daniel and Birol, Inanc and Varhol, Richard and Tam, Angela
              and Dhalla, Noreen and Zeng, Thomas and Ma, Kevin and Chan, Simon
              K and Griffith, Malachi and Moradian, Annie and Cheng, S-W Grace
              and Morin, Gregg B and Watson, Peter and Gelmon, Karen and Chia,
              Stephen and Chin, Suet-Feung and Curtis, Christina and Rueda,
              Oscar M and Pharoah, Paul D and Damaraju, Sambasivarao and
              Mackey, John and Hoon, Kelly and Harkins, Timothy and Tadigotla,
              Vasisht and Sigaroudinia, Mahvash and Gascard, Philippe and
              Tlsty, Thea and Costello, Joseph F and Meyer, Irmtraud M and
              Eaves, Connie J and Wasserman, Wyeth W and Jones, Steven and
              Huntsman, David and Hirst, Martin and Caldas, Carlos and Marra,
              Marco A and Aparicio, Samuel",
  abstract = "Primary triple-negative breast cancers (TNBCs), a tumour type
              defined by lack of oestrogen receptor, progesterone receptor and
              ERBB2 gene amplification, represent approximately 16\% of all
              breast cancers. Here we show in 104 TNBC cases that at the time
              of diagnosis these cancers exhibit a wide and continuous spectrum
              of genomic evolution, with some having only a handful of coding
              somatic aberrations in a few pathways, whereas others contain
              hundreds of coding somatic mutations. High-throughput RNA
              sequencing (RNA-seq) revealed that only approximately 36\% of
              mutations are expressed. Using deep re-sequencing measurements of
              allelic abundance for 2,414 somatic mutations, we determine for
              the first time-to our knowledge-in an epithelial tumour subtype,
              the relative abundance of clonal frequencies among cases
              representative of the population. We show that TNBCs vary widely
              in their clonal frequencies at the time of diagnosis, with the
              basal subtype of TNBC showing more variation than non-basal TNBC.
              Although p53 (also known as TP53), PIK3CA and PTEN somatic
              mutations seem to be clonally dominant compared to other genes,
              in some tumours their clonal frequencies are incompatible with
              founder status. Mutations in cytoskeletal, cell shape and
              motility proteins occurred at lower clonal frequencies,
              suggesting that they occurred later during tumour progression.
              Taken together, our results show that understanding the biology
              and therapeutic responses of patients with TNBC will require the
              determination of individual tumour clonal genotypes.",
  journal  = "Nature",
  volume   =  486,
  number   =  7403,
  pages    = "395--399",
  month    =  "4~" # apr,
  year     =  2012,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "22495314",
  doi      = "10.1038/nature10933",
  pmc      = "PMC3863681"
}

@ARTICLE{Davis2007-at,
  title    = "{GEOquery}: a bridge between the Gene Expression Omnibus ({GEO})
              and {BioConductor}",
  author   = "Davis, Sean and Meltzer, Paul S",
  abstract = "UNLABELLED: Microarray technology has become a standard molecular
              biology tool. Experimental data have been generated on a huge
              number of organisms, tissue types, treatment conditions and
              disease states. The Gene Expression Omnibus (Barrett et al.,
              2005), developed by the National Center for Bioinformatics (NCBI)
              at the National Institutes of Health is a repository of nearly
              140,000 gene expression experiments. The BioConductor project
              (Gentleman et al., 2004) is an open-source and open-development
              software project built in the R statistical programming
              environment (R Development core Team, 2005) for the analysis and
              comprehension of genomic data. The tools contained in the
              BioConductor project represent many state-of-the-art methods for
              the analysis of microarray and genomics data. We have developed a
              software tool that allows access to the wealth of information
              within GEO directly from BioConductor, eliminating many the
              formatting and parsing problems that have made such analyses
              labor-intensive in the past. The software, called GEOquery,
              effectively establishes a bridge between GEO and BioConductor.
              Easy access to GEO data from BioConductor will likely lead to new
              analyses of GEO data using novel and rigorous statistical and
              bioinformatic tools. Facilitating analyses and meta-analyses of
              microarray data will increase the efficiency with which
              biologically important conclusions can be drawn from published
              genomic data. AVAILABILITY: GEOquery is available as part of the
              BioConductor project.",
  journal  = "Bioinformatics",
  volume   =  23,
  number   =  14,
  pages    = "1846--1847",
  month    =  "15~" # jul,
  year     =  2007,
  language = "en",
  issn     = "1367-4803, 1367-4811",
  pmid     = "17496320",
  doi      = "10.1093/bioinformatics/btm254"
}

@ARTICLE{Thomas2007-yj,
  title    = "High-throughput oncogene mutation profiling in human cancer",
  author   = "Thomas, Roman K and Baker, Alissa C and Debiasi, Ralph M and
              Winckler, Wendy and Laframboise, Thomas and Lin, William M and
              Wang, Meng and Feng, Whei and Zander, Thomas and MacConaill,
              Laura and Lee, Jeffrey C and Nicoletti, Rick and Hatton, Charlie
              and Goyette, Mary and Girard, Luc and Majmudar, Kuntal and
              Ziaugra, Liuda and Wong, Kwok-Kin and Gabriel, Stacey and
              Beroukhim, Rameen and Peyton, Michael and Barretina, Jordi and
              Dutt, Amit and Emery, Caroline and Greulich, Heidi and Shah,
              Kinjal and Sasaki, Hidefumi and Gazdar, Adi and Minna, John and
              Armstrong, Scott A and Mellinghoff, Ingo K and Hodi, F Stephen
              and Dranoff, Glenn and Mischel, Paul S and Cloughesy, Tim F and
              Nelson, Stan F and Liau, Linda M and Mertz, Kirsten and Rubin,
              Mark A and Moch, Holger and Loda, Massimo and Catalona, William
              and Fletcher, Jonathan and Signoretti, Sabina and Kaye, Frederic
              and Anderson, Kenneth C and Demetri, George D and Dummer,
              Reinhard and Wagner, Stephan and Herlyn, Meenhard and Sellers,
              William R and Meyerson, Matthew and Garraway, Levi A",
  abstract = "Systematic efforts are underway to decipher the genetic changes
              associated with tumor initiation and progression. However,
              widespread clinical application of this information is hampered
              by an inability to identify critical genetic events across the
              spectrum of human tumors with adequate sensitivity and
              scalability. Here, we have adapted high-throughput genotyping to
              query 238 known oncogene mutations across 1,000 human tumor
              samples. This approach established robust mutation distributions
              spanning 17 cancer types. Of 17 oncogenes analyzed, we found 14
              to be mutated at least once, and 298 (30\%) samples carried at
              least one mutation. Moreover, we identified previously
              unrecognized oncogene mutations in several tumor types and
              observed an unexpectedly high number of co-occurring mutations.
              These results offer a new dimension in tumor genetics, where
              mutations involving multiple cancer genes may be interrogated
              simultaneously and in 'real time' to guide cancer classification
              and rational therapeutic intervention.",
  journal  = "Nat. Genet.",
  volume   =  39,
  number   =  3,
  pages    = "347--351",
  month    =  mar,
  year     =  2007,
  language = "en",
  issn     = "1061-4036",
  pmid     = "17293865",
  doi      = "10.1038/ng1975"
}

@ARTICLE{Kanehisa2017-wj,
  title    = "{KEGG}: new perspectives on genomes, pathways, diseases and drugs",
  author   = "Kanehisa, Minoru and Furumichi, Miho and Tanabe, Mao and Sato,
              Yoko and Morishima, Kanae",
  abstract = "KEGG (http://www.kegg.jp/ or http://www.genome.jp/kegg/) is an
              encyclopedia of genes and genomes. Assigning functional meanings
              to genes and genomes both at the molecular and higher levels is
              the primary objective of the KEGG database project.
              Molecular-level functions are stored in the KO (KEGG Orthology)
              database, where each KO is defined as a functional ortholog of
              genes and proteins. Higher-level functions are represented by
              networks of molecular interactions, reactions and relations in
              the forms of KEGG pathway maps, BRITE hierarchies and KEGG
              modules. In the past the KO database was developed for the
              purpose of defining nodes of molecular networks, but now the
              content has been expanded and the quality improved irrespective
              of whether or not the KOs appear in the three molecular network
              databases. The newly introduced addendum category of the GENES
              database is a collection of individual proteins whose functions
              are experimentally characterized and from which an increasing
              number of KOs are defined. Furthermore, the DISEASE and DRUG
              databases have been improved by systematic analysis of drug
              labels for better integration of diseases and drugs with the KEGG
              molecular networks. KEGG is moving towards becoming a
              comprehensive knowledge base for both functional interpretation
              and practical application of genomic information.",
  journal  = "Nucleic Acids Res.",
  volume   =  45,
  number   = "D1",
  pages    = "D353--D361",
  month    =  "4~" # jan,
  year     =  2017,
  language = "en",
  issn     = "0305-1048, 1362-4962",
  pmid     = "27899662",
  doi      = "10.1093/nar/gkw1092",
  pmc      = "PMC5210567"
}

@ARTICLE{Rebouissou2014-ep,
  title    = "{EGFR} as a potential therapeutic target for a subset of
              muscle-invasive bladder cancers presenting a basal-like phenotype",
  author   = "Rebouissou, Sandra and Bernard-Pierrot, Isabelle and de
              Reyni{\`e}s, Aur{\'e}lien and Lepage, May-Linda and Krucker,
              Cl{\'e}mentine and Chapeaublanc, Elodie and H{\'e}rault,
              Aur{\'e}lie and Kamoun, Aur{\'e}lie and Caillault, Aur{\'e}lie
              and Letouz{\'e}, Eric and Elarouci, Nabila and Neuzillet, Yann
              and Denoux, Yves and Molini{\'e}, Vincent and Vordos, Dimitri and
              Laplanche, Agn{\`e}s and Maill{\'e}, Pascale and Soyeux, Pascale
              and Ofualuka, Karina and Reyal, Fabien and Biton, Anne and
              Sibony, Mathilde and Paoletti, Xavier and Southgate, Jennifer and
              Benhamou, Simone and Lebret, Thierry and Allory, Yves and
              Radvanyi, Fran{\c c}ois",
  abstract = "Muscle-invasive bladder carcinoma (MIBC) constitutes a
              heterogeneous group of tumors with a poor outcome. Molecular
              stratification of MIBC may identify clinically relevant tumor
              subgroups and help to provide effective targeted therapies. From
              seven series of large-scale transcriptomic data (383 tumors), we
              identified an MIBC subgroup accounting for 23.5\% of MIBC,
              associated with shorter survival and displaying a basal-like
              phenotype, as shown by the expression of epithelial basal cell
              markers. Basal-like tumors presented an activation of the
              epidermal growth factor receptor (EGFR) pathway linked to
              frequent EGFR gains and activation of an EGFR autocrine loop. We
              used a 40-gene expression classifier derived from human tumors to
              identify human bladder cancer cell lines and a chemically induced
              mouse model of bladder cancer corresponding to human basal-like
              bladder cancer. We showed, in both models, that tumor cells were
              sensitive to anti-EGFR therapy. Our findings provide preclinical
              proof of concept that anti-EGFR therapy can be used to target a
              subset of particularly aggressive MIBC tumors expressing basal
              cell markers and provide diagnostic tools for identifying these
              tumors.",
  journal  = "Sci. Transl. Med.",
  volume   =  6,
  number   =  244,
  pages    = "244ra91",
  month    =  "9~" # jul,
  year     =  2014,
  language = "en",
  issn     = "1946-6234, 1946-6242",
  pmid     = "25009231",
  doi      = "10.1126/scitranslmed.3008970"
}

@ARTICLE{Marzouka2018-ge,
  title     = "A validation and extended description of the Lund taxonomy for
               urothelial carcinoma using the {TCGA} cohort",
  author    = "Marzouka, Nour-Al-Dain and Eriksson, Pontus and Rovira, Carlos
               and Liedberg, Fredrik and Sj{\"o}dahl, Gottfrid and H{\"o}glund,
               Mattias",
  abstract  = "Global gene expression analysis has been a major tool for
               urothelial carcinoma subtype discovery. This approach has
               revealed extensive complexity both in intrinsic features of the
               tumor cells and in the microenvironment. However, global gene
               expression cannot distinguish between gene expression signals
               originating from the tumor cells proper and from normal cells in
               the biopsy. Here, we use a large cohort of advanced urothelial
               carcinomas for which both gene expression data and extensive
               immunohistochemistry are available to create a supervised mRNA
               expression centroid classifier. This classifier identifies the
               major Lund taxonomy tumor cell phenotypes as defined by IHC. We
               apply this classifier to the independent TCGA dataset and show
               excellent associations between identified subtypes and genomic
               features. We validate a progressed version of Urothelial-like A
               (UroA-Prog) that shows FGFR3 mutations and CDKN2A deletions, and
               we show that the variant Urothelial-like C is almost devoid of
               FGFR3 mutations. We show that Genomically Unstable tumors are
               very distinct from Urothelial-like tumors at the genomic level,
               and that tumors classified as Basal/SCC-like all complied with
               the established definition for Basal/SCC-like tumors. We
               identify the Mesenchymal-like and Small-cell/Neuroendocrine-like
               subtypes, and demonstrate that patients with UroB and Sc/NE-like
               tumors show the worst overall survival.",
  journal   = "Sci. Rep.",
  publisher = "Nature Publishing Group",
  volume    =  8,
  number    =  1,
  pages     = "1--12",
  month     =  "27~" # feb,
  year      =  2018,
  keywords  = "consens;Consensus",
  language  = "en",
  issn      = "2045-2322, 2045-2322",
  doi       = "10.1038/s41598-018-22126-x"
}

@ARTICLE{Choi2014-ed,
  title    = "Identification of distinct basal and luminal subtypes of
              muscle-invasive bladder cancer with different sensitivities to
              frontline chemotherapy",
  author   = "Choi, Woonyoung and Porten, Sima and Kim, Seungchan and Willis,
              Daniel and Plimack, Elizabeth R and Hoffman-Censits, Jean and
              Roth, Beat and Cheng, Tiewei and Tran, Mai and Lee, I-Ling and
              Melquist, Jonathan and Bondaruk, Jolanta and Majewski, Tadeusz
              and Zhang, Shizhen and Pretzsch, Shanna and Baggerly, Keith and
              Siefker-Radtke, Arlene and Czerniak, Bogdan and Dinney, Colin P N
              and McConkey, David J",
  abstract = "Muscle-invasive bladder cancers (MIBCs) are biologically
              heterogeneous and have widely variable clinical outcomes and
              responses to conventional chemotherapy. We discovered three
              molecular subtypes of MIBC that resembled established molecular
              subtypes of breast cancer. Basal MIBCs shared biomarkers with
              basal breast cancers and were characterized by p63 activation,
              squamous differentiation, and more aggressive disease at
              presentation. Luminal MIBCs contained features of active
              PPAR$\gamma$ and estrogen receptor transcription and were
              enriched with activating FGFR3 mutations and potential FGFR
              inhibitor sensitivity. p53-like MIBCs were consistently resistant
              to neoadjuvant methotrexate, vinblastine, doxorubicin and
              cisplatin chemotherapy, and all chemoresistant tumors adopted a
              p53-like phenotype after therapy. Our observations have important
              implications for prognostication, the future clinical development
              of targeted agents, and disease management with conventional
              chemotherapy.",
  journal  = "Cancer Cell",
  volume   =  25,
  number   =  2,
  pages    = "152--165",
  month    =  "10~" # feb,
  year     =  2014,
  keywords = "consens;Consensus",
  language = "en",
  issn     = "1535-6108, 1878-3686",
  pmid     = "24525232",
  doi      = "10.1016/j.ccr.2014.01.009",
  pmc      = "PMC4011497"
}

@ARTICLE{Mo2018-rl,
  title    = "Prognostic Power of a Tumor Differentiation Gene Signature for
              Bladder Urothelial Carcinomas",
  author   = "Mo, Qianxing and Nikolos, Fotis and Chen, Fengju and Tramel, Zoe
              and Lee, Yu-Cheng and Hayashi, Kazukuni and Xiao, Jing and Shen,
              Jianjun and Chan, Keith Syson",
  abstract = "Background: Muscle-invasive bladder cancers (MIBCs) cause
              approximately 150 000 deaths per year worldwide. Survival for
              MIBC patients is heterogeneous, with no clinically validated
              molecular markers that predict clinical outcome. Non-MIBCs
              (NMIBCs) generally have favorable outcome; however, a portion
              progress to MIBC. Hence, development of a prognostic tool that
              can guide decision-making is crucial for improving clinical
              management of bladder urothelial carcinomas. Methods: Tumor grade
              is defined by pathologic evaluation of tumor cell
              differentiation, and it often associates with clinical outcome.
              The current study extrapolates this conventional wisdom and
              combines it with molecular profiling. We developed an 18-gene
              signature that molecularly defines urothelial cellular
              differentiation, thus classifying MIBCs and NMIBCs into two
              subgroups: basal and differentiated. We evaluated the prognostic
              capability of this ``tumor differentiation signature'' and three
              other existing gene signatures including the The Cancer Genome
              Atlas (TCGA; 2707 genes), MD Anderson Cancer Center (MDA; 2252
              genes/2697 probes), and University of North Carolina at Chapel
              Hill (UNC; 47 genes) using five gene expression data sets derived
              from MIBC and NMIBC patients. All statistical tests were
              two-sided. Results: The tumor differentiation signature
              demonstrated consistency and statistical robustness toward
              stratifying MIBC patients into different overall survival
              outcomes (TCGA cohort 1, P = .03; MDA discovery, P = .009; MDA
              validation, P = .01), while the other signatures were not as
              consistent. In addition, we analyzed the progression (Ta/T1
              progressing to $\geq$T2) probability of NMIBCs. NMIBC patients
              with a basal tumor differentiation signature associated with
              worse progression outcome (P = .008). Gene functional term
              enrichment and gene set enrichment analyses revealed that genes
              involved in the biologic process of immune response and
              inflammatory response are among the most elevated within basal
              bladder cancers, implicating them as candidates for immune
              checkpoint therapies. Conclusions: These results provide
              definitive evidence that a biology-prioritizing clustering
              methodology generates meaningful insights into patient
              stratification and reveals targetable molecular pathways to
              impact future therapeutic approach.",
  journal  = "J. Natl. Cancer Inst.",
  volume   =  110,
  number   =  5,
  pages    = "448--459",
  month    =  "1~" # may,
  year     =  2018,
  keywords = "consens;Consensus",
  language = "en",
  issn     = "0027-8874, 1460-2105",
  pmid     = "29342309",
  doi      = "10.1093/jnci/djx243",
  pmc      = "PMC6279371"
}

@MISC{Jordan2018-bc,
  title        = "Introduction to autoencoders",
  author       = "Jordan, Jeremy",
  abstract     = "Autoencoders are an unsupervised learning technique in which
                  we leverage neural networks for the task of representation
                  learning. Specifically, we'll design a neural network
                  architecture such that we impose a bottleneck in the network
                  which forces a compressed knowledge representation of the
                  original input. If the input features were each",
  publisher    = "Jeremy Jordan",
  month        =  "19~" # mar,
  year         =  2018,
  howpublished = "\url{https://www.jeremyjordan.me/autoencoders/}",
  note         = "Accessed: 2021-6-27"
}

@ARTICLE{Chen2018-db,
  title    = "{GSAE}: an autoencoder with embedded gene-set nodes for genomics
              functional characterization",
  author   = "Chen, Hung-I Harry and Chiu, Yu-Chiao and Zhang, Tinghe and
              Zhang, Songyao and Huang, Yufei and Chen, Yidong",
  abstract = "BACKGROUND: Bioinformatics tools have been developed to interpret
              gene expression data at the gene set level, and these gene set
              based analyses improve the biologists' capability to discover
              functional relevance of their experiment design. While
              elucidating gene set individually, inter-gene sets association is
              rarely taken into consideration. Deep learning, an emerging
              machine learning technique in computational biology, can be used
              to generate an unbiased combination of gene set, and to determine
              the biological relevance and analysis consistency of these
              combining gene sets by leveraging large genomic data sets.
              RESULTS: In this study, we proposed a gene superset autoencoder
              (GSAE), a multi-layer autoencoder model with the incorporation of
              a priori defined gene sets that retain the crucial biological
              features in the latent layer. We introduced the concept of the
              gene superset, an unbiased combination of gene sets with weights
              trained by the autoencoder, where each node in the latent layer
              is a superset. Trained with genomic data from TCGA and evaluated
              with their accompanying clinical parameters, we showed gene
              supersets' ability of discriminating tumor subtypes and their
              prognostic capability. We further demonstrated the biological
              relevance of the top component gene sets in the significant
              supersets. CONCLUSIONS: Using autoencoder model and gene superset
              at its latent layer, we demonstrated that gene supersets retain
              sufficient biological information with respect to tumor subtypes
              and clinical prognostic significance. Superset also provides high
              reproducibility on survival analysis and accurate prediction for
              cancer subtypes.",
  journal  = "BMC Syst. Biol.",
  volume   =  12,
  number   = "Suppl 8",
  pages    = "142",
  month    =  "21~" # dec,
  year     =  2018,
  keywords = "Autoencoder; Deep learning; Gene superset analysis; Survival
              analysis;autoencoders",
  language = "en",
  issn     = "1752-0509",
  pmid     = "30577835",
  doi      = "10.1186/s12918-018-0642-2",
  pmc      = "PMC6302374"
}

@INPROCEEDINGS{Wang2018-zg,
  title     = "Exploring {DNA} Methylation Data of Lung Cancer Samples with
               Variational Autoencoders",
  booktitle = "2018 {IEEE} International Conference on Bioinformatics and
               Biomedicine ({BIBM})",
  author    = "Wang, Zhenxing and Wang, Yadong",
  abstract  = "Lung cancer causes over one million deaths each year worldwide.
               DNA methylation is a well-defined epigenetics factor in genome
               data analyses for model training. In this article, we explore
               the applications of unsupervised deep learning method,
               variational autoencoders, using DNA methylation data of lung
               cancer samples downloaded from the GDC TCGA project and perform
               further work with latent features. We show the logistic
               regression classifier on the encoded latent features accurately
               classifies cancer subtypes.",
  pages     = "1286--1289",
  month     =  dec,
  year      =  2018,
  keywords  = "Cancer;DNA;Lung;Tumors;Bioinformatics;Heating systems;Deep
               learning;DNA methylation;lung cancer;variational
               autoencoder;autoencoders",
  doi       = "10.1109/BIBM.2018.8621365"
}

@ARTICLE{Guo2019-bf,
  title    = "Identification of cancer subtypes by integrating multiple types
              of transcriptomics data with deep learning in breast cancer",
  author   = "Guo, Yang and Shang, Xuequn and Li, Zhanhuai",
  abstract = "The identification of cancer subtypes is vital to advance the
              precision of cancer disease diagnosis and therapy. Several works
              had been done to integrate multiple types of genomics data to
              investigate cancer subtypes. However, (1) few of them
              particularly considered the intrinsic correlations in each type
              of data; (2) to the best of our knowledge, none of them
              considered transcriptome alternative splicing regulation in data
              integration. It has been demonstrated that many cancers are
              related to abnormal alternative splicing regulations in recent
              years. In this paper, we propose a hierarchical deep learning
              framework, HI-SAE, to integrate gene expression and transcriptome
              alternative splicing profiles data to identify cancer subtypes.
              We adopt the stacked autoencoder (SAE) neural network to learn
              high-level representations in each type of data, respectively,
              and then integrate all the learned high-level representations by
              another learning layer to learn more complex data
              representations. Based on the final learned data representations,
              we cluster patients into different cancer subtype groups.
              Comprehensive experiments based on TCGA breast cancer data
              demonstrate that our model provides an effective and useful
              approach to integrate multiple types of transcriptomics data to
              identify cancer subtypes and the transcriptome alternative
              splicing data offers distinguishable clues of cancer subtypes.",
  journal  = "Neurocomputing",
  volume   =  324,
  pages    = "20--30",
  month    =  "9~" # jan,
  year     =  2019,
  keywords = "Deep learning; Autoencoder; Gene expression; Alternative
              splicing; Cancer subtype;autoencoders",
  issn     = "0925-2312",
  doi      = "10.1016/j.neucom.2018.03.072"
}

@ARTICLE{International_Cancer_Genome_Consortium2010-ca,
  title    = "International network of cancer genome projects",
  author   = "{International Cancer Genome Consortium} and Hudson, Thomas J and
              Anderson, Warwick and Artez, Axel and Barker, Anna D and Bell,
              Cindy and Bernab{\'e}, Rosa R and Bhan, M K and Calvo, Fabien and
              Eerola, Iiro and Gerhard, Daniela S and Guttmacher, Alan and
              Guyer, Mark and Hemsley, Fiona M and Jennings, Jennifer L and
              Kerr, David and Klatt, Peter and Kolar, Patrik and Kusada, Jun
              and Lane, David P and Laplace, Frank and Youyong, Lu and
              Nettekoven, Gerd and Ozenberger, Brad and Peterson, Jane and Rao,
              T S and Remacle, Jacques and Schafer, Alan J and Shibata,
              Tatsuhiro and Stratton, Michael R and Vockley, Joseph G and
              Watanabe, Koichi and Yang, Huanming and Yuen, Matthew M F and
              Knoppers, Bartha M and Bobrow, Martin and Cambon-Thomsen, Anne
              and Dressler, Lynn G and Dyke, Stephanie O M and Joly, Yann and
              Kato, Kazuto and Kennedy, Karen L and Nicol{\'a}s, Pilar and
              Parker, Michael J and Rial-Sebbag, Emmanuelle and Romeo-Casabona,
              Carlos M and Shaw, Kenna M and Wallace, Susan and Wiesner,
              Georgia L and Zeps, Nikolajs and Lichter, Peter and Biankin,
              Andrew V and Chabannon, Christian and Chin, Lynda and
              Cl{\'e}ment, Bruno and de Alava, Enrique and Degos, Fran{\c
              c}oise and Ferguson, Martin L and Geary, Peter and Hayes, D Neil
              and Hudson, Thomas J and Johns, Amber L and Kasprzyk, Arek and
              Nakagawa, Hidewaki and Penny, Robert and Piris, Miguel A and
              Sarin, Rajiv and Scarpa, Aldo and Shibata, Tatsuhiro and van de
              Vijver, Marc and Futreal, P Andrew and Aburatani, Hiroyuki and
              Bay{\'e}s, M{\'o}nica and Botwell, David D L and Campbell, Peter
              J and Estivill, Xavier and Gerhard, Daniela S and Grimmond, Sean
              M and Gut, Ivo and Hirst, Martin and L{\'o}pez-Ot{\'\i}n, Carlos
              and Majumder, Partha and Marra, Marco and McPherson, John D and
              Nakagawa, Hidewaki and Ning, Zemin and Puente, Xose S and Ruan,
              Yijun and Shibata, Tatsuhiro and Stratton, Michael R and
              Stunnenberg, Hendrik G and Swerdlow, Harold and Velculescu,
              Victor E and Wilson, Richard K and Xue, Hong H and Yang, Liu and
              Spellman, Paul T and Bader, Gary D and Boutros, Paul C and
              Campbell, Peter J and Flicek, Paul and Getz, Gad and Guig{\'o},
              Roderic and Guo, Guangwu and Haussler, David and Heath, Simon and
              Hubbard, Tim J and Jiang, Tao and Jones, Steven M and Li, Qibin
              and L{\'o}pez-Bigas, Nuria and Luo, Ruibang and Muthuswamy,
              Lakshmi and Ouellette, B F Francis and Pearson, John V and
              Puente, Xose S and Quesada, Victor and Raphael, Benjamin J and
              Sander, Chris and Shibata, Tatsuhiro and Speed, Terence P and
              Stein, Lincoln D and Stuart, Joshua M and Teague, Jon W and
              Totoki, Yasushi and Tsunoda, Tatsuhiko and Valencia, Alfonso and
              Wheeler, David A and Wu, Honglong and Zhao, Shancen and Zhou,
              Guangyu and Stein, Lincoln D and Guig{\'o}, Roderic and Hubbard,
              Tim J and Joly, Yann and Jones, Steven M and Kasprzyk, Arek and
              Lathrop, Mark and L{\'o}pez-Bigas, Nuria and Ouellette, B F
              Francis and Spellman, Paul T and Teague, Jon W and Thomas, Gilles
              and Valencia, Alfonso and Yoshida, Teruhiko and Kennedy, Karen L
              and Axton, Myles and Dyke, Stephanie O M and Futreal, P Andrew
              and Gerhard, Daniela S and Gunter, Chris and Guyer, Mark and
              Hudson, Thomas J and McPherson, John D and Miller, Linda J and
              Ozenberger, Brad and Shaw, Kenna M and Kasprzyk, Arek and Stein,
              Lincoln D and Zhang, Junjun and Haider, Syed A and Wang, Jianxin
              and Yung, Christina K and Cros, Anthony and Liang, Yong and
              Gnaneshan, Saravanamuttu and Guberman, Jonathan and Hsu, Jack and
              Bobrow, Martin and Chalmers, Don R C and Hasel, Karl W and Joly,
              Yann and Kaan, Terry S H and Kennedy, Karen L and Knoppers,
              Bartha M and Lowrance, William W and Masui, Tohru and
              Nicol{\'a}s, Pilar and Rial-Sebbag, Emmanuelle and Rodriguez,
              Laura Lyman and Vergely, Catherine and Yoshida, Teruhiko and
              Grimmond, Sean M and Biankin, Andrew V and Bowtell, David D L and
              Cloonan, Nicole and deFazio, Anna and Eshleman, James R and
              Etemadmoghadam, Dariush and Gardiner, Brooke B and Kench, James G
              and Scarpa, Aldo and Sutherland, Robert L and Tempero, Margaret A
              and Waddell, Nicola J and Wilson, Peter J and McPherson, John D
              and Gallinger, Steve and Tsao, Ming-Sound and Shaw, Patricia A
              and Petersen, Gloria M and Mukhopadhyay, Debabrata and Chin,
              Lynda and DePinho, Ronald A and Thayer, Sarah and Muthuswamy,
              Lakshmi and Shazand, Kamran and Beck, Timothy and Sam, Michelle
              and Timms, Lee and Ballin, Vanessa and Lu, Youyong and Ji, Jiafu
              and Zhang, Xiuqing and Chen, Feng and Hu, Xueda and Zhou, Guangyu
              and Yang, Qi and Tian, Geng and Zhang, Lianhai and Xing, Xiaofang
              and Li, Xianghong and Zhu, Zhenggang and Yu, Yingyan and Yu, Jun
              and Yang, Huanming and Lathrop, Mark and Tost, J{\"o}rg and
              Brennan, Paul and Holcatova, Ivana and Zaridze, David and Brazma,
              Alvis and Egevard, Lars and Prokhortchouk, Egor and Banks,
              Rosamonde Elizabeth and Uhl{\'e}n, Mathias and Cambon-Thomsen,
              Anne and Viksna, Juris and Ponten, Fredrik and Skryabin,
              Konstantin and Stratton, Michael R and Futreal, P Andrew and
              Birney, Ewan and Borg, Ake and B{\o}rresen-Dale, Anne-Lise and
              Caldas, Carlos and Foekens, John A and Martin, Sancha and
              Reis-Filho, Jorge S and Richardson, Andrea L and Sotiriou,
              Christos and Stunnenberg, Hendrik G and Thoms, Giles and van de
              Vijver, Marc and van't Veer, Laura and Calvo, Fabien and
              Birnbaum, Daniel and Blanche, H{\'e}l{\`e}ne and Boucher, Pascal
              and Boyault, Sandrine and Chabannon, Christian and Gut, Ivo and
              Masson-Jacquemier, Jocelyne D and Lathrop, Mark and Pauport{\'e},
              Iris and Pivot, Xavier and Vincent-Salomon, Anne and Tabone, Eric
              and Theillet, Charles and Thomas, Gilles and Tost, J{\"o}rg and
              Treilleux, Isabelle and Calvo, Fabien and Bioulac-Sage, Paulette
              and Cl{\'e}ment, Bruno and Decaens, Thomas and Degos, Fran{\c
              c}oise and Franco, Dominique and Gut, Ivo and Gut, Marta and
              Heath, Simon and Lathrop, Mark and Samuel, Didier and Thomas,
              Gilles and Zucman-Rossi, Jessica and Lichter, Peter and Eils,
              Roland and Brors, Benedikt and Korbel, Jan O and Korshunov,
              Andrey and Landgraf, Pablo and Lehrach, Hans and Pfister, Stefan
              and Radlwimmer, Bernhard and Reifenberger, Guido and Taylor,
              Michael D and von Kalle, Christof and Majumder, Partha P and
              Sarin, Rajiv and Rao, T S and Bhan, M K and Scarpa, Aldo and
              Pederzoli, Paolo and Lawlor, Rita A and Delledonne, Massimo and
              Bardelli, Alberto and Biankin, Andrew V and Grimmond, Sean M and
              Gress, Thomas and Klimstra, David and Zamboni, Giuseppe and
              Shibata, Tatsuhiro and Nakamura, Yusuke and Nakagawa, Hidewaki
              and Kusada, Jun and Tsunoda, Tatsuhiko and Miyano, Satoru and
              Aburatani, Hiroyuki and Kato, Kazuto and Fujimoto, Akihiro and
              Yoshida, Teruhiko and Campo, Elias and L{\'o}pez-Ot{\'\i}n,
              Carlos and Estivill, Xavier and Guig{\'o}, Roderic and de
              Sanjos{\'e}, Silvia and Piris, Miguel A and Montserrat, Emili and
              Gonz{\'a}lez-D{\'\i}az, Marcos and Puente, Xose S and Jares,
              Pedro and Valencia, Alfonso and Himmelbauer, Heinz and Quesada,
              Victor and Bea, Silvia and Stratton, Michael R and Futreal, P
              Andrew and Campbell, Peter J and Vincent-Salomon, Anne and
              Richardson, Andrea L and Reis-Filho, Jorge S and van de Vijver,
              Marc and Thomas, Gilles and Masson-Jacquemier, Jocelyne D and
              Aparicio, Samuel and Borg, Ake and B{\o}rresen-Dale, Anne-Lise
              and Caldas, Carlos and Foekens, John A and Stunnenberg, Hendrik G
              and van't Veer, Laura and Easton, Douglas F and Spellman, Paul T
              and Martin, Sancha and Barker, Anna D and Chin, Lynda and
              Collins, Francis S and Compton, Carolyn C and Ferguson, Martin L
              and Gerhard, Daniela S and Getz, Gad and Gunter, Chris and
              Guttmacher, Alan and Guyer, Mark and Hayes, D Neil and Lander,
              Eric S and Ozenberger, Brad and Penny, Robert and Peterson, Jane
              and Sander, Chris and Shaw, Kenna M and Speed, Terence P and
              Spellman, Paul T and Vockley, Joseph G and Wheeler, David A and
              Wilson, Richard K and Hudson, Thomas J and Chin, Lynda and
              Knoppers, Bartha M and Lander, Eric S and Lichter, Peter and
              Stein, Lincoln D and Stratton, Michael R and Anderson, Warwick
              and Barker, Anna D and Bell, Cindy and Bobrow, Martin and Burke,
              Wylie and Collins, Francis S and Compton, Carolyn C and DePinho,
              Ronald A and Easton, Douglas F and Futreal, P Andrew and Gerhard,
              Daniela S and Green, Anthony R and Guyer, Mark and Hamilton,
              Stanley R and Hubbard, Tim J and Kallioniemi, Olli P and Kennedy,
              Karen L and Ley, Timothy J and Liu, Edison T and Lu, Youyong and
              Majumder, Partha and Marra, Marco and Ozenberger, Brad and
              Peterson, Jane and Schafer, Alan J and Spellman, Paul T and
              Stunnenberg, Hendrik G and Wainwright, Brandon J and Wilson,
              Richard K and Yang, Huanming",
  abstract = "The International Cancer Genome Consortium (ICGC) was launched to
              coordinate large-scale cancer genome studies in tumours from 50
              different cancer types and/or subtypes that are of clinical and
              societal importance across the globe. Systematic studies of more
              than 25,000 cancer genomes at the genomic, epigenomic and
              transcriptomic levels will reveal the repertoire of oncogenic
              mutations, uncover traces of the mutagenic influences, define
              clinically relevant subtypes for prognosis and therapeutic
              management, and enable the development of new cancer therapies.",
  journal  = "Nature",
  volume   =  464,
  number   =  7291,
  pages    = "993--998",
  month    =  "15~" # apr,
  year     =  2010,
  keywords = "autoencoders",
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "20393554",
  doi      = "10.1038/nature08987",
  pmc      = "PMC2902243"
}

@ARTICLE{Chaudhary2018-qj,
  title    = "Deep learning-based multi-omics integration robustly predicts
              survival in liver cancer",
  author   = "Chaudhary, Kumardeep and Poirion, Olivier B and Lu, Liangqun and
              Garmire, Lana X",
  abstract = "Identifying robust survival subgroups of hepatocellular carcinoma
              (HCC) will significantly improve patient care. Currently,
              endeavor of integrating multi-omics data to explicitly predict
              HCC survival from multiple patient cohorts is lacking. To fill
              this gap, we present a deep learning (DL)-based model on HCC that
              robustly differentiates survival subpopulations of patients in
              six cohorts. We built the DL-based, survival-sensitive model on
              360 HCC patients' data using RNA sequencing (RNA-Seq), miRNA
              sequencing (miRNA-Seq), and methylation data from The Cancer
              Genome Atlas (TCGA), which predicts prognosis as good as an
              alternative model where genomics and clinical data are both
              considered. This DL-based model provides two optimal subgroups of
              patients with significant survival differences (P = 7.13e-6) and
              good model fitness [concordance index (C-index) = 0.68]. More
              aggressive subtype is associated with frequent TP53 inactivation
              mutations, higher expression of stemness markers (KRT19 and
              EPCAM) and tumor marker BIRC5, and activated Wnt and Akt
              signaling pathways. We validated this multi-omics model on five
              external datasets of various omics types: LIRI-JP cohort (n =
              230, C-index = 0.75), NCI cohort (n = 221, C-index = 0.67),
              Chinese cohort (n = 166, C-index = 0.69), E-TABM-36 cohort (n =
              40, C-index = 0.77), and Hawaiian cohort (n = 27, C-index =
              0.82). This is the first study to employ DL to identify
              multi-omics features linked to the differential survival of
              patients with HCC. Given its robustness over multiple cohorts, we
              expect this workflow to be useful at predicting HCC prognosis
              prediction. Clin Cancer Res; 24(6); 1248-59. \copyright{}2017
              AACR.",
  journal  = "Clin. Cancer Res.",
  volume   =  24,
  number   =  6,
  pages    = "1248--1259",
  month    =  "15~" # mar,
  year     =  2018,
  keywords = "autoencoders",
  language = "en",
  issn     = "1078-0432, 1557-3265",
  pmid     = "28982688",
  doi      = "10.1158/1078-0432.CCR-17-0853",
  pmc      = "PMC6050171"
}

@INPROCEEDINGS{Zhang2019-xb,
  title     = "Integrated Multi-omics Analysis Using Variational Autoencoders:
               Application to Pan-cancer Classification",
  booktitle = "2019 {IEEE} International Conference on Bioinformatics and
               Biomedicine ({BIBM})",
  author    = "Zhang, Xiaoyu and Zhang, Jingqing and Sun, Kai and Yang, Xian
               and Dai, Chengliang and Guo, Yike",
  abstract  = "Omics data are normally high dimensional with large number of
               molecular features and relatively small number of available
               samples with clinical labels. The ``curse of dimensionality''
               makes it challenging to train a machine learning model using
               high dimensional omics data like DNA methylation and gene
               expression profiles. Here we propose an end-to-end deep learning
               model called OmiVAE to extract low dimensional features and
               classify samples from multi-omics data. OmiVAE combines the
               basic structure of variational autoencoders with a classifier to
               achieve task-oriented feature extraction and multi-class
               classification. The training procedure of OmiVAE is comprised of
               an unsupervised phase and a supervised phase. During the
               unsupervised phase, a hierarchical cluster structure of samples
               can be automatically formed without the need for labels. And in
               the supervised phase, OmiVAE achieved an average accuracy of
               97.49\% after 10-fold cross-validation among 33 tumour types and
               normal samples, which shows better performance than existing
               methods. The integrated model learned from multi-omics datasets
               outperformed those using only one type of omics data, which
               indicates that the complementary information from different
               omics datatypes provides useful insights for biomedical tasks
               like cancer classification.",
  pages     = "765--769",
  month     =  nov,
  year      =  2019,
  keywords  = "deep learning;variational autoencoders;multi-omics analysis;DNA
               methylation;gene expression;cancer;autoencoders;ML",
  doi       = "10.1109/BIBM47256.2019.8983228"
}

@ARTICLE{Geddes2019-sl,
  title    = "Autoencoder-based cluster ensembles for single-cell {RNA-seq}
              data analysis",
  author   = "Geddes, Thomas A and Kim, Taiyun and Nan, Lihao and Burchfield,
              James G and Yang, Jean Y H and Tao, Dacheng and Yang, Pengyi",
  abstract = "BACKGROUND: Single-cell RNA-sequencing (scRNA-seq) is a
              transformative technology, allowing global transcriptomes of
              individual cells to be profiled with high accuracy. An essential
              task in scRNA-seq data analysis is the identification of cell
              types from complex samples or tissues profiled in an experiment.
              To this end, clustering has become a key computational technique
              for grouping cells based on their transcriptome profiles,
              enabling subsequent cell type identification from each cluster of
              cells. Due to the high feature-dimensionality of the
              transcriptome (i.e. the large number of measured genes in each
              cell) and because only a small fraction of genes are cell
              type-specific and therefore informative for generating cell
              type-specific clusters, clustering directly on the original
              feature/gene dimension may lead to uninformative clusters and
              hinder correct cell type identification. RESULTS: Here, we
              propose an autoencoder-based cluster ensemble framework in which
              we first take random subspace projections from the data, then
              compress each random projection to a low-dimensional space using
              an autoencoder artificial neural network, and finally apply
              ensemble clustering across all encoded datasets to generate
              clusters of cells. We employ four evaluation metrics to benchmark
              clustering performance and our experiments demonstrate that the
              proposed autoencoder-based cluster ensemble can lead to
              substantially improved cell type-specific clusters when applied
              with both the standard k-means clustering algorithm and a
              state-of-the-art kernel-based clustering algorithm (SIMLR)
              designed specifically for scRNA-seq data. Compared to directly
              using these clustering algorithms on the original datasets, the
              performance improvement in some cases is up to 100\%, depending
              on the evaluation metric used. CONCLUSIONS: Our results suggest
              that the proposed framework can facilitate more accurate cell
              type identification as well as other downstream analyses. The
              code for creating the proposed autoencoder-based cluster ensemble
              framework is freely available from
              https://github.com/gedcom/scCCESS.",
  journal  = "BMC Bioinformatics",
  volume   =  20,
  number   = "Suppl 19",
  pages    = "660",
  month    =  "24~" # dec,
  year     =  2019,
  keywords = "Autoencoder; Cell type identification; Cluster ensemble; Single
              cells; Single-cell transcriptome; scRNA-seq;autoencoders;ML",
  language = "en",
  issn     = "1471-2105",
  pmid     = "31870278",
  doi      = "10.1186/s12859-019-3179-5",
  pmc      = "PMC6929272"
}

@ARTICLE{Meng2016-vu,
  title    = "Dimension reduction techniques for the integrative analysis of
              multi-omics data",
  author   = "Meng, Chen and Zeleznik, Oana A and Thallinger, Gerhard G and
              Kuster, Bernhard and Gholami, Amin M and Culhane, Aed{\'\i}n C",
  abstract = "State-of-the-art next-generation sequencing, transcriptomics,
              proteomics and other high-throughput 'omics' technologies enable
              the efficient generation of large experimental data sets. These
              data may yield unprecedented knowledge about molecular pathways
              in cells and their role in disease. Dimension reduction
              approaches have been widely used in exploratory analysis of
              single omics data sets. This review will focus on dimension
              reduction approaches for simultaneous exploratory analyses of
              multiple data sets. These methods extract the linear
              relationships that best explain the correlated structure across
              data sets, the variability both within and between variables (or
              observations) and may highlight data issues such as batch effects
              or outliers. We explore dimension reduction techniques as one of
              the emerging approaches for data integration, and how these can
              be applied to increase our understanding of biological systems in
              normal physiological function and disease.",
  journal  = "Brief. Bioinform.",
  volume   =  17,
  number   =  4,
  pages    = "628--641",
  month    =  jul,
  year     =  2016,
  keywords = "dimension reduction; exploratory data analysis; integrative
              genomics; multi-assay; multi-omics data integration; multivariate
              analysis",
  language = "en",
  issn     = "1467-5463, 1477-4054",
  pmid     = "26969681",
  doi      = "10.1093/bib/bbv108",
  pmc      = "PMC4945831"
}

@ARTICLE{Pierre-Jean2020-ys,
  title    = "Clustering and variable selection evaluation of 13 unsupervised
              methods for multi-omics data integration",
  author   = "Pierre-Jean, Morgane and Deleuze, Jean-Fran{\c c}ois and Le
              Floch, Edith and Mauger, Florence",
  abstract = "Recent advances in NGS sequencing, microarrays and mass
              spectrometry for omics data production have enabled the
              generation and collection of different modalities of
              high-dimensional molecular data. The integration of multiple
              omics datasets is a statistical challenge, due to the limited
              number of individuals, the high number of variables and the
              heterogeneity of the datasets to integrate. Recently, a lot of
              tools have been developed to solve the problem of integrating
              omics data including canonical correlation analysis, matrix
              factorization and SM. These commonly used techniques aim to
              analyze simultaneously two or more types of omics. In this
              article, we compare a panel of 13 unsupervised methods based on
              these different approaches to integrate various types of
              multi-omics datasets: iClusterPlus, regularized generalized
              canonical correlation analysis, sparse generalized canonical
              correlation analysis, multiple co-inertia analysis (MCIA),
              integrative-NMF (intNMF), SNF, MoCluster, mixKernel, CIMLR,
              LRAcluster, ConsensusClustering, PINSPlus and multi-omics factor
              analysis (MOFA). We evaluate the ability of the methods to
              recover the subgroups and the variables that drive the clustering
              on eight benchmarks of simulation. MOFA does not provide any
              results on these benchmarks. For clustering, SNF, MoCluster,
              CIMLR, LRAcluster, ConsensusClustering and intNMF provide the
              best results. For variable selection, MoCluster outperforms the
              others. However, the performance of the methods seems to depend
              on the heterogeneity of the datasets (especially for MCIA, intNMF
              and iClusterPlus). Finally, we apply the methods on three real
              studies with heterogeneous data and various phenotypes. We
              conclude that MoCluster is the best method to analyze these omics
              data. Availability: An R package named CrIMMix is available on
              GitHub at https://github.com/CNRGH/crimmix to reproduce all the
              results of this article.",
  journal  = "Brief. Bioinform.",
  volume   =  21,
  number   =  6,
  pages    = "2011--2030",
  month    =  "1~" # dec,
  year     =  2020,
  keywords = "benchmarks; multi-omics; performance evaluation; real data;
              unsupervised integrative methods",
  language = "en",
  issn     = "1467-5463, 1477-4054",
  pmid     = "31792509",
  doi      = "10.1093/bib/bbz138"
}

@ARTICLE{Ma2019-hk,
  title    = "Integrate multi-omics data with biological interaction networks
              using Multi-view Factorization {AutoEncoder} ({MAE})",
  author   = "Ma, Tianle and Zhang, Aidong",
  abstract = "BACKGROUND: Comprehensive molecular profiling of various cancers
              and other diseases has generated vast amounts of multi-omics
              data. Each type of -omics data corresponds to one feature space,
              such as gene expression, miRNA expression, DNA methylation, etc.
              Integrating multi-omics data can link different layers of
              molecular feature spaces and is crucial to elucidate molecular
              pathways underlying various diseases. Machine learning approaches
              to mining multi-omics data hold great promises in uncovering
              intricate relationships among molecular features. However, due to
              the ``big p, small n'' problem (i.e., small sample sizes with
              high-dimensional features), training a large-scale generalizable
              deep learning model with multi-omics data alone is very
              challenging. RESULTS: We developed a method called Multi-view
              Factorization AutoEncoder (MAE) with network constraints that can
              seamlessly integrate multi-omics data and domain knowledge such
              as molecular interaction networks. Our method learns feature and
              patient embeddings simultaneously with deep representation
              learning. Both feature representations and patient
              representations are subject to certain constraints specified as
              regularization terms in the training objective. By incorporating
              domain knowledge into the training objective, we implicitly
              introduced a good inductive bias into the machine learning model,
              which helps improve model generalizability. We performed
              extensive experiments on the TCGA datasets and demonstrated the
              power of integrating multi-omics data and biological interaction
              networks using our proposed method for predicting target clinical
              variables. CONCLUSIONS: To alleviate the overfitting problem in
              deep learning on multi-omics data with the ``big p, small n''
              problem, it is helpful to incorporate biological domain knowledge
              into the model as inductive biases. It is very promising to
              design machine learning models that facilitate the seamless
              integration of large-scale multi-omics data and biomedical domain
              knowledge for uncovering intricate relationships among molecular
              features and clinical features.",
  journal  = "BMC Genomics",
  volume   =  20,
  number   = "Suppl 11",
  pages    = "944",
  month    =  "20~" # dec,
  year     =  2019,
  keywords = "Autoencoder; Biological interaction networks; Data integration;
              Deep learning; Graph regularization; Multi-omics data; Multi-view
              learning;autoencoders",
  language = "en",
  issn     = "1471-2164",
  pmid     = "31856727",
  doi      = "10.1186/s12864-019-6285-x",
  pmc      = "PMC6923820"
}

@ARTICLE{Zhang2018-wd,
  title    = "Deep {Learning-Based} {Multi-Omics} Data Integration Reveals Two
              Prognostic Subtypes in {High-Risk} Neuroblastoma",
  author   = "Zhang, Li and Lv, Chenkai and Jin, Yaqiong and Cheng, Ganqi and
              Fu, Yibao and Yuan, Dongsheng and Tao, Yiran and Guo, Yongli and
              Ni, Xin and Shi, Tieliu",
  abstract = "High-risk neuroblastoma is a very aggressive disease, with
              excessive tumor growth and poor outcomes. A proper stratification
              of the high-risk patients by prognostic outcome is important for
              treatment. However, there is still a lack of survival
              stratification for the high-risk neuroblastoma. To fill the gap,
              we adopt a deep learning algorithm, Autoencoder, to integrate
              multi-omics data, and combine it with K-means clustering to
              identify two subtypes with significant survival differences. By
              comparing the Autoencoder with PCA, iCluster, and DGscore about
              the classification based on multi-omics data integration,
              Autoencoder-based classification outperforms the alternative
              approaches. Furthermore, we also validated the classification in
              two independent datasets by training machine-learning
              classification models, and confirmed its robustness. Functional
              analysis revealed that MYCN amplification was more frequently
              occurred in the ultra-high-risk subtype, in accordance with the
              overexpression of MYC/MYCN targets in this subtype. In summary,
              prognostic subtypes identified by deep learning-based multi-omics
              integration could not only improve our understanding of molecular
              mechanism, but also help the clinicians make decisions.",
  journal  = "Front. Genet.",
  volume   =  9,
  pages    = "477",
  month    =  "18~" # oct,
  year     =  2018,
  keywords = "MYCN amplification; deep learning; high-risk neuroblastoma;
              machine learning; multi-omics data integration;DL",
  language = "en",
  issn     = "1664-8021",
  pmid     = "30405689",
  doi      = "10.3389/fgene.2018.00477",
  pmc      = "PMC6201709"
}

@ARTICLE{Huang2019-hh,
  title    = "{SALMON}: Survival Analysis Learning With {Multi-Omics} Neural
              Networks on Breast Cancer",
  author   = "Huang, Zhi and Zhan, Xiaohui and Xiang, Shunian and Johnson,
              Travis S and Helm, Bryan and Yu, Christina Y and Zhang, Jie and
              Salama, Paul and Rizkalla, Maher and Han, Zhi and Huang, Kun",
  abstract = "Improved cancer prognosis is a central goal for precision health
              medicine. Though many models can predict differential survival
              from data, there is a strong need for sophisticated algorithms
              that can aggregate and filter relevant predictors from
              increasingly complex data inputs. In turn, these models should
              provide deeper insight into which types of data are most relevant
              to improve prognosis. Deep Learning-based neural networks offer a
              potential solution for both problems because they are highly
              flexible and account for data complexity in a non-linear fashion.
              In this study, we implement Deep Learning-based networks to
              determine how gene expression data predicts Cox regression
              survival in breast cancer. We accomplish this through an
              algorithm called SALMON (Survival Analysis Learning with
              Multi-Omics Neural Networks), which aggregates and simplifies
              gene expression data and cancer biomarkers to enable prognosis
              prediction. The results revealed improved performance when more
              omics data were used in model construction. Rather than use raw
              gene expression values as model inputs, we innovatively use
              eigengene modules from the result of gene co-expression network
              analysis. The corresponding high impact co-expression modules and
              other omics data are identified by feature selection technique,
              then examined by conducting enrichment analysis and exploiting
              biological functions, escalated the interpretation of input
              feature from gene level to co-expression modules level. Our study
              shows the feasibility of discovering breast cancer related
              co-expression modules, sketch a blueprint of future endeavors on
              Deep Learning-based survival analysis. SALMON source code is
              available at https://github.com/huangzhii/SALMON/.",
  journal  = "Front. Genet.",
  volume   =  10,
  pages    = "166",
  month    =  "8~" # mar,
  year     =  2019,
  keywords = "breast cancer; co-expression analysis; cox regression; deep
              Learning; multi-omics; neural networks; survival prognosis;DL",
  language = "en",
  issn     = "1664-8021",
  pmid     = "30906311",
  doi      = "10.3389/fgene.2019.00166",
  pmc      = "PMC6419526"
}

@ARTICLE{Tarazona2021-yh,
  title     = "Undisclosed, unmet and neglected challenges in multi-omics
               studies",
  author    = "Tarazona, Sonia and Arzalluz-Luque, Angeles and Conesa, Ana",
  abstract  = "Multi-omics approaches have become a reality in both large
               genomics projects and small laboratories. However, the
               multi-omics research community still faces a number of issues
               that have either not been sufficiently discussed or for which
               current solutions are still limited. In this Perspective, we
               elaborate on these limitations and suggest points of attention
               for future research. We finally discuss new opportunities and
               challenges brought to the field by the rapid development of
               single-cell high-throughput molecular technologies. Multi-omics
               studies have been increasingly used to better understand
               biological samples and infer molecular interactions.
               Nevertheless, a number of challenges must still be addressed to
               take full advantage of multi-omics data and to avoid reaching
               potentially incorrect conclusions.",
  journal   = "Nature Computational Science",
  publisher = "Nature Publishing Group",
  pages     = "1--8",
  month     =  "21~" # jun,
  year      =  2021,
  keywords  = "Review",
  language  = "en",
  issn      = "2662-8457, 2662-8457",
  doi       = "10.1038/s43588-021-00086-z"
}

@ARTICLE{Brown2020-wh,
  title         = "Language Models are {Few-Shot} Learners",
  author        = "Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah,
                   Melanie and Kaplan, Jared and Dhariwal, Prafulla and
                   Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and
                   Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel
                   and Krueger, Gretchen and Henighan, Tom and Child, Rewon and
                   Ramesh, Aditya and Ziegler, Daniel M and Wu, Jeffrey and
                   Winter, Clemens and Hesse, Christopher and Chen, Mark and
                   Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess,
                   Benjamin and Clark, Jack and Berner, Christopher and
                   McCandlish, Sam and Radford, Alec and Sutskever, Ilya and
                   Amodei, Dario",
  abstract      = "Recent work has demonstrated substantial gains on many NLP
                   tasks and benchmarks by pre-training on a large corpus of
                   text followed by fine-tuning on a specific task. While
                   typically task-agnostic in architecture, this method still
                   requires task-specific fine-tuning datasets of thousands or
                   tens of thousands of examples. By contrast, humans can
                   generally perform a new language task from only a few
                   examples or from simple instructions - something which
                   current NLP systems still largely struggle to do. Here we
                   show that scaling up language models greatly improves
                   task-agnostic, few-shot performance, sometimes even reaching
                   competitiveness with prior state-of-the-art fine-tuning
                   approaches. Specifically, we train GPT-3, an autoregressive
                   language model with 175 billion parameters, 10x more than
                   any previous non-sparse language model, and test its
                   performance in the few-shot setting. For all tasks, GPT-3 is
                   applied without any gradient updates or fine-tuning, with
                   tasks and few-shot demonstrations specified purely via text
                   interaction with the model. GPT-3 achieves strong
                   performance on many NLP datasets, including translation,
                   question-answering, and cloze tasks, as well as several
                   tasks that require on-the-fly reasoning or domain
                   adaptation, such as unscrambling words, using a novel word
                   in a sentence, or performing 3-digit arithmetic. At the same
                   time, we also identify some datasets where GPT-3's few-shot
                   learning still struggles, as well as some datasets where
                   GPT-3 faces methodological issues related to training on
                   large web corpora. Finally, we find that GPT-3 can generate
                   samples of news articles which human evaluators have
                   difficulty distinguishing from articles written by humans.
                   We discuss broader societal impacts of this finding and of
                   GPT-3 in general.",
  month         =  "28~" # may,
  year          =  2020,
  keywords      = "ML",
  archivePrefix = "arXiv",
  eprint        = "2005.14165",
  primaryClass  = "cs.CL",
  arxivid       = "2005.14165"
}

@ARTICLE{Duan2017-ae,
  title         = "One-shot imitation learning",
  author        = "Duan, Yan and Andrychowicz, Marcin and Stadie, Bradly C and
                   Ho, Jonathan and Schneider, Jonas and Sutskever, Ilya and
                   Abbeel, Pieter and Zaremba, Wojciech",
  abstract      = "Imitation learning has been commonly applied to solve
                   different tasks in isolation. This usually requires either
                   careful feature engineering, or a significant number of
                   samples. This is far from what we desire: ideally, robots
                   should be able to learn from very few demonstrations of any
                   given task, and instantly generalize to new situations of
                   the same task, without requiring task-specific engineering.
                   In this paper, we propose a meta-learning framework for
                   achieving such capability, which we call one-shot imitation
                   learning. Specifically, we consider the setting where there
                   is a very large set of tasks, and each task has many
                   instantiations. For example, a task could be to stack all
                   blocks on a table into a single tower, another task could be
                   to place all blocks on a table into two-block towers, etc.
                   In each case, different instances of the task would consist
                   of different sets of blocks with different initial states.
                   At training time, our algorithm is presented with pairs of
                   demonstrations for a subset of all tasks. A neural net is
                   trained that takes as input one demonstration and the
                   current state (which initially is the initial state of the
                   other demonstration of the pair), and outputs an action with
                   the goal that the resulting sequence of states and actions
                   matches as closely as possible with the second
                   demonstration. At test time, a demonstration of a single
                   instance of a new task is presented, and the neural net is
                   expected to perform well on new instances of this new task.
                   The use of soft attention allows the model to generalize to
                   conditions and tasks unseen in the training data. We
                   anticipate that by training this model on a much greater
                   variety of tasks and settings, we will obtain a general
                   system that can turn any demonstrations into robust policies
                   that can accomplish an overwhelming variety of tasks. Videos
                   available at https://bit.ly/nips2017-oneshot .",
  month         =  "21~" # mar,
  year          =  2017,
  keywords      = "ML",
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  eprint        = "1703.07326",
  primaryClass  = "cs.AI",
  arxivid       = "1703.07326"
}

@ARTICLE{Zhu2020-cv,
  title    = "The Application of Deep Learning in Cancer Prognosis Prediction",
  author   = "Zhu, Wan and Xie, Longxiang and Han, Jianye and Guo, Xiangqian",
  abstract = "Deep learning has been applied to many areas in health care,
              including imaging diagnosis, digital pathology, prediction of
              hospital admission, drug design, classification of cancer and
              stromal cells, doctor assistance, etc. Cancer prognosis is to
              estimate the fate of cancer, probabilities of cancer recurrence
              and progression, and to provide survival estimation to the
              patients. The accuracy of cancer prognosis prediction will
              greatly benefit clinical management of cancer patients. The
              improvement of biomedical translational research and the
              application of advanced statistical analysis and machine learning
              methods are the driving forces to improve cancer prognosis
              prediction. Recent years, there is a significant increase of
              computational power and rapid advancement in the technology of
              artificial intelligence, particularly in deep learning. In
              addition, the cost reduction in large scale next-generation
              sequencing, and the availability of such data through open source
              databases (e.g., TCGA and GEO databases) offer us opportunities
              to possibly build more powerful and accurate models to predict
              cancer prognosis more accurately. In this review, we reviewed the
              most recent published works that used deep learning to build
              models for cancer prognosis prediction. Deep learning has been
              suggested to be a more generic model, requires less data
              engineering, and achieves more accurate prediction when working
              with large amounts of data. The application of deep learning in
              cancer prognosis has been shown to be equivalent or better than
              current approaches, such as Cox-PH. With the burst of multi-omics
              data, including genomics data, transcriptomics data and clinical
              information in cancer studies, we believe that deep learning
              would potentially improve cancer prognosis.",
  journal  = "Cancers",
  volume   =  12,
  number   =  3,
  month    =  "5~" # mar,
  year     =  2020,
  keywords = "cancer prognosis; deep learning; machine learning; multi-omics;
              prognosis prediction;Bio-med;ML",
  language = "en",
  issn     = "2072-6694",
  pmid     = "32150991",
  doi      = "10.3390/cancers12030603",
  pmc      = "PMC7139576"
}

@MISC{The_AlphaFold_team2020-gx,
  title        = "{AlphaFold}: a solution to a 50-year-old grand challenge in
                  biology",
  booktitle    = "{DeepMind}",
  author       = "{The AlphaFold team}",
  abstract     = "In a major scientific advance, the latest version of our AI
                  system AlphaFold has been recognised as a solution to this
                  grand challenge by the organisers of the biennial Critical
                  Assessment of protein Structure Prediction (CASP) assessment.
                  This breakthrough demonstrates the impact AI can have on
                  scientific discovery and its potential to dramatically
                  accelerate progress in some of the most fundamental fields
                  that explain and shape our world.",
  month        =  "30~" # nov,
  year         =  2020,
  howpublished = "\url{https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology}",
  note         = "Accessed: 2021-6-22",
  keywords     = "ML"
}

@ARTICLE{Katzman2018-qv,
  title    = "{DeepSurv}: personalized treatment recommender system using a Cox
              proportional hazards deep neural network",
  author   = "Katzman, Jared L and Shaham, Uri and Cloninger, Alexander and
              Bates, Jonathan and Jiang, Tingting and Kluger, Yuval",
  abstract = "BACKGROUND: Medical practitioners use survival models to explore
              and understand the relationships between patients' covariates
              (e.g. clinical and genetic features) and the effectiveness of
              various treatment options. Standard survival models like the
              linear Cox proportional hazards model require extensive feature
              engineering or prior medical knowledge to model treatment
              interaction at an individual level. While nonlinear survival
              methods, such as neural networks and survival forests, can
              inherently model these high-level interaction terms, they have
              yet to be shown as effective treatment recommender systems.
              METHODS: We introduce DeepSurv, a Cox proportional hazards deep
              neural network and state-of-the-art survival method for modeling
              interactions between a patient's covariates and treatment
              effectiveness in order to provide personalized treatment
              recommendations. RESULTS: We perform a number of experiments
              training DeepSurv on simulated and real survival data. We
              demonstrate that DeepSurv performs as well as or better than
              other state-of-the-art survival models and validate that DeepSurv
              successfully models increasingly complex relationships between a
              patient's covariates and their risk of failure. We then show how
              DeepSurv models the relationship between a patient's features and
              effectiveness of different treatment options to show how DeepSurv
              can be used to provide individual treatment recommendations.
              Finally, we train DeepSurv on real clinical studies to
              demonstrate how it's personalized treatment recommendations would
              increase the survival time of a set of patients. CONCLUSIONS: The
              predictive and modeling capabilities of DeepSurv will enable
              medical researchers to use deep neural networks as a tool in
              their exploration, understanding, and prediction of the effects
              of a patient's characteristics on their risk of failure.",
  journal  = "BMC Med. Res. Methodol.",
  volume   =  18,
  number   =  1,
  pages    = "24",
  month    =  "26~" # feb,
  year     =  2018,
  keywords = "Deep learning; Survival analysis; Treatment recommendations;ML",
  language = "en",
  issn     = "1471-2288",
  pmid     = "29482517",
  doi      = "10.1186/s12874-018-0482-1",
  pmc      = "PMC5828433"
}

@ARTICLE{Ching2018-gq,
  title    = "Cox-nnet: An artificial neural network method for prognosis
              prediction of high-throughput omics data",
  author   = "Ching, Travers and Zhu, Xun and Garmire, Lana X",
  abstract = "Artificial neural networks (ANN) are computing architectures with
              many interconnections of simple neural-inspired computing
              elements, and have been applied to biomedical fields such as
              imaging analysis and diagnosis. We have developed a new ANN
              framework called Cox-nnet to predict patient prognosis from high
              throughput transcriptomics data. In 10 TCGA RNA-Seq data sets,
              Cox-nnet achieves the same or better predictive accuracy compared
              to other methods, including Cox-proportional hazards regression
              (with LASSO, ridge, and mimimax concave penalty), Random Forests
              Survival and CoxBoost. Cox-nnet also reveals richer biological
              information, at both the pathway and gene levels. The outputs
              from the hidden layer node provide an alternative approach for
              survival-sensitive dimension reduction. In summary, we have
              developed a new method for accurate and efficient prognosis
              prediction on high throughput data, with functional biological
              insights. The source code is freely available at
              https://github.com/lanagarmire/cox-nnet.",
  journal  = "PLoS Comput. Biol.",
  volume   =  14,
  number   =  4,
  pages    = "e1006076",
  month    =  apr,
  year     =  2018,
  keywords = "ML",
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "29634719",
  doi      = "10.1371/journal.pcbi.1006076",
  pmc      = "PMC5909924"
}

@ARTICLE{Huang2020-xh,
  title    = "Deep learning-based cancer survival prognosis from {RNA-seq}
              data: approaches and evaluations",
  author   = "Huang, Zhi and Johnson, Travis S and Han, Zhi and Helm, Bryan and
              Cao, Sha and Zhang, Chi and Salama, Paul and Rizkalla, Maher and
              Yu, Christina Y and Cheng, Jun and Xiang, Shunian and Zhan,
              Xiaohui and Zhang, Jie and Huang, Kun",
  abstract = "BACKGROUND: Recent advances in kernel-based Deep Learning models
              have introduced a new era in medical research. Originally
              designed for pattern recognition and image processing, Deep
              Learning models are now applied to survival prognosis of cancer
              patients. Specifically, Deep Learning versions of the Cox
              proportional hazards models are trained with transcriptomic data
              to predict survival outcomes in cancer patients. METHODS: In this
              study, a broad analysis was performed on TCGA cancers using a
              variety of Deep Learning-based models, including Cox-nnet,
              DeepSurv, and a method proposed by our group named AECOX
              (AutoEncoder with Cox regression network). Concordance index and
              p-value of the log-rank test are used to evaluate the model
              performances. RESULTS: All models show competitive results across
              12 cancer types. The last hidden layers of the Deep Learning
              approaches are lower dimensional representations of the input
              data that can be used for feature reduction and visualization.
              Furthermore, the prognosis performances reveal a negative
              correlation between model accuracy, overall survival time
              statistics, and tumor mutation burden (TMB), suggesting an
              association among overall survival time, TMB, and prognosis
              prediction accuracy. CONCLUSIONS: Deep Learning based algorithms
              demonstrate superior performances than traditional machine
              learning based models. The cancer prognosis results measured in
              concordance index are indistinguishable across models while are
              highly variable across cancers. These findings shedding some
              light into the relationships between patient characteristics and
              survival learnability on a pan-cancer level.",
  journal  = "BMC Med. Genomics",
  volume   =  13,
  number   = "Suppl 5",
  pages    = "41",
  month    =  "3~" # apr,
  year     =  2020,
  keywords = "Cancer prognosis; Cox regression; Deep learning; Survival
              analysis; Tumor mutation burden;Bio-med;ML",
  language = "en",
  issn     = "1755-8794",
  pmid     = "32241264",
  doi      = "10.1186/s12920-020-0686-1",
  pmc      = "PMC7118823"
}

@INPROCEEDINGS{Lu2018-bi,
  title     = "A Hybrid Ensemble Algorithm Combining {AdaBoost} and Genetic
               Algorithm for Cancer Classification with Gene Expression Data",
  booktitle = "2018 9th International Conference on Information Technology in
               Medicine and Education ({ITME})",
  author    = "Lu, Huijuan and Gao, Huiyun and Ye, Minchao and Yan, Ke and
               Wang, Xiuhui",
  abstract  = "There are two key issues in the field of ensemble learning: (1)
               diversity of base classifiers; (2) the way of integrating
               multiple classifiers. In this paper, a special classifier
               structure, namely, decision group, is designed to increase the
               diversity of base classifier pool; and the genetic algorithm
               (GA) is used to assign weight to each base classifier, thus to
               improve the classification performance by avoiding local
               extremes. Overall, this work presents an ensemble classification
               algorithm based on AdaBoost. The base classifiers are decision
               groups composed by base classifiers, including
               K-nearest-neighbor (KNN), na{\"\i}ve Bayes (NB) and decision
               tree (C4.5). Aiming at the characteristics of high dimensional
               and small samples of cancer gene expression data, a simple
               ensemble algorithm with decision groups composed of three base
               classifiers is proposed. Experimental results show that the
               proposed algorithm is superior to existing ensemble learning
               methods, such as Bagging, Random Forest (RF), Rotation Forest
               (RoF), AdaBoost, AdaBoost-BPNN, AdaBoost-SVM and AdaBoost-RF,
               and especially it has better performance on small sample and
               unbalanced gene expression data processing.",
  pages     = "15--19",
  month     =  oct,
  year      =  2018,
  keywords  = "Information technology;Education;AdaBoost;Decision
               Group;K-Nearest Neighbor;Na{\"\i}ve Bayes;Decision Tree;Genetic
               Algorithm",
  issn      = "2474-3828",
  doi       = "10.1109/ITME.2018.00015"
}

@ARTICLE{1-31-_undated-ot,
  title  = "{AUC} Knowledge {FAUC} Knowledge Fountain ountain",
  author = "1-31-, Dissertations Winter"
}

@ARTICLE{Sharma2021-aa,
  title    = "A Systematic Review of Applications of Machine Learning in Cancer
              Prediction and Diagnosis",
  author   = "Sharma, Aman and Rani, Rinkle",
  abstract = "Advancement in genome sequencing technology has empowered
              researchers to think beyond their imagination. Researchers are
              trying their hard to fight against various genetic diseases such
              as cancer. Artificial intelligence has empowered research in the
              healthcare sector. The availability of open-source healthcare
              datasets has motivated the researchers to develop applications
              which helps in early diagnosis and prognosis of diseases.
              Further, Next-generation sequencing has helped to look into
              detailed intricacies of biological systems. It has provided an
              efficient and cost-effective approach with higher accuracy. The
              advent of microRNAs also known as small noncoding genes has begun
              the paradigm shift in oncological research. We are now able to
              profile expression profiles of RNAs using RNA-seq data. microRNA
              profiling has helped in uncovering their relationship in various
              genetic and biological processes. Here in this paper, we present
              a review of the machine learning perspective in cancer research.
              The best way to develop effective cancer treatment/drugs is to
              better understand the intricacies and complexities involved in
              the cancer microenvironment. Although there has been a plethora
              of methods and techniques proposed in the literature, still the
              deadliness of cancer can't be reduced. In such a situation
              Artificial intelligence (AI) or machine learning is providing a
              reliable, fast, and efficient way to deal with such stringent
              diseases.",
  journal  = "Arch. Comput. Methods Eng.",
  month    =  "25~" # jan,
  year     =  2021,
  keywords = "ML;Bio-med",
  issn     = "1134-3060, 1886-1784",
  doi      = "10.1007/s11831-021-09556-z"
}

@ARTICLE{Zrimec2020-in,
  title    = "Deep learning suggests that gene expression is encoded in all
              parts of a co-evolving interacting gene regulatory structure",
  author   = "Zrimec, Jan and B{\"o}rlin, Christoph S and Buric, Filip and
              Muhammad, Azam Sheikh and Chen, Rhongzen and Siewers, Verena and
              Verendel, Vilhelm and Nielsen, Jens and T{\"o}pel, Mats and
              Zelezniak, Aleksej",
  abstract = "Understanding the genetic regulatory code governing gene
              expression is an important challenge in molecular biology.
              However, how individual coding and non-coding regions of the gene
              regulatory structure interact and contribute to mRNA expression
              levels remains unclear. Here we apply deep learning on over
              20,000 mRNA datasets to examine the genetic regulatory code
              controlling mRNA abundance in 7 model organisms ranging from
              bacteria to Human. In all organisms, we can predict mRNA
              abundance directly from DNA sequence, with up to 82\% of the
              variation of transcript levels encoded in the gene regulatory
              structure. By searching for DNA regulatory motifs across the gene
              regulatory structure, we discover that motif interactions could
              explain the whole dynamic range of mRNA levels. Co-evolution
              across coding and non-coding regions suggests that it is not
              single motifs or regions, but the entire gene regulatory
              structure and specific combination of regulatory elements that
              define gene expression levels.",
  journal  = "Nat. Commun.",
  volume   =  11,
  number   =  1,
  pages    = "6141",
  month    =  "1~" # dec,
  year     =  2020,
  keywords = "ML",
  language = "en",
  issn     = "2041-1723",
  pmid     = "33262328",
  doi      = "10.1038/s41467-020-19921-4",
  pmc      = "PMC7708451"
}

@ARTICLE{Lim2019-xh,
  title    = "Compendiums of cancer transcriptomes for machine learning
              applications",
  author   = "Lim, Su Bin and Tan, Swee Jin and Lim, Wan-Teck and Lim, Chwee
              Teck",
  abstract = "There are massive transcriptome profiles in the form of
              microarray. The challenge is that they are processed using
              diverse platforms and preprocessing tools, requiring considerable
              time and informatics expertise for cross-dataset analyses. If
              there exists a single, integrated data source, data-reuse can be
              facilitated for discovery, analysis, and validation of
              biomarker-based clinical strategy. Here, we present merged
              microarray-acquired datasets (MMDs) across 11 major cancer types,
              curating 8,386 patient-derived tumor and tumor-free samples from
              95 GEO datasets. Using machine learning algorithms, we show that
              diagnostic models trained from MMDs can be directly applied to
              RNA-seq-acquired TCGA data with high classification accuracy.
              Machine learning optimized MMD further aids to reveal immune
              landscape across various carcinomas critically needed in disease
              management and clinical interventions. This unified data source
              may serve as an excellent training or test set to apply, develop,
              and refine machine learning algorithms that can be tapped to
              better define genomic landscape of human cancers.",
  journal  = "Sci Data",
  volume   =  6,
  number   =  1,
  pages    = "194",
  month    =  "8~" # oct,
  year     =  2019,
  keywords = "Bio-med;ML",
  language = "en",
  issn     = "2052-4463",
  pmid     = "31594947",
  doi      = "10.1038/s41597-019-0207-2",
  pmc      = "PMC6783425"
}

@INPROCEEDINGS{Schmidt2009-zh,
  title     = "Bayesian Non-negative Matrix Factorization",
  booktitle = "Independent Component Analysis and Signal Separation",
  author    = "Schmidt, Mikkel N and Winther, Ole and Hansen, Lars Kai",
  abstract  = "We present a Bayesian treatment of non-negative matrix
               factorization (NMF), based on a normal likelihood and
               exponential priors, and derive an efficient Gibbs sampler to
               approximate the posterior density of the NMF factors. On a
               chemical brain imaging data set, we show that this improves
               interpretability by providing uncertainty estimates. We discuss
               how the Gibbs sampler can be used for model order selection by
               estimating the marginal likelihood, and compare with the
               Bayesian information criterion. For computing the maximum a
               posteriori estimate we present an iterated conditional modes
               algorithm that rivals existing state-of-the-art NMF algorithms
               on an image feature extraction problem.",
  publisher = "Springer Berlin Heidelberg",
  pages     = "540--547",
  year      =  2009,
  doi       = "10.1007/978-3-642-00599-2\_68"
}

@ARTICLE{Rule2019-pl,
  title    = "Causes and consequences of representational drift",
  author   = "Rule, Michael E and O'Leary, Timothy and Harvey, Christopher D",
  abstract = "The nervous system learns new associations while maintaining
              memories over long periods, exhibiting a balance between
              flexibility and stability. Recent experiments reveal that
              neuronal representations of learned sensorimotor tasks
              continually change over days and weeks, even after animals have
              achieved expert behavioral performance. How is learned
              information stored to allow consistent behavior despite ongoing
              changes in neuronal activity? What functions could ongoing
              reconfiguration serve? We highlight recent experimental evidence
              for such representational drift in sensorimotor systems, and
              discuss how this fits into a framework of distributed population
              codes. We identify recent theoretical work that suggests
              computational roles for drift and argue that the recurrent and
              distributed nature of sensorimotor representations permits drift
              while limiting disruptive effects. We propose that
              representational drift may create error signals between
              interconnected brain regions that can be used to keep neural
              codes consistent in the presence of continual change. These
              concepts suggest experimental and theoretical approaches to
              studying both learning and maintenance of distributed and
              adaptive population codes.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  58,
  pages    = "141--147",
  month    =  oct,
  year     =  2019,
  language = "en",
  issn     = "0959-4388, 1873-6882",
  pmid     = "31569062",
  doi      = "10.1016/j.conb.2019.08.005",
  pmc      = "PMC7385530"
}

@ARTICLE{Chavlis2021-zf,
  title    = "Drawing inspiration from biological dendrites to empower
              artificial neural networks",
  author   = "Chavlis, Spyridon and Poirazi, Panayiota",
  abstract = "This article highlights specific features of biological neurons
              and their dendritic trees, whose adoption may help advance
              artificial neural networks used in various machine learning
              applications. Advancements could take the form of increased
              computational capabilities and/or reduced power consumption.
              Proposed features include dendritic anatomy, dendritic
              nonlinearities, and compartmentalized plasticity rules, all of
              which shape learning and information processing in biological
              networks. We discuss the computational benefits provided by these
              features in biological neurons and suggest ways to adopt them in
              artificial neurons in order to exploit the respective benefits in
              machine learning.",
  journal  = "Curr. Opin. Neurobiol.",
  volume   =  70,
  pages    = "1--10",
  month    =  "1~" # oct,
  year     =  2021,
  issn     = "0959-4388",
  doi      = "10.1016/j.conb.2021.04.007"
}

@ARTICLE{Babur2015-qk,
  title    = "Systematic identification of cancer driving signaling pathways
              based on mutual exclusivity of genomic alterations",
  author   = "Babur, {\"O}zg{\"u}n and G{\"o}nen, Mithat and Aksoy, B{\"u}lent
              Arman and Schultz, Nikolaus and Ciriello, Giovanni and Sander,
              Chris and Demir, Emek",
  abstract = "We present a novel method for the identification of sets of
              mutually exclusive gene alterations in a given set of genomic
              profiles. We scan the groups of genes with a common downstream
              effect on the signaling network, using a mutual exclusivity
              criterion that ensures that each gene in the group significantly
              contributes to the mutual exclusivity pattern. We test the method
              on all available TCGA cancer genomics datasets, and detect
              multiple previously unreported alterations that show significant
              mutual exclusivity and are likely to be driver events.",
  journal  = "Genome Biol.",
  volume   =  16,
  pages    = "45",
  month    =  "26~" # feb,
  year     =  2015,
  keywords = "ML;Bio-med",
  language = "en",
  issn     = "1465-6906",
  pmid     = "25887147",
  doi      = "10.1186/s13059-015-0612-6",
  pmc      = "PMC4381444"
}

@ARTICLE{Tian2021-vu,
  title     = "Clustering of cancer data based on Stiefel manifold for multiple
               views",
  author    = "Tian, Jing and Zhao, Jianping and Zheng, Chunhou",
  abstract  = "In recent years, various sequencing techniques have been used to
               collect biomedical omics datasets. It is usually possible to
               obtain multiple types of omics data from a single patient
               sample. Clustering of omics data plays an indispensable role in
               biological and medical research, and it is helpful to reveal
               data structures from multiple collections. Nevertheless,
               clustering of omics data consists of many challenges. The
               primary challenges in omics data analysis come from high
               dimension of data and small size of sample. Therefore, it is
               difficult to find a suitable integration method for structural
               analysis of multiple datasets. In this paper, a multi-view
               clustering based on Stiefel manifold method (MCSM) is proposed.
               The MCSM method comprises three core steps. Firstly, we
               established a binary optimization model for the simultaneous
               clustering problem. Secondly, we solved the optimization problem
               by linear search algorithm based on Stiefel manifold. Finally,
               we integrated the clustering results obtained from three omics
               by using k-nearest neighbor method. We applied this approach to
               four cancer datasets on TCGA. The result shows that our method
               is superior to several state-of-art methods, which depends on
               the hypothesis that the underlying omics cluster class is the
               same. Particularly, our approach has better performance than
               compared approaches when the underlying clusters are
               inconsistent. For patients with different subtypes, both
               consistent and differential clusters can be identified at the
               same time.",
  journal   = "BMC Bioinformatics",
  publisher = "BioMed Central",
  volume    =  22,
  number    =  1,
  pages     = "1--15",
  month     =  "25~" # may,
  year      =  2021,
  keywords  = "ML;Bio-med",
  language  = "en",
  issn      = "1471-2105, 1471-2105",
  doi       = "10.1186/s12859-021-04195-4"
}

@ARTICLE{Baker2021-xj,
  title         = "A philosophical understanding of representation for
                   neuroscience",
  author        = "Baker, Ben and Lansdell, Benjamin and Kording, Konrad",
  abstract      = "Neuroscientists often describe neural activity as a
                   representation of something, or claim to have found evidence
                   for a neural representation. But what do these statements
                   mean? The reasons to call some neural activity a
                   representation and the assumptions that come with this term
                   are not generally made clear from its common uses in
                   neuroscience. Representation is a central concept in
                   philosophy of mind, with a rich history going back to the
                   ancient period. In order to clarify its usage in
                   neuroscience, here we advance a link between the
                   connotations of this term across these disciplines. We draw
                   on a broad range of discourse in philosophy to distinguish
                   three key aspects of representation: correspondence,
                   functional role, and teleology. We argue that each of these
                   aspects are implied by the explanatory role the term plays
                   in neuroscience. However, evidence related to all three
                   aspects is rarely presented or discussed in the course of
                   individual studies that aim to identify representations.
                   Overlooking the significance of all three aspects hinders
                   communication in neuroscience, as it obscures the
                   limitations of experimental paradigms and conceals gaps in
                   our understanding of the phenomena of primary interest.
                   Working from this three-part view, we discuss how to move
                   toward clearer communication about representations in the
                   brain.",
  month         =  "12~" # feb,
  year          =  2021,
  keywords      = "SNN",
  copyright     = "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  archivePrefix = "arXiv",
  eprint        = "2102.06592",
  primaryClass  = "q-bio.NC",
  arxivid       = "2102.06592"
}

@ARTICLE{Hasson2020-yf,
  title     = "Direct fit to nature: An evolutionary perspective on biological
               and artificial neural networks",
  author    = "Hasson, Uri and Nastase, Samuel A and Goldstein, Ariel",
  abstract  = "Evolution is a blind fitting process by which organisms become
               adapted to their environment. Does the brain use similar
               brute-force fitting processes to learn how to perceive and act
               upon the world? Recent advances in artificial neural networks
               have exposed the power of optimizing millions of synaptic
               weights over millions of observations to operate robustly in
               real-world contexts. These models do not learn simple,
               human-interpretable rules or representations of the world;
               rather, they use local computations to interpolate over
               task-relevant manifolds in a high-dimensional parameter space.
               Counterintuitively, similar to evolutionary processes,
               over-parameterized models can be simple and parsimonious, as
               they provide a versatile, robust solution for learning a diverse
               set of functions. This new family of direct-fit models present a
               radical challenge to many of the theoretical assumptions in
               psychology and neuroscience. At the same time, this shift in
               perspective establishes unexpected links with developmental and
               ecological psychology.",
  journal   = "Neuron",
  publisher = "Elsevier BV",
  volume    =  105,
  number    =  3,
  pages     = "416--434",
  month     =  "5~" # feb,
  year      =  2020,
  keywords  = "evolution; experimental design; interpolation; learning; neural
               networks;SNN",
  copyright = "http://www.elsevier.com/open-access/userlicense/1.0/",
  language  = "en",
  issn      = "0896-6273, 1097-4199",
  pmid      = "32027833",
  doi       = "10.1016/j.neuron.2019.12.002",
  pmc       = "PMC7096172"
}

@ARTICLE{Kording2020-up,
  title         = "Appreciating the variety of goals in computational
                   neuroscience",
  author        = "Kording, Konrad P and Blohm, Gunnar and Schrater, Paul and
                   Kay, Kendrick",
  abstract      = "Within computational neuroscience, informal interactions
                   with modelers often reveal wildly divergent goals. In this
                   opinion piece, we explicitly address the diversity of goals
                   that motivate and ultimately influence modeling efforts. We
                   argue that a wide range of goals can be meaningfully taken
                   to be of highest importance. A simple informal survey
                   conducted on the Internet confirmed the diversity of goals
                   in the community. However, different priorities or
                   preferences of individual researchers can lead to divergent
                   model evaluation criteria. We propose that many
                   disagreements in evaluating the merit of computational
                   research stem from differences in goals and not from the
                   mechanics of constructing, describing, and validating
                   models. We suggest that authors state explicitly their goals
                   when proposing models so that others can judge the quality
                   of the research with respect to its stated goals.",
  month         =  "8~" # feb,
  year          =  2020,
  keywords      = "SNN",
  copyright     = "http://creativecommons.org/licenses/by/4.0/",
  archivePrefix = "arXiv",
  eprint        = "2002.03211",
  primaryClass  = "q-bio.NC",
  arxivid       = "2002.03211"
}

@ARTICLE{Krichmar2021-cw,
  title         = "Edelman's Steps Toward a Conscious Artifact",
  author        = "Krichmar, Jeffrey L",
  abstract      = "In 2006, during a meeting of a working group of scientists
                   in La Jolla, California at The Neurosciences Institute
                   (NSI), Gerald Edelman described a roadmap towards the
                   creation of a Conscious Artifact. As far as I know, this
                   roadmap was not published. However, it did shape my thinking
                   and that of many others in the years since that meeting.
                   This short paper, which is based on my notes taken during
                   the meeting, describes the key steps in this roadmap. I
                   believe it is as groundbreaking today as it was more than 15
                   years ago.",
  month         =  "22~" # may,
  year          =  2021,
  archivePrefix = "arXiv",
  eprint        = "2105.10461",
  primaryClass  = "q-bio.NC",
  arxivid       = "2105.10461"
}

@MISC{Carbon2018-ah,
  title     = "Gene Ontology Data Archive",
  author    = "Carbon, Seth and Mungall, Chris",
  abstract  = "Archival bundle of GO data release.",
  publisher = "Zenodo",
  year      =  2018,
  doi       = "10.5281/ZENODO.4735677"
}

@ARTICLE{Szklarczyk2019-pu,
  title    = "{STRING} v11: protein-protein association networks with increased
              coverage, supporting functional discovery in genome-wide
              experimental datasets",
  author   = "Szklarczyk, Damian and Gable, Annika L and Lyon, David and Junge,
              Alexander and Wyder, Stefan and Huerta-Cepas, Jaime and
              Simonovic, Milan and Doncheva, Nadezhda T and Morris, John H and
              Bork, Peer and Jensen, Lars J and Mering, Christian von",
  abstract = "Proteins and their functional interactions form the backbone of
              the cellular machinery. Their connectivity network needs to be
              considered for the full understanding of biological phenomena,
              but the available information on protein-protein associations is
              incomplete and exhibits varying levels of annotation granularity
              and reliability. The STRING database aims to collect, score and
              integrate all publicly available sources of protein-protein
              interaction information, and to complement these with
              computational predictions. Its goal is to achieve a comprehensive
              and objective global network, including direct (physical) as well
              as indirect (functional) interactions. The latest version of
              STRING (11.0) more than doubles the number of organisms it
              covers, to 5090. The most important new feature is an option to
              upload entire, genome-wide datasets as input, allowing users to
              visualize subsets as interaction networks and to perform gene-set
              enrichment analysis on the entire input. For the enrichment
              analysis, STRING implements well-known classification systems
              such as Gene Ontology and KEGG, but also offers additional, new
              classification systems based on high-throughput text-mining as
              well as on a hierarchical clustering of the association network
              itself. The STRING resource is available online at
              https://string-db.org/.",
  journal  = "Nucleic Acids Res.",
  volume   =  47,
  number   = "D1",
  pages    = "D607--D613",
  month    =  "8~" # jan,
  year     =  2019,
  keywords = "Bio-med",
  language = "en",
  issn     = "0305-1048, 1362-4962",
  pmid     = "30476243",
  doi      = "10.1093/nar/gky1131",
  pmc      = "PMC6323986"
}

@ARTICLE{Feltes2019-bd,
  title    = "{CuMiDa}: An Extensively Curated Microarray Database for
              Benchmarking and Testing of Machine Learning Approaches in Cancer
              Research",
  author   = "Feltes, Bruno C{\'e}sar and Chandelier, Eduardo Bassani and
              Grisci, Bruno Iochins and Dorn, M{\'a}rcio",
  abstract = "The employment of machine learning (ML) approaches to extract
              gene expression information from microarray studies has increased
              in the past years, specially on cancer-related works. However,
              despite this continuous interest in applying ML in cancer
              biomedical research, there are no curated repositories focused
              only on providing quality data sets exclusively for benchmarking
              and testing of such techniques for cancer research. Thus, in this
              work, we present the Curated Microarray Database (CuMiDa), a
              database composed of 78 handpicked microarray data sets for Homo
              sapiens that were carefully examined from more than 30,000
              microarray experiments from the Gene Expression Omnibus using a
              rigorous filtering criteria. All data sets were individually
              submitted to background correction, normalization, sample quality
              analysis and were manually edited to eliminate erroneous probes.
              All data sets were tested using principal component analysis
              (PCA) and t-distributed stochastic neighbor embedding (t-SNE)
              analyses to observe sample division and were additionally tested
              using various ML approaches to provide a base accuracy for the
              major techniques employed for microarray data sets. CuMiDa is a
              database created solely for benchmarking and testing of ML
              approaches applied to cancer research.",
  journal  = "J. Comput. Biol.",
  volume   =  26,
  number   =  4,
  pages    = "376--386",
  month    =  apr,
  year     =  2019,
  keywords = "benchmarking; cancer; classification; curation; machine learning;
              microarray; supervised learning; unsupervised learning;Bio-med",
  language = "en",
  issn     = "1066-5277, 1557-8666",
  pmid     = "30789283",
  doi      = "10.1089/cmb.2018.0238"
}

@ARTICLE{Troyanskaya2020-go,
  title     = "Artificial intelligence and cancer",
  author    = "Troyanskaya, Olga and Trajanoski, Zlatko and Carpenter, Anne and
               Thrun, Sebastian and Razavian, Narges and Oliver, Nuria",
  abstract  = "Filtered through the analytical power of artificial
               intelligence, the wealth of available biomedical data promises
               to revolutionize cancer research, diagnosis and care. In this
               Viewpoint, six experts discuss some of the challenges, exciting
               developments and future questions arising at the interface of
               machine learning and oncology.",
  journal   = "Nature Cancer",
  publisher = "Nature Publishing Group",
  volume    =  1,
  number    =  2,
  pages     = "149--152",
  month     =  "24~" # feb,
  year      =  2020,
  keywords  = "Bio-med;ML",
  language  = "en",
  issn      = "2662-1347, 2662-1347",
  doi       = "10.1038/s43018-020-0034-6"
}

@ARTICLE{Vandin2011-bs,
  title    = "Algorithms for detecting significantly mutated pathways in cancer",
  author   = "Vandin, Fabio and Upfal, Eli and Raphael, Benjamin J",
  abstract = "Recent genome sequencing studies have shown that the somatic
              mutations that drive cancer development are distributed across a
              large number of genes. This mutational heterogeneity complicates
              efforts to distinguish functional mutations from sporadic,
              passenger mutations. Since cancer mutations are hypothesized to
              target a relatively small number of cellular signaling and
              regulatory pathways, a common practice is to assess whether known
              pathways are enriched for mutated genes. We introduce an
              alternative approach that examines mutated genes in the context
              of a genome-scale gene interaction network. We present a
              computationally efficient strategy for de novo identification of
              subnetworks in an interaction network that are mutated in a
              statistically significant number of patients. This framework
              includes two major components. First, we use a diffusion process
              on the interaction network to define a local neighborhood of
              ``influence'' for each mutated gene in the network. Second, we
              derive a two-stage multiple hypothesis test to bound the false
              discovery rate (FDR) associated with the identified subnetworks.
              We test these algorithms on a large human protein-protein
              interaction network using somatic mutation data from glioblastoma
              and lung adenocarcinoma samples. We successfully recover pathways
              that are known to be important in these cancers and also identify
              additional pathways that have been implicated in other cancers
              but not previously reported as mutated in these samples. We
              anticipate that our approach will find increasing use as cancer
              genome studies increase in size and scope.",
  journal  = "J. Comput. Biol.",
  volume   =  18,
  number   =  3,
  pages    = "507--522",
  month    =  mar,
  year     =  2011,
  keywords = "ML;Bio-med",
  language = "en",
  issn     = "1066-5277, 1557-8666",
  pmid     = "21385051",
  doi      = "10.1089/cmb.2010.0265"
}

@ARTICLE{Cancer_Genome_Atlas_Research_Network2008-hb,
  title     = "Comprehensive genomic characterization defines human
               glioblastoma genes and core pathways",
  author    = "{Cancer Genome Atlas Research Network}",
  abstract  = "Human cancer cells typically harbour multiple chromosomal
               aberrations, nucleotide substitutions and epigenetic
               modifications that drive malignant transformation. The Cancer
               Genome Atlas (TCGA) pilot project aims to assess the value of
               large-scale multi-dimensional analysis of these molecular
               characteristics in human cancer and to provide the data rapidly
               to the research community. Here we report the interim
               integrative analysis of DNA copy number, gene expression and DNA
               methylation aberrations in 206 glioblastomas--the most common
               type of adult brain cancer--and nucleotide sequence aberrations
               in 91 of the 206 glioblastomas. This analysis provides new
               insights into the roles of ERBB2, NF1 and TP53, uncovers
               frequent mutations of the phosphatidylinositol-3-OH kinase
               regulatory subunit gene PIK3R1, and provides a network view of
               the pathways altered in the development of glioblastoma.
               Furthermore, integration of mutation, DNA methylation and
               clinical treatment data reveals a link between MGMT promoter
               methylation and a hypermutator phenotype consequent to mismatch
               repair deficiency in treated glioblastomas, an observation with
               potential clinical implications. Together, these findings
               establish the feasibility and power of TCGA, demonstrating that
               it can rapidly expand knowledge of the molecular basis of
               cancer.",
  journal   = "Nature",
  publisher = "Springer Science and Business Media LLC",
  volume    =  455,
  number    =  7216,
  pages     = "1061--1068",
  month     =  "23~" # oct,
  year      =  2008,
  keywords  = "Relevant",
  language  = "en",
  issn      = "0028-0836, 1476-4687",
  pmid      = "18772890",
  doi       = "10.1038/nature07385",
  pmc       = "PMC2671642"
}

@ARTICLE{Szczurek2014-dh,
  title    = "Modeling mutual exclusivity of cancer mutations",
  author   = "Szczurek, Ewa and Beerenwinkel, Niko",
  abstract = "In large collections of tumor samples, it has been observed that
              sets of genes that are commonly involved in the same cancer
              pathways tend not to occur mutated together in the same patient.
              Such gene sets form mutually exclusive patterns of gene
              alterations in cancer genomic data. Computational approaches that
              detect mutually exclusive gene sets, rank and test candidate
              alteration patterns by rewarding the number of samples the
              pattern covers and by punishing its impurity, i.e., additional
              alterations that violate strict mutual exclusivity. However, the
              extant approaches do not account for possible observation errors.
              In practice, false negatives and especially false positives can
              severely bias evaluation and ranking of alteration patterns. To
              address these limitations, we develop a fully probabilistic,
              generative model of mutual exclusivity, explicitly taking
              coverage, impurity, as well as error rates into account, and
              devise efficient algorithms for parameter estimation and pattern
              ranking. Based on this model, we derive a statistical test of
              mutual exclusivity by comparing its likelihood to the null model
              that assumes independent gene alterations. Using extensive
              simulations, the new test is shown to be more powerful than a
              permutation test applied previously. When applied to detect
              mutual exclusivity patterns in glioblastoma and in pan-cancer
              data from twelve tumor types, we identify several significant
              patterns that are biologically relevant, most of which would not
              be detected by previous approaches. Our statistical modeling
              framework of mutual exclusivity provides increased flexibility
              and power to detect cancer pathways from genomic alteration data
              in the presence of noise. A summary of this paper appears in the
              proceedings of the RECOMB 2014 conference, April 2-5.",
  journal  = "PLoS Comput. Biol.",
  volume   =  10,
  number   =  3,
  pages    = "e1003503",
  month    =  mar,
  year     =  2014,
  keywords = "Bio-med;ML",
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "24675718",
  doi      = "10.1371/journal.pcbi.1003503",
  pmc      = "PMC3967923"
}

@ARTICLE{Leiserson2013-da,
  title    = "Simultaneous identification of multiple driver pathways in cancer",
  author   = "Leiserson, Mark D M and Blokh, Dima and Sharan, Roded and
              Raphael, Benjamin J",
  abstract = "Distinguishing the somatic mutations responsible for cancer
              (driver mutations) from random, passenger mutations is a key
              challenge in cancer genomics. Driver mutations generally target
              cellular signaling and regulatory pathways consisting of multiple
              genes. This heterogeneity complicates the identification of
              driver mutations by their recurrence across samples, as different
              combinations of mutations in driver pathways are observed in
              different samples. We introduce the Multi-Dendrix algorithm for
              the simultaneous identification of multiple driver pathways de
              novo in somatic mutation data from a cohort of cancer samples.
              The algorithm relies on two combinatorial properties of mutations
              in a driver pathway: high coverage and mutual exclusivity. We
              derive an integer linear program that finds set of mutations
              exhibiting these properties. We apply Multi-Dendrix to somatic
              mutations from glioblastoma, breast cancer, and lung cancer
              samples. Multi-Dendrix identifies sets of mutations in genes that
              overlap with known pathways - including Rb, p53, PI(3)K, and cell
              cycle pathways - and also novel sets of mutually exclusive
              mutations, including mutations in several transcription factors
              or other genes involved in transcriptional regulation. These sets
              are discovered directly from mutation data with no prior
              knowledge of pathways or gene interactions. We show that
              Multi-Dendrix outperforms other algorithms for identifying
              combinations of mutations and is also orders of magnitude faster
              on genome-scale data. Software available at:
              http://compbio.cs.brown.edu/software.",
  journal  = "PLoS Comput. Biol.",
  volume   =  9,
  number   =  5,
  pages    = "e1003054",
  month    =  "23~" # may,
  year     =  2013,
  keywords = "Bio-med;ML",
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "23717195",
  doi      = "10.1371/journal.pcbi.1003054",
  pmc      = "PMC3662702"
}

@ARTICLE{Leiserson2015-yk,
  title     = "{CoMEt}: a statistical approach to identify combinations of
               mutually exclusive alterations in cancer",
  author    = "Leiserson, Mark D M and Wu, Hsin-Ta and Vandin, Fabio and
               Raphael, Benjamin J",
  abstract  = "Cancer is a heterogeneous disease with different combinations of
               genetic alterations driving its development in different
               individuals. We introduce CoMEt, an algorithm to identify
               combinations of alterations that exhibit a pattern of mutual
               exclusivity across individuals, often observed for alterations
               in the same pathway. CoMEt includes an exact statistical test
               for mutual exclusivity and techniques to perform simultaneous
               analysis of multiple sets of mutually exclusive and
               subtype-specific alterations. We demonstrate that CoMEt
               outperforms existing approaches on simulated and real data. We
               apply CoMEt to five different cancer types, identifying both
               known cancer genes and pathways, and novel putative cancer
               genes.",
  journal   = "Genome Biol.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  16,
  number    =  1,
  pages     = "160",
  month     =  "8~" # aug,
  year      =  2015,
  keywords  = "Bio-med;ML",
  copyright = "http://creativecommons.org/licenses/by/4.0/",
  language  = "en",
  issn      = "1474-7596, 1474-760X",
  pmid      = "26253137",
  doi       = "10.1186/s13059-015-0700-7",
  pmc       = "PMC4531541"
}

@ARTICLE{Aure2013-je,
  title    = "Identifying in-trans process associated genes in breast cancer by
              integrated analysis of copy number and expression data",
  author   = "Aure, Miriam Ragle and Steinfeld, Israel and Baumbusch, Lars
              Oliver and Liest{\o}l, Knut and Lipson, Doron and Nyberg, Sandra
              and Naume, Bj{\o}rn and Sahlberg, Kristine Kleivi and Kristensen,
              Vessela N and B{\o}rresen-Dale, Anne-Lise and Lingj{\ae}rde, Ole
              Christian and Yakhini, Zohar",
  abstract = "Genomic copy number alterations are common in cancer. Finding the
              genes causally implicated in oncogenesis is challenging because
              the gain or loss of a chromosomal region may affect a few key
              driver genes and many passengers. Integrative analyses have
              opened new vistas for addressing this issue. One approach is to
              identify genes with frequent copy number alterations and
              corresponding changes in expression. Several methods also analyse
              effects of transcriptional changes on known pathways. Here, we
              propose a method that analyses in-cis correlated genes for
              evidence of in-trans association to biological processes, with no
              bias towards processes of a particular type or function. The
              method aims to identify cis-regulated genes for which the
              expression correlation to other genes provides further evidence
              of a network-perturbing role in cancer. The proposed unsupervised
              approach involves a sequence of statistical tests to
              systematically narrow down the list of relevant genes, based on
              integrative analysis of copy number and gene expression data. A
              novel adjustment method handles confounding effects of
              co-occurring copy number aberrations, potentially a large source
              of false positives in such studies. Applying the method to
              whole-genome copy number and expression data from 100 primary
              breast carcinomas, 6373 genes were identified as commonly
              aberrant, 578 were highly in-cis correlated, and 56 were in
              addition associated in-trans to biological processes. Among these
              in-trans process associated and cis-correlated (iPAC) genes, 28\%
              have previously been reported as breast cancer associated, and
              64\% as cancer associated. By combining statistical evidence from
              three separate subanalyses that focus respectively on copy
              number, gene expression and the combination of the two, the
              proposed method identifies several known and novel cancer driver
              candidates. Validation in an independent data set supports the
              conclusion that the method identifies genes implicated in cancer.",
  journal  = "PLoS One",
  volume   =  8,
  number   =  1,
  pages    = "e53014",
  month    =  "30~" # jan,
  year     =  2013,
  keywords = "Bio-med;ML;Relevant",
  language = "en",
  issn     = "1932-6203",
  pmid     = "23382830",
  doi      = "10.1371/journal.pone.0053014",
  pmc      = "PMC3559658"
}

@ARTICLE{Vandin2012-ns,
  title    = "Discovery of mutated subnetworks associated with clinical data in
              cancer",
  author   = "Vandin, Fabio and Clay, Patrick and Upfal, Eli and Raphael,
              Benjamin J",
  abstract = "A major goal of cancer sequencing projects is to identify genetic
              alterations that determine clinical phenotypes, such as survival
              time or drug response. Somatic mutations in cancer are typically
              very diverse, and are found in different sets of genes in
              different patients. This mutational heterogeneity complicates the
              discovery of associations between individual mutations and a
              clinical phenotype. This mutational heterogeneity is explained in
              part by the fact that driver mutations, the somatic mutations
              that drive cancer development, target genes in cellular pathways,
              and only a subset of pathway genes is mutated in a given patient.
              Thus, pathway-based analysis of associations between mutations
              and phenotype are warranted. Here, we introduce an algorithm to
              find groups of genes, or pathways, whose mutational status is
              associated to a clinical phenotype without prior definition of
              the pathways. Rather, we find subnetworks of genes in an gene
              interaction network with the property that the mutational status
              of the genes in the subnetwork are significantly associated with
              a clinical phenotype. This new algorithm is built upon HotNet, an
              algorithm that finds groups of mutated genes using a heat
              diffusion model and a two-stage statistical test. We focus here
              on discovery of statistically significant correlations between
              mutated subnetworks and patient survival data. A similar approach
              can be used for correlations with other types of clinical data,
              through use of an appropriate statistical test. We apply our
              method to simulated data as well as to mutation and survival data
              from ovarian cancer samples from The Cancer Genome Atlas. In the
              TCGA data, we discover nine subnetworks containing genes whose
              mutational status is correlated with survival. Genes in four of
              these subnetworks overlap known pathways, including the focal
              adhesion and cell adhesion pathways, while other subnetworks are
              novel.",
  journal  = "Pac. Symp. Biocomput.",
  pages    = "55--66",
  year     =  2012,
  keywords = "Bio-med;ML",
  language = "en",
  issn     = "2335-6936, 2335-6928",
  pmid     = "22174262",
  doi      = "10.1142/9789814366496\_0006"
}

@MISC{Tcga2018-sj,
  title        = "The Cancer Genome Atlas Program",
  booktitle    = "Cancer Gov",
  author       = "{tcga}",
  abstract     = "The Cancer Genome Atlas (TCGA) is a landmark cancer genomics
                  program that sequenced and molecularly characterized over
                  11,000 cases of primary cancer samples. Learn more about how
                  the program transformed the cancer research community and
                  beyond.",
  year         =  2018,
  howpublished = "\url{https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga}",
  note         = "Accessed: 2021-5-12",
  keywords     = "Bio-med;Relevant;Transcriptomics"
}

@ARTICLE{Damrauer2014-tc,
  title    = "Intrinsic subtypes of high-grade bladder cancer reflect the
              hallmarks of breast cancer biology",
  author   = "Damrauer, Jeffrey S and Hoadley, Katherine A and Chism, David D
              and Fan, Cheng and Tiganelli, Christopher J and Wobker, Sara E
              and Yeh, Jen Jen and Milowsky, Matthew I and Iyer, Gopa and
              Parker, Joel S and Kim, William Y",
  abstract = "We sought to define whether there are intrinsic molecular
              subtypes of high-grade bladder cancer. Consensus clustering
              performed on gene expression data from a meta-dataset of
              high-grade, muscle-invasive bladder tumors identified two
              intrinsic, molecular subsets of high-grade bladder cancer, termed
              ``luminal'' and ``basal-like,'' which have characteristics of
              different stages of urothelial differentiation, reflect the
              luminal and basal-like molecular subtypes of breast cancer, and
              have clinically meaningful differences in outcome. A gene set
              predictor, bladder cancer analysis of subtypes by gene expression
              (BASE47) was defined by prediction analysis of microarrays (PAM)
              and accurately classifies the subtypes. Our data demonstrate that
              there are at least two molecularly and clinically distinct
              subtypes of high-grade bladder cancer and validate the BASE47 as
              a subtype predictor. Future studies exploring the predictive
              value of the BASE47 subtypes for standard of care bladder cancer
              therapies, as well as novel subtype-specific therapies, will be
              of interest.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  111,
  number   =  8,
  pages    = "3110--3115",
  month    =  "25~" # feb,
  year     =  2014,
  keywords = "consens;Consensus",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "24520177",
  doi      = "10.1073/pnas.1318376111",
  pmc      = "PMC3939870"
}

@ARTICLE{Lawrence2013-pl,
  title    = "Mutational heterogeneity in cancer and the search for new
              cancer-associated genes",
  author   = "Lawrence, Michael S and Stojanov, Petar and Polak, Paz and
              Kryukov, Gregory V and Cibulskis, Kristian and Sivachenko, Andrey
              and Carter, Scott L and Stewart, Chip and Mermel, Craig H and
              Roberts, Steven A and Kiezun, Adam and Hammerman, Peter S and
              McKenna, Aaron and Drier, Yotam and Zou, Lihua and Ramos, Alex H
              and Pugh, Trevor J and Stransky, Nicolas and Helman, Elena and
              Kim, Jaegil and Sougnez, Carrie and Ambrogio, Lauren and
              Nickerson, Elizabeth and Shefler, Erica and Cort{\'e}s, Maria L
              and Auclair, Daniel and Saksena, Gordon and Voet, Douglas and
              Noble, Michael and DiCara, Daniel and Lin, Pei and Lichtenstein,
              Lee and Heiman, David I and Fennell, Timothy and Imielinski,
              Marcin and Hernandez, Bryan and Hodis, Eran and Baca, Sylvan and
              Dulak, Austin M and Lohr, Jens and Landau, Dan-Avi and Wu,
              Catherine J and Melendez-Zajgla, Jorge and Hidalgo-Miranda,
              Alfredo and Koren, Amnon and McCarroll, Steven A and Mora, Jaume
              and Crompton, Brian and Onofrio, Robert and Parkin, Melissa and
              Winckler, Wendy and Ardlie, Kristin and Gabriel, Stacey B and
              Roberts, Charles W M and Biegel, Jaclyn A and Stegmaier, Kimberly
              and Bass, Adam J and Garraway, Levi A and Meyerson, Matthew and
              Golub, Todd R and Gordenin, Dmitry A and Sunyaev, Shamil and
              Lander, Eric S and Getz, Gad",
  abstract = "Major international projects are underway that are aimed at
              creating a comprehensive catalogue of all the genes responsible
              for the initiation and progression of cancer. These studies
              involve the sequencing of matched tumour-normal samples followed
              by mathematical analysis to identify those genes in which
              mutations occur more frequently than expected by random chance.
              Here we describe a fundamental problem with cancer genome
              studies: as the sample size increases, the list of putatively
              significant genes produced by current analytical methods burgeons
              into the hundreds. The list includes many implausible genes (such
              as those encoding olfactory receptors and the muscle protein
              titin), suggesting extensive false-positive findings that
              overshadow true driver events. We show that this problem stems
              largely from mutational heterogeneity and provide a novel
              analytical methodology, MutSigCV, for resolving the problem. We
              apply MutSigCV to exome sequences from 3,083 tumour-normal pairs
              and discover extraordinary variation in mutation frequency and
              spectrum within cancer types, which sheds light on mutational
              processes and disease aetiology, and in mutation frequency across
              the genome, which is strongly correlated with DNA replication
              timing and also with transcriptional activity. By incorporating
              mutational heterogeneity into the analyses, MutSigCV is able to
              eliminate most of the apparent artefactual findings and enable
              the identification of genes truly associated with cancer.",
  journal  = "Nature",
  volume   =  499,
  number   =  7457,
  pages    = "214--218",
  month    =  "11~" # jul,
  year     =  2013,
  keywords = "Bio-med;ML",
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "23770567",
  doi      = "10.1038/nature12213",
  pmc      = "PMC3919509"
}

@ARTICLE{Caravagna2016-vw,
  title    = "Algorithmic methods to infer the evolutionary trajectories in
              cancer progression",
  author   = "Caravagna, Giulio and Graudenzi, Alex and Ramazzotti, Daniele and
              Sanz-Pamplona, Rebeca and De Sano, Luca and Mauri, Giancarlo and
              Moreno, Victor and Antoniotti, Marco and Mishra, Bud",
  abstract = "The genomic evolution inherent to cancer relates directly to a
              renewed focus on the voluminous next-generation sequencing data
              and machine learning for the inference of explanatory models of
              how the (epi)genomic events are choreographed in cancer
              initiation and development. However, despite the increasing
              availability of multiple additional -omics data, this quest has
              been frustrated by various theoretical and technical hurdles,
              mostly stemming from the dramatic heterogeneity of the disease.
              In this paper, we build on our recent work on the ``selective
              advantage'' relation among driver mutations in cancer progression
              and investigate its applicability to the modeling problem at the
              population level. Here, we introduce PiCnIc (Pipeline for Cancer
              Inference), a versatile, modular, and customizable pipeline to
              extract ensemble-level progression models from cross-sectional
              sequenced cancer genomes. The pipeline has many translational
              implications because it combines state-of-the-art techniques for
              sample stratification, driver selection, identification of
              fitness-equivalent exclusive alterations, and progression model
              inference. We demonstrate PiCnIc's ability to reproduce much of
              the current knowledge on colorectal cancer progression as well as
              to suggest novel experimentally verifiable hypotheses.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  113,
  number   =  28,
  pages    = "E4025--34",
  month    =  "12~" # jul,
  year     =  2016,
  keywords = "Bayesian structural inference; cancer evolution; causality; next
              generation sequencing; selective advantage;Bio-med;ML",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "27357673",
  doi      = "10.1073/pnas.1520213113",
  pmc      = "PMC4948322"
}

@ARTICLE{Grzadkowski2021-bs,
  title     = "Systematic interrogation of mutation groupings reveals divergent
               downstream expression programs within key cancer genes",
  author    = "Grzadkowski, Michal R and Holly, Hannah D and Somers, Julia and
               Demir, Emek",
  abstract  = "Genes implicated in tumorigenesis often exhibit diverse sets of
               genomic variants in the tumor cohorts within which they are
               frequently mutated. For many genes, neither the transcriptomic
               effects of these variants nor their relationship to one another
               in cancer processes have been well-characterized. We sought to
               identify the downstream expression effects of these mutations
               and to determine whether this heterogeneity at the genomic level
               is reflected in a corresponding heterogeneity at the
               transcriptomic level. By applying a novel hierarchical framework
               for organizing the mutations present in a cohort along with
               machine learning pipelines trained on samples' expression
               profiles we systematically interrogated the signatures
               associated with combinations of mutations recurrent in cancer.
               This allowed us to catalogue the mutations with discernible
               downstream expression effects across a number of tumor cohorts
               as well as to uncover and characterize over a hundred cases
               where subsets of a gene's mutations are clearly divergent in
               their function from the remaining mutations of the gene. These
               findings successfully replicated across a number of disease
               contexts and were found to have clear implications for the
               delineation of cancer processes and for clinical decisions. The
               results of cataloguing the downstream effects of mutation
               subgroupings across cancer cohorts underline the importance of
               incorporating the diversity present within oncogenes in models
               designed to capture the downstream effects of their mutations.",
  journal   = "BMC Bioinformatics",
  publisher = "BioMed Central",
  volume    =  22,
  number    =  1,
  pages     = "1--34",
  month     =  "6~" # may,
  year      =  2021,
  keywords  = "Bio-med;ML",
  language  = "en",
  issn      = "1471-2105, 1471-2105",
  doi       = "10.1186/s12859-021-04147-y"
}

@ARTICLE{Bashashati2012-lk,
  title    = "{DriverNet}: uncovering the impact of somatic driver mutations on
              transcriptional networks in cancer",
  author   = "Bashashati, Ali and Haffari, Gholamreza and Ding, Jiarui and Ha,
              Gavin and Lui, Kenneth and Rosner, Jamie and Huntsman, David G
              and Caldas, Carlos and Aparicio, Samuel A and Shah, Sohrab P",
  abstract = "Simultaneous interrogation of tumor genomes and transcriptomes is
              underway in unprecedented global efforts. Yet, despite the
              essential need to separate driver mutations modulating gene
              expression networks from transcriptionally inert passenger
              mutations, robust computational methods to ascertain the impact
              of individual mutations on transcriptional networks are
              underdeveloped. We introduce a novel computational framework,
              DriverNet, to identify likely driver mutations by virtue of their
              effect on mRNA expression networks. Application to four cancer
              datasets reveals the prevalence of rare candidate driver
              mutations associated with disrupted transcriptional networks and
              a simultaneous modulation of oncogenic and metabolic networks,
              induced by copy number co-modification of adjacent oncogenic and
              metabolic drivers. DriverNet is available on Bioconductor or at
              http://compbio.bccrc.ca/software/drivernet/.",
  journal  = "Genome Biol.",
  volume   =  13,
  number   =  12,
  pages    = "R124",
  month    =  "22~" # dec,
  year     =  2012,
  keywords = "Bio-med;ML",
  language = "en",
  issn     = "1465-6906",
  pmid     = "23383675",
  doi      = "10.1186/gb-2012-13-12-r124",
  pmc      = "PMC4056374"
}

@INPROCEEDINGS{Whiteson2005-dn,
  title     = "Automatic feature selection in neuroevolution",
  booktitle = "Proceedings of the 7th annual conference on Genetic and
               evolutionary computation",
  author    = "Whiteson, Shimon and Stone, Peter and Stanley, Kenneth O and
               Miikkulainen, Risto and Kohl, Nate",
  abstract  = "Feature selection is the process of finding the set of inputs to
               a machine learning algorithm that will yield the best
               performance. Developing a way to solve this problem
               automatically would make current machine learning methods much
               more useful. Previous efforts to automate feature selection rely
               on expensive meta-learning or are applicable only when labeled
               training data is available. This paper presents a novel method
               called FS-NEAT which extends the NEAT neuroevolution method to
               automatically determine an appropriate set of inputs for the
               networks it evolves. By learning the network's inputs, topology,
               and weights simultaneously, FS-NEAT addresses the feature
               selection problem without relying on meta-learning or labeled
               data. Initial experiments in an autonomous car racing simulation
               demonstrate that FS-NEAT can learn better and faster than
               regular NEAT. In addition, the networks it evolves are smaller
               and require fewer inputs. Furthermore, FS-NEAT's performance
               remains robust even as the feature selection task it faces is
               made increasingly difficult.",
  publisher = "Association for Computing Machinery",
  pages     = "1225--1232",
  series    = "GECCO '05",
  month     =  "25~" # jun,
  year      =  2005,
  address   = "New York, NY, USA",
  keywords  = "neural networks, feature selection, genetic algorithms;EA;ML",
  location  = "Washington DC, USA",
  isbn      = "9781595930101",
  doi       = "10.1145/1068009.1068210"
}

@ARTICLE{Stanley2002-tg,
  title    = "Evolving neural networks through augmenting topologies",
  author   = "Stanley, Kenneth O and Miikkulainen, Risto",
  abstract = "An important question in neuroevolution is how to gain an
              advantage from evolving neural network topologies along with
              weights. We present a method, NeuroEvolution of Augmenting
              Topologies (NEAT), which outperforms the best fixed-topology
              method on a challenging benchmark reinforcement learning task. We
              claim that the increased efficiency is due to (1) employing a
              principled method of crossover of different topologies, (2)
              protecting structural innovation using speciation, and (3)
              incrementally growing from minimal structure. We test this claim
              through a series of ablation studies that demonstrate that each
              component is necessary to the system as a whole and to each
              other. What results is significantly faster learning. NEAT is
              also an important contribution to GAs because it shows how it is
              possible for evolution to both optimize and complexify solutions
              simultaneously, offering the possibility of evolving increasingly
              complex solutions over generations, and strengthening the analogy
              with biological evolution.",
  journal  = "Evol. Comput.",
  volume   =  10,
  number   =  2,
  pages    = "99--127",
  year     =  2002,
  keywords = "ML;EA",
  language = "en",
  issn     = "1063-6560",
  pmid     = "12180173",
  doi      = "10.1162/106365602320169811"
}

@ARTICLE{Grisci2019-xn,
  title    = "Neuroevolution as a tool for microarray gene expression pattern
              identification in cancer research",
  author   = "Grisci, Bruno Iochins and Feltes, Bruno C{\'e}sar and Dorn,
              Marcio",
  abstract = "Microarrays are still one of the major techniques employed to
              study cancer biology. However, the identification of expression
              patterns from microarray datasets is still a significant
              challenge to overcome. In this work, a new approach using
              Neuroevolution, a machine learning field that combines neural
              networks and evolutionary computation, provides aid in this
              challenge by simultaneously classifying microarray data and
              selecting the subset of more relevant genes. The main algorithm,
              FS-NEAT, was adapted by the addition of new structural operators
              designed for this high dimensional data. In addition, a rigorous
              filtering and preprocessing protocol was employed to select
              quality microarray datasets for the proposed method, selecting 13
              datasets from three different cancer types. The results show that
              Neuroevolution was able to successfully classify microarray
              samples when compared with other methods in the literature, while
              also finding subsets of genes that can be generalized for other
              algorithms and carry relevant biological information. This
              approach detected 177 genes, and 82 were validated as already
              being associated to their respective cancer types and 44 were
              associated to other types of cancer, becoming potential targets
              to be explored as cancer biomarkers. Five long non-coding RNAs
              were also detected, from which four don't have described
              functions yet. The expression patterns found are intrinsically
              related to extracellular matrix, exosomes and cell proliferation.
              The results obtained in this work could aid in unraveling the
              molecular mechanisms underlying the tumoral process and describe
              new potential targets to be explored in future works.",
  journal  = "J. Biomed. Inform.",
  volume   =  89,
  pages    = "122--133",
  month    =  jan,
  year     =  2019,
  keywords = "Cancer; FS-NEAT; Feature selection; Machine learning; Microarray;
              Neuroevolution;Bio-med;EA;ML;Transcriptomics",
  language = "en",
  issn     = "1532-0464, 1532-0480",
  pmid     = "30521855",
  doi      = "10.1016/j.jbi.2018.11.013"
}

@ARTICLE{Lones2007-sp,
  title    = "Regulatory motif discovery using a population clustering
              evolutionary algorithm",
  author   = "Lones, Michael and Tyrrell, Andy",
  abstract = "This paper describes a novel evolutionary algorithm for
              regulatory motif discovery in DNA promoter sequences. The
              algorithm uses data clustering to logically distribute the
              evolving population across the search space. Mating then takes
              place within local regions of the population, promoting overall
              solution diversity and encouraging discovery of multiple
              solutions. Experiments using synthetic data sets have
              demonstrated the algorithm's capacity to find position frequency
              matrix models of known regulatory motifs in relatively long
              promoter sequences. These experiments have also shown the
              algorithm's ability to maintain diversity during search and
              discover multiple motifs within a single population. The utility
              of the algorithm for discovering motifs in real biological data
              is demonstrated by its ability to find meaningful motifs within
              muscle-specific regulatory sequences.",
  journal  = "IEEE/ACM Trans. Comput. Biol. Bioinform.",
  volume   =  4,
  number   =  3,
  pages    = "403--414",
  month    =  jul,
  year     =  2007,
  keywords = "EA",
  language = "en",
  issn     = "1545-5963",
  pmid     = "17666760",
  doi      = "10.1109/tcbb.2007.1044"
}

@ARTICLE{Vandin2012-cf,
  title    = "De novo discovery of mutated driver pathways in cancer",
  author   = "Vandin, Fabio and Upfal, Eli and Raphael, Benjamin J",
  abstract = "Next-generation DNA sequencing technologies are enabling
              genome-wide measurements of somatic mutations in large numbers of
              cancer patients. A major challenge in the interpretation of these
              data is to distinguish functional ``driver mutations'' important
              for cancer development from random ``passenger mutations.'' A
              common approach for identifying driver mutations is to find genes
              that are mutated at significant frequency in a large cohort of
              cancer genomes. This approach is confounded by the observation
              that driver mutations target multiple cellular signaling and
              regulatory pathways. Thus, each cancer patient may exhibit a
              different combination of mutations that are sufficient to perturb
              these pathways. This mutational heterogeneity presents a problem
              for predicting driver mutations solely from their frequency of
              occurrence. We introduce two combinatorial properties, coverage
              and exclusivity, that distinguish driver pathways, or groups of
              genes containing driver mutations, from groups of genes with
              passenger mutations. We derive two algorithms, called Dendrix, to
              find driver pathways de novo from somatic mutation data. We apply
              Dendrix to analyze somatic mutation data from 623 genes in 188
              lung adenocarcinoma patients, 601 genes in 84 glioblastoma
              patients, and 238 known mutations in 1000 patients with various
              cancers. In all data sets, we find groups of genes that are
              mutated in large subsets of patients and whose mutations are
              approximately exclusive. Our Dendrix algorithms scale to
              whole-genome analysis of thousands of patients and thus will
              prove useful for larger data sets to come from The Cancer Genome
              Atlas (TCGA) and other large-scale cancer genome sequencing
              projects.",
  journal  = "Genome Res.",
  volume   =  22,
  number   =  2,
  pages    = "375--385",
  month    =  feb,
  year     =  2012,
  keywords = "Bio-med;ML;Relevant",
  language = "en",
  issn     = "1088-9051, 1549-5469",
  pmid     = "21653252",
  doi      = "10.1101/gr.120477.111",
  pmc      = "PMC3266044"
}

@ARTICLE{Mitchell2019-hv,
  title     = "Artificial intelligence hits the barrier of meaning",
  author    = "Mitchell, Melanie",
  abstract  = "Today's AI systems sorely lack the essence of human
               intelligence: Understanding the situations we experience, being
               able to grasp their meaning. The lack of humanlike understanding
               in machines is underscored by recent studies demonstrating lack
               of robustness of state-of-the-art deep-learning systems. Deeper
               networks and larger datasets alone are not likely to unlock AI's
               ``barrier of meaning''; instead the field will need to embrace
               its original roots as an interdisciplinary science of
               intelligence.",
  journal   = "Information (Basel)",
  publisher = "MDPI AG",
  volume    =  10,
  number    =  2,
  pages     = "51",
  month     =  "5~" # feb,
  year      =  2019,
  language  = "en",
  issn      = "2078-2489",
  doi       = "10.3390/info10020051"
}

@ARTICLE{Ewing2020-os,
  title    = "{GeneSetCluster}: a tool for summarizing and integrating gene-set
              analysis results",
  author   = "Ewing, Ewoud and Planell-Picola, Nuria and Jagodic, Maja and
              Gomez-Cabrero, David",
  abstract = "BACKGROUND: Gene-set analysis tools, which make use of curated
              sets of molecules grouped based on their shared functions, aim to
              identify which gene-sets are over-represented in the set of
              features that have been associated with a given trait of
              interest. Such tools are frequently used in gene-centric
              approaches derived from RNA-sequencing or microarrays such as
              Ingenuity or GSEA, but they have also been adapted for
              interval-based analysis derived from DNA methylation or
              ChIP/ATAC-sequencing. Gene-set analysis tools return, as a
              result, a list of significant gene-sets. However, while these
              results are useful for the researcher in the identification of
              major biological insights, they may be complex to interpret
              because many gene-sets have largely overlapping gene contents.
              Additionally, in many cases the result of gene-set analysis
              consists of a large number of gene-sets making it complicated to
              identify the major biological insights. RESULTS: We present
              GeneSetCluster, a novel approach which allows clustering of
              identified gene-sets, from one or multiple experiments and/or
              tools, based on shared genes. GeneSetCluster calculates a
              distance score based on overlapping gene content, which is then
              used to cluster them together and as a result, GeneSetCluster
              identifies groups of gene-sets with similar gene-set definitions
              (i.e. gene content). These groups of gene-sets can aid the
              researcher to focus on such groups for biological
              interpretations. CONCLUSIONS: GeneSetCluster is a novel approach
              for grouping together post gene-set analysis results based on
              overlapping gene content. GeneSetCluster is implemented as a
              package in R. The package and the vignette can be downloaded at
              https://github.com/TranslationalBioinformaticsUnit.",
  journal  = "BMC Bioinformatics",
  volume   =  21,
  number   =  1,
  pages    = "443",
  month    =  "7~" # oct,
  year     =  2020,
  keywords = "Clustering gene-sets; Clustering pathways; Data-mining; Gene-set
              enrichment; Overlapping pathways;Bio-med;ML",
  language = "en",
  issn     = "1471-2105",
  pmid     = "33028195",
  doi      = "10.1186/s12859-020-03784-z",
  pmc      = "PMC7542881"
}

@ARTICLE{Xie2021-al,
  title    = "Popularity and performance of bioinformatics software: the case
              of gene set analysis",
  author   = "Xie, Chengshu and Jauhari, Shaurya and Mora, Antonio",
  abstract = "BACKGROUND: Gene Set Analysis (GSA) is arguably the method of
              choice for the functional interpretation of omics results. The
              following paper explores the popularity and the performance of
              all the GSA methodologies and software published during the 20
              years since its inception. ``Popularity'' is estimated according
              to each paper's citation counts, while ``performance'' is based
              on a comprehensive evaluation of the validation strategies used
              by papers in the field, as well as the consolidated results from
              the existing benchmark studies. RESULTS: Regarding popularity,
              data is collected into an online open database (``GSARefDB'')
              which allows browsing bibliographic and method-descriptive
              information from 503 GSA paper references; regarding performance,
              we introduce a repository of jupyter workflows and shiny apps for
              automated benchmarking of GSA methods (``GSA-BenchmarKING'').
              After comparing popularity versus performance, results show
              discrepancies between the most popular and the best performing
              GSA methods. CONCLUSIONS: The above-mentioned results call our
              attention towards the nature of the tool selection procedures
              followed by researchers and raise doubts regarding the quality of
              the functional interpretation of biological datasets in current
              biomedical studies. Suggestions for the future of the functional
              interpretation field are made, including strategies for education
              and discussion of GSA tools, better validation and benchmarking
              practices, reproducibility, and functional re-analysis of
              previously reported data.",
  journal  = "BMC Bioinformatics",
  volume   =  22,
  number   =  1,
  pages    = "191",
  month    =  "15~" # apr,
  year     =  2021,
  keywords = "Benchmark; GSEA; Gene set analysis; Pathway analysis;Bio-med;ML",
  language = "en",
  issn     = "1471-2105",
  pmid     = "33858350",
  doi      = "10.1186/s12859-021-04124-5",
  pmc      = "PMC8050894"
}

@ARTICLE{Ciriello2012-hi,
  title    = "Mutual exclusivity analysis identifies oncogenic network modules",
  author   = "Ciriello, Giovanni and Cerami, Ethan and Sander, Chris and
              Schultz, Nikolaus",
  abstract = "Although individual tumors of the same clinical type have
              surprisingly diverse genomic alterations, these events tend to
              occur in a limited number of pathways, and alterations that
              affect the same pathway tend to not co-occur in the same patient.
              While pathway analysis has been a powerful tool in cancer
              genomics, our knowledge of oncogenic pathway modules is
              incomplete. To systematically identify such modules, we have
              developed a novel method, Mutual Exclusivity Modules in cancer
              (MEMo). The method uses correlation analysis and statistical
              tests to identify network modules by three criteria: (1) Member
              genes are recurrently altered across a set of tumor samples; (2)
              member genes are known to or are likely to participate in the
              same biological process; and (3) alteration events within the
              modules are mutually exclusive. Applied to data from the Cancer
              Genome Atlas (TCGA), the method identifies the principal known
              altered modules in glioblastoma (GBM) and highlights the striking
              mutual exclusivity of genomic alterations in the PI(3)K, p53, and
              Rb pathways. In serous ovarian cancer, we make the novel
              observation that inactivation of BRCA1 and BRCA2 is mutually
              exclusive of amplification of CCNE1 and inactivation of RB1,
              suggesting distinct alternative causes of genomic instability in
              this cancer type; and, we identify RBBP8 as a candidate oncogene
              involved in Rb-mediated cell cycle control. When applied to any
              cancer genomics data set, the algorithm can nominate oncogenic
              alterations that have a particularly strong selective effect and
              may also be useful in the design of therapeutic combinations in
              cases where mutual exclusivity reflects synthetic lethality.",
  journal  = "Genome Res.",
  volume   =  22,
  number   =  2,
  pages    = "398--406",
  month    =  feb,
  year     =  2012,
  keywords = "Bio-med;ML",
  language = "en",
  issn     = "1088-9051, 1549-5469",
  pmid     = "21908773",
  doi      = "10.1101/gr.125567.111",
  pmc      = "PMC3266046"
}

@ARTICLE{Cerami2010-ei,
  title    = "Automated network analysis identifies core pathways in
              glioblastoma",
  author   = "Cerami, Ethan and Demir, Emek and Schultz, Nikolaus and Taylor,
              Barry S and Sander, Chris",
  abstract = "BACKGROUND: Glioblastoma multiforme (GBM) is the most common and
              aggressive type of brain tumor in humans and the first cancer
              with comprehensive genomic profiles mapped by The Cancer Genome
              Atlas (TCGA) project. A central challenge in large-scale genome
              projects, such as the TCGA GBM project, is the ability to
              distinguish cancer-causing ``driver'' mutations from passively
              selected ``passenger'' mutations. PRINCIPAL FINDINGS: In contrast
              to a purely frequency based approach to identifying driver
              mutations in cancer, we propose an automated network-based
              approach for identifying candidate oncogenic processes and driver
              genes. The approach is based on the hypothesis that cellular
              networks contain functional modules, and that tumors target
              specific modules critical to their growth. Key elements in the
              approach include combined analysis of sequence mutations and DNA
              copy number alterations; use of a unified molecular interaction
              network consisting of both protein-protein interactions and
              signaling pathways; and identification and statistical assessment
              of network modules, i.e. cohesive groups of genes of interest
              with a higher density of interactions within groups than between
              groups. CONCLUSIONS: We confirm and extend the observation that
              GBM alterations tend to occur within specific functional modules,
              in spite of considerable patient-to-patient variation, and that
              two of the largest modules involve signaling via p53, Rb, PI3K
              and receptor protein kinases. We also identify new candidate
              drivers in GBM, including AGAP2/CENTG1, a putative oncogene and
              an activator of the PI3K pathway; and, three additional
              significantly altered modules, including one involved in
              microtubule organization. To facilitate the application of our
              network-based approach to additional cancer types, we make the
              method freely available as part of a software tool called NetBox.",
  journal  = "PLoS One",
  volume   =  5,
  number   =  2,
  pages    = "e8918",
  month    =  "12~" # feb,
  year     =  2010,
  language = "en",
  issn     = "1932-6203",
  pmid     = "20169195",
  doi      = "10.1371/journal.pone.0008918",
  pmc      = "PMC2820542"
}

@ARTICLE{Hou2014-se,
  title    = "{DawnRank}: discovering personalized driver genes in cancer",
  author   = "Hou, Jack P and Ma, Jian",
  abstract = "Large-scale cancer genomic studies have revealed that the genetic
              heterogeneity of the same type of cancer is greater than
              previously thought. A key question in cancer genomics is the
              identification of driver genes. Although existing methods have
              identified many common drivers, it remains challenging to predict
              personalized drivers to assess rare and even patient-specific
              mutations. We developed a new algorithm called DawnRank to
              directly prioritize altered genes on a single patient level.
              Applications to TCGA datasets demonstrated the effectiveness of
              our method. We believe DawnRank complements existing driver
              identification methods and will help us discover personalized
              causal mutations that would otherwise be obscured by tumor
              heterogeneity. Source code can be accessed at
              http://bioen-compbio.bioen.illinois.edu/DawnRank/.",
  journal  = "Genome Med.",
  volume   =  6,
  number   =  7,
  pages    = "56",
  month    =  "31~" # jul,
  year     =  2014,
  keywords = "Bio-med;ML",
  language = "en",
  issn     = "1756-994X",
  pmid     = "25177370",
  doi      = "10.1186/s13073-014-0056-8",
  pmc      = "PMC4148527"
}

@ARTICLE{Zhao2012-wj,
  title    = "Efficient methods for identifying mutated driver pathways in
              cancer",
  author   = "Zhao, Junfei and Zhang, Shihua and Wu, Ling-Yun and Zhang,
              Xiang-Sun",
  abstract = "MOTIVATION: The first step for clinical diagnostics, prognostics
              and targeted therapeutics of cancer is to comprehensively
              understand its molecular mechanisms. Large-scale cancer genomics
              projects are providing a large volume of data about genomic,
              epigenomic and gene expression aberrations in multiple cancer
              types. One of the remaining challenges is to identify driver
              mutations, driver genes and driver pathways promoting cancer
              proliferation and filter out the unfunctional and passenger ones.
              RESULTS: In this study, we propose two methods to solve the
              so-called maximum weight submatrix problem, which is designed to
              de novo identify mutated driver pathways from mutation data in
              cancer. The first one is an exact method that can be helpful for
              assessing other approximate or/and heuristic algorithms. The
              second one is a stochastic and flexible method that can be
              employed to incorporate other types of information to improve the
              first method. Particularly, we propose an integrative model to
              combine mutation and expression data. We first apply our methods
              onto simulated data to show their efficiency. We further apply
              the proposed methods onto several real biological datasets, such
              as the mutation profiles of 74 head and neck squamous cell
              carcinomas samples, 90 glioblastoma tumor samples and 313 ovarian
              carcinoma samples. The gene expression profiles were also
              considered for the later two data. The results show that our
              integrative model can identify more biologically relevant gene
              sets. We have implemented all these methods and made a package
              called mutated driver pathway finder, which can be easily used
              for other researchers. AVAILABILITY: A MATLAB package of
              MDPFinder is available at http://zhangroup.aporc.org/ShiHuaZhang.
              CONTACT: zsh@amss.ac.cn. SUPPLEMENTARY INFORMATION: Supplementary
              data are available at Bioinformatics online.",
  journal  = "Bioinformatics",
  volume   =  28,
  number   =  22,
  pages    = "2940--2947",
  month    =  "15~" # nov,
  year     =  2012,
  keywords = "Bio-med;EA;ML;Transcriptomics ;Relevant",
  language = "en",
  issn     = "1367-4803, 1367-4811",
  pmid     = "22982574",
  doi      = "10.1093/bioinformatics/bts564"
}

@ARTICLE{Fang2012-vr,
  title    = "A network-based gene-weighting approach for pathway analysis",
  author   = "Fang, Zhaoyuan and Tian, Weidong and Ji, Hongbin",
  abstract = "Classical algorithms aiming at identifying biological pathways
              significantly related to studying conditions frequently reduced
              pathways to gene sets, with an obvious ignorance of the
              constitutive non-equivalence of various genes within a defined
              pathway. We here designed a network-based method to determine
              such non-equivalence in terms of gene weights. The gene weights
              determined are biologically consistent and robust to network
              perturbations. By integrating the gene weights into the classical
              gene set analysis, with a subsequent correction for the
              ``over-counting'' bias associated with multi-subunit proteins, we
              have developed a novel gene-weighed pathway analysis approach, as
              implemented in an R package called ``Gene Associaqtion
              Network-based Pathway Analysis'' (GANPA). Through analysis of
              several microarray datasets, including the p53 dataset, asthma
              dataset and three breast cancer datasets, we demonstrated that
              our approach is biologically reliable and reproducible, and
              therefore helpful for microarray data interpretation and
              hypothesis generation.",
  journal  = "Cell Res.",
  volume   =  22,
  number   =  3,
  pages    = "565--580",
  month    =  mar,
  year     =  2012,
  keywords = "Bio-med;ML",
  language = "en",
  issn     = "1001-0602, 1748-7838",
  pmid     = "21894192",
  doi      = "10.1038/cr.2011.149",
  pmc      = "PMC3292304"
}

@ARTICLE{Dong2016-zs,
  title    = "{LEGO}: a novel method for gene set over-representation analysis
              by incorporating network-based gene weights",
  author   = "Dong, Xinran and Hao, Yun and Wang, Xiao and Tian, Weidong",
  abstract = "Pathway or gene set over-representation analysis (ORA) has become
              a routine task in functional genomics studies. However, currently
              widely used ORA tools employ statistical methods such as Fisher's
              exact test that reduce a pathway into a list of genes, ignoring
              the constitutive functional non-equivalent roles of genes and the
              complex gene-gene interactions. Here, we develop a novel method
              named LEGO (functional Link Enrichment of Gene Ontology or gene
              sets) that takes into consideration these two types of
              information by incorporating network-based gene weights in ORA
              analysis. In three benchmarks, LEGO achieves better performance
              than Fisher and three other network-based methods. To further
              evaluate LEGO's usefulness, we compare LEGO with five gene
              expression-based and three pathway topology-based methods using a
              benchmark of 34 disease gene expression datasets compiled by a
              recent publication, and show that LEGO is among the top-ranked
              methods in terms of both sensitivity and prioritization for
              detecting target KEGG pathways. In addition, we develop a
              cluster-and-filter approach to reduce the redundancy among the
              enriched gene sets, making the results more interpretable to
              biologists. Finally, we apply LEGO to two lists of autism genes,
              and identify relevant gene sets to autism that could not be found
              by Fisher.",
  journal  = "Sci. Rep.",
  volume   =  6,
  pages    = "18871",
  month    =  "11~" # jan,
  year     =  2016,
  keywords = "Bio-med;ML",
  language = "en",
  issn     = "2045-2322",
  pmid     = "26750448",
  doi      = "10.1038/srep18871",
  pmc      = "PMC4707541"
}

@ARTICLE{Neapolitan2015-dt,
  title     = "Pan-cancer analysis of {TCGA} data reveals notable signaling
               pathways",
  author    = "Neapolitan, Richard and Horvath, Curt M and Jiang, Xia",
  abstract  = "BACKGROUND: A signal transduction pathway (STP) is a network of
               intercellular information flow initiated when extracellular
               signaling molecules bind to cell-surface receptors. Many
               aberrant STPs have been associated with various cancers. To
               develop optimal treatments for cancer patients, it is important
               to discover which STPs are implicated in a cancer or
               cancer-subtype. The Cancer Genome Atlas (TCGA) makes available
               gene expression level data on cases and controls in ten
               different types of cancer including breast cancer, colon
               adenocarcinoma, glioblastoma, kidney renal papillary cell
               carcinoma, low grade glioma, lung adenocarcinoma, lung squamous
               cell carcinoma, ovarian carcinoma, rectum adenocarcinoma, and
               uterine corpus endometriod carcinoma. Signaling Pathway Impact
               Analysis (SPIA) is a software package that analyzes gene
               expression data to identify whether a pathway is relevant in a
               given condition. METHODS: We present the results of a study that
               uses SPIA to investigate all 157 signaling pathways in the KEGG
               PATHWAY database. We analyzed each of the ten cancer types
               mentioned above separately, and we perform a pan-cancer analysis
               by grouping the data for all the cancer types. RESULTS: In each
               analysis several pathways were found to be markedly more
               significant than all the other pathways. We call them notable.
               Research has already established a connection between many of
               these pathways and the corresponding cancer type. However, some
               of our discovered pathways appear to be new findings. Altogether
               there were 37 notable findings in the separate analyses, 26 of
               them occurred in 7 pathways. These 7 pathways included the 4
               notable pathways discovered in the pan-cancer analysis. So, our
               results suggest that these 7 pathways account for much of the
               mechanisms of cancer. Furthermore, by looking at the overlap
               among pathways, we identified possible regions on the pathways
               where the aberrant activity is occurring. CONCLUSIONS: We
               obtained 37 notable findings concerning 18 pathways. Some of
               them appear to be new discoveries. Furthermore, we identified
               regions on pathways where the aberrant activity might be
               occurring. We conclude that our results will prove to be
               valuable to cancer researchers because they provide many
               opportunities for laboratory and clinical follow-up studies.",
  journal   = "BMC Cancer",
  publisher = "Springer Nature",
  volume    =  15,
  number    =  1,
  pages     = "516",
  month     =  "14~" # jul,
  year      =  2015,
  keywords  = "Bio-med;Transcriptomics ;Relevant",
  language  = "en",
  issn      = "1471-2407",
  pmid      = "26169172",
  doi       = "10.1186/s12885-015-1484-6",
  pmc       = "PMC4501083"
}

@ARTICLE{Cava2018-rv,
  title    = "Integration of multiple networks and pathways identifies cancer
              driver genes in pan-cancer analysis",
  author   = "Cava, Claudia and Bertoli, Gloria and Colaprico, Antonio and
              Olsen, Catharina and Bontempi, Gianluca and Castiglioni, Isabella",
  abstract = "BACKGROUND: Modern high-throughput genomic technologies represent
              a comprehensive hallmark of molecular changes in pan-cancer
              studies. Although different cancer gene signatures have been
              revealed, the mechanism of tumourigenesis has yet to be
              completely understood. Pathways and networks are important tools
              to explain the role of genes in functional genomic studies.
              However, few methods consider the functional non-equal roles of
              genes in pathways and the complex gene-gene interactions in a
              network. RESULTS: We present a novel method in pan-cancer
              analysis that identifies de-regulated genes with a functional
              role by integrating pathway and network data. A pan-cancer
              analysis of 7158 tumour/normal samples from 16 cancer types
              identified 895 genes with a central role in pathways and
              de-regulated in cancer. Comparing our approach with 15 current
              tools that identify cancer driver genes, we found that 35.6\% of
              the 895 genes identified by our method have been found as cancer
              driver genes with at least 2/15 tools. Finally, we applied a
              machine learning algorithm on 16 independent GEO cancer datasets
              to validate the diagnostic role of cancer driver genes for each
              cancer. We obtained a list of the top-ten cancer driver genes for
              each cancer considered in this study. CONCLUSIONS: Our analysis
              1) confirmed that there are several known cancer driver genes in
              common among different types of cancer, 2) highlighted that
              cancer driver genes are able to regulate crucial pathways.",
  journal  = "BMC Genomics",
  volume   =  19,
  number   =  1,
  pages    = "25",
  month    =  "6~" # jan,
  year     =  2018,
  keywords = "Genes; Multi-networks; Pan-cancer; Pathways;Bio-med;ML",
  language = "en",
  issn     = "1471-2164",
  pmid     = "29304754",
  doi      = "10.1186/s12864-017-4423-x",
  pmc      = "PMC5756345"
}

@ARTICLE{Palazzo2019-hx,
  title    = "A pan-cancer somatic mutation embedding using autoencoders",
  author   = "Palazzo, Martin and Beauseroy, Pierre and Yankilevich, Patricio",
  abstract = "BACKGROUND: Next generation sequencing instruments are providing
              new opportunities for comprehensive analyses of cancer genomes.
              The increasing availability of tumor data allows to research the
              complexity of cancer disease with machine learning methods. The
              large available repositories of high dimensional tumor samples
              characterised with germline and somatic mutation data requires
              advance computational modelling for data interpretation. In this
              work, we propose to analyze this complex data with neural network
              learning, a methodology that made impressive advances in image
              and natural language processing. RESULTS: Here we present a tumor
              mutation profile analysis pipeline based on an autoencoder model,
              which is used to discover better representations of lower
              dimensionality from large somatic mutation data of 40 different
              tumor types and subtypes. Kernel learning with hierarchical
              cluster analysis are used to assess the quality of the learned
              somatic mutation embedding, on which support vector machine
              models are used to accurately classify tumor subtypes.
              CONCLUSIONS: The learned latent space maps the original samples
              in a much lower dimension while keeping the biological signals
              from the original tumor samples. This pipeline and the resulting
              embedding allows an easier exploration of the heterogeneity
              within and across tumor types and to perform an accurate
              classification of tumor samples in the pan-cancer somatic
              mutation landscape.",
  journal  = "BMC Bioinformatics",
  volume   =  20,
  number   =  1,
  pages    = "655",
  month    =  "11~" # dec,
  year     =  2019,
  keywords = "Autoencoder; Cancer genomics; Kernel learning;Bio-med;ML",
  language = "en",
  issn     = "1471-2105",
  pmid     = "31829157",
  doi      = "10.1186/s12859-019-3298-z",
  pmc      = "PMC6907172"
}

@ARTICLE{Gonzalez-Reymundez2020-az,
  title    = "Multi-omic signatures identify pan-cancer classes of tumors
              beyond tissue of origin",
  author   = "Gonz{\'a}lez-Reym{\'u}ndez, Agust{\'\i}n and V{\'a}zquez, Ana I",
  abstract = "Despite recent advances in treatment, cancer continues to be one
              of the most lethal human maladies. One of the challenges of
              cancer treatment is the diversity among similar tumors that
              exhibit different clinical outcomes. Most of this variability
              comes from wide-spread molecular alterations that can be
              summarized by omic integration. Here, we have identified eight
              novel tumor groups (C1-8) via omic integration, characterized by
              unique cancer signatures and clinical characteristics. C3 had the
              best clinical outcomes, while C2 and C5 had poorest. C1, C7, and
              C8 were upregulated for cellular and mitochondrial translation,
              and relatively low proliferation. C6 and C4 were also
              downregulated for cellular and mitochondrial translation, and had
              high proliferation rates. C4 was represented by copy losses on
              chromosome 6, and had the highest number of metastatic samples.
              C8 was characterized by copy losses on chromosome 11, having also
              the lowest lymphocytic infiltration rate. C6 had the lowest
              natural killer infiltration rate and was represented by copy
              gains of genes in chromosome 11. C7 was represented by copy gains
              on chromosome 6, and had the highest upregulation in
              mitochondrial translation. We believe that, since molecularly
              alike tumors could respond similarly to treatment, our results
              could inform therapeutic action.",
  journal  = "Sci. Rep.",
  volume   =  10,
  number   =  1,
  pages    = "8341",
  month    =  "20~" # may,
  year     =  2020,
  keywords = "Bio-med;Transcriptomics",
  language = "en",
  issn     = "2045-2322",
  pmid     = "32433524",
  doi      = "10.1038/s41598-020-65119-5",
  pmc      = "PMC7239905"
}

@ARTICLE{Zamanighomi2018-qz,
  title     = "Unsupervised clustering and epigenetic classification of single
               cells",
  author    = "Zamanighomi, Mahdi and Lin, Zhixiang and Daley, Timothy and
               Chen, Xi and Duren, Zhana and Schep, Alicia and Greenleaf,
               William J and Wong, Wing Hung",
  abstract  = "Characterizing epigenetic heterogeneity at the cellular level is
               a critical problem in the modern genomics era. Assays such as
               single cell ATAC-seq (scATAC-seq) offer an opportunity to
               interrogate cellular level epigenetic heterogeneity through
               patterns of variability in open chromatin. However, these assays
               exhibit technical variability that complicates clear
               classification and cell type identification in heterogeneous
               populations. We present scABC, an R package for the unsupervised
               clustering of single-cell epigenetic data, to classify
               scATAC-seq data and discover regions of open chromatin specific
               to cell identity. Single cell ATAC-seq (scATAC-seq) data reveals
               cellular level epigenetic heterogeneity but its application in
               delineating distinct subpopulations is still challenging. Here,
               the authors develop scABC, a statistical method for unsupervised
               clustering of scATAC-seq data and identification of open
               chromatin regions specific to cell identity.",
  journal   = "Nat. Commun.",
  publisher = "Nature Publishing Group",
  volume    =  9,
  number    =  1,
  pages     = "1--8",
  month     =  "20~" # jun,
  year      =  2018,
  keywords  = "ML;Bio-med",
  language  = "en",
  issn      = "2041-1723, 2041-1723",
  doi       = "10.1038/s41467-018-04629-3"
}

@ARTICLE{Wu2018-mq,
  title    = "Visualizing and Interpreting {Single-Cell} Gene Expression
              Datasets with Similarity Weighted Nonnegative Embedding",
  author   = "Wu, Yan and Tamayo, Pablo and Zhang, Kun",
  abstract = "High-throughput single-cell gene expression profiling has enabled
              the definition of new cell types and developmental trajectories.
              Visualizing these datasets is crucial to biological
              interpretation, and a popular method is t-stochastic neighbor
              embedding (t-SNE), which visualizes local patterns well but
              distorts global structure, such as distances between clusters. We
              developed similarity weighted nonnegative embedding (SWNE), which
              enhances interpretation of datasets by embedding the genes and
              factors that separate cell states on the visualization alongside
              the cells and maintains fidelity when visualizing local and
              global structure for both developmental trajectories and discrete
              cell types. SWNE uses nonnegative matrix factorization to
              decompose the gene expression matrix into biologically relevant
              factors; embeds the cells, genes, and factors in a 2D
              visualization; and uses a similarity matrix to smooth the
              embeddings. We demonstrate SWNE on single-cell RNA-seq data from
              hematopoietic progenitors and human brain cells. SWNE is
              available as an R package at github.com/yanwu2014/swne.",
  journal  = "Cell Syst",
  volume   =  7,
  number   =  6,
  pages    = "656--666.e4",
  month    =  "26~" # dec,
  year     =  2018,
  keywords = "ontology embedding; single-cell analysis; transcriptome;
              visualization;Bio-med;ML",
  language = "en",
  issn     = "2405-4712",
  pmid     = "30528274",
  doi      = "10.1016/j.cels.2018.10.015",
  pmc      = "PMC6311449"
}

@ARTICLE{Chan2017-ob,
  title    = "Gene Regulatory Network Inference from {Single-Cell} Data Using
              Multivariate Information Measures",
  author   = "Chan, Thalia E and Stumpf, Michael P H and Babtie, Ann C",
  abstract = "While single-cell gene expression experiments present new
              challenges for data processing, the cell-to-cell variability
              observed also reveals statistical relationships that can be used
              by information theory. Here, we use multivariate information
              theory to explore the statistical dependencies between triplets
              of genes in single-cell gene expression datasets. We develop
              PIDC, a fast, efficient algorithm that uses partial information
              decomposition (PID) to identify regulatory relationships between
              genes. We thoroughly evaluate the performance of our algorithm
              and demonstrate that the higher-order information captured by
              PIDC allows it to outperform pairwise mutual information-based
              algorithms when recovering true relationships present in
              simulated data. We also infer gene regulatory networks from three
              experimental single-cell datasets and illustrate how network
              context, choices made during analysis, and sources of variability
              affect network inference. PIDC tutorials and open-source software
              for estimating PID are available. PIDC should facilitate the
              identification of putative functional relationships and
              mechanistic hypotheses from single-cell transcriptomic data.",
  journal  = "Cell Syst",
  volume   =  5,
  number   =  3,
  pages    = "251--267.e3",
  month    =  "27~" # sep,
  year     =  2017,
  keywords = "gene regulation; mutual information; network reconstruction;
              single-cell PCR; single-cell RNA-seq;Bio-med;ML",
  language = "en",
  issn     = "2405-4712",
  pmid     = "28957658",
  doi      = "10.1016/j.cels.2017.08.014",
  pmc      = "PMC5624513"
}

@MISC{noauthor_undated-sl,
  title    = "Molecular Biology of the {Cell\_Alberts\_6th} Edition.pdf",
  keywords = "Bio-med"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{He2020-mg,
  title    = "Integrating spatial gene expression and breast tumour morphology
              via deep learning",
  author   = "He, Bryan and Bergenstr{\aa}hle, Ludvig and Stenbeck, Linnea and
              Abid, Abubakar and Andersson, Alma and Borg, {\AA}ke and
              Maaskola, Jonas and Lundeberg, Joakim and Zou, James",
  abstract = "Spatial transcriptomics allows for the measurement of RNA
              abundance at a high spatial resolution, making it possible to
              systematically link the morphology of cellular neighbourhoods and
              spatially localized gene expression. Here, we report the
              development of a deep learning algorithm for the prediction of
              local gene expression from haematoxylin-and-eosin-stained
              histopathology images using a new dataset of 30,612 spatially
              resolved gene expression data matched to histopathology images
              from 23 patients with breast cancer. We identified over 100
              genes, including known breast cancer biomarkers of intratumoral
              heterogeneity and the co-localization of tumour growth and immune
              activation, the expression of which can be predicted from the
              histopathology images at a resolution of 100 m. We also show
              that the algorithm generalizes well to The Cancer Genome Atlas
              and to other breast cancer gene expression datasets without the
              need for re-training. Predicting the spatially resolved
              transcriptome of a tissue directly from tissue images may enable
              image-based screening for molecular biomarkers with spatial
              variation.",
  journal  = "Nat Biomed Eng",
  volume   =  4,
  number   =  8,
  pages    = "827--834",
  month    =  aug,
  year     =  2020,
  keywords = "Bio-med;ML",
  language = "en",
  issn     = "2157-846X",
  pmid     = "32572199",
  doi      = "10.1038/s41551-020-0578-x"
}

@MISC{Su2020-va,
  title    = "Mining genetic and transcriptomic data using machine learning
              approaches in Parkinson's disease",
  author   = "Su, Chang and Tong, Jie and Wang, Fei",
  journal  = "npj Parkinson's Disease",
  volume   =  6,
  number   =  1,
  year     =  2020,
  keywords = "Bio-med;ML",
  doi      = "10.1038/s41531-020-00127-w"
}

@ARTICLE{Kobak2019-fj,
  title    = "The art of using {t-SNE} for single-cell transcriptomics",
  author   = "Kobak, Dmitry and Berens, Philipp",
  abstract = "Single-cell transcriptomics yields ever growing data sets
              containing RNA expression levels for thousands of genes from up
              to millions of cells. Common data analysis pipelines include a
              dimensionality reduction step for visualising the data in two
              dimensions, most frequently performed using t-distributed
              stochastic neighbour embedding (t-SNE). It excels at revealing
              local structure in high-dimensional data, but naive applications
              often suffer from severe shortcomings, e.g. the global structure
              of the data is not represented accurately. Here we describe how
              to circumvent such pitfalls, and develop a protocol for creating
              more faithful t-SNE visualisations. It includes PCA
              initialisation, a high learning rate, and multi-scale similarity
              kernels; for very large data sets, we additionally use
              exaggeration and downsampling-based initialisation. We use
              published single-cell RNA-seq data sets to demonstrate that this
              protocol yields superior results compared to the naive
              application of t-SNE.",
  journal  = "Nat. Commun.",
  volume   =  10,
  number   =  1,
  pages    = "5416",
  month    =  "28~" # nov,
  year     =  2019,
  keywords = "Bio-med;ML;Relevant",
  language = "en",
  issn     = "2041-1723",
  pmid     = "31780648",
  doi      = "10.1038/s41467-019-13056-x",
  pmc      = "PMC6882829"
}

@ARTICLE{Saxe2021-in,
  title    = "If deep learning is the answer, what is the question?",
  author   = "Saxe, Andrew and Nelli, Stephanie and Summerfield, Christopher",
  abstract = "Neuroscience research is undergoing a minor revolution. Recent
              advances in machine learning and artificial intelligence research
              have opened up new ways of thinking about neural computation.
              Many researchers are excited by the possibility that deep neural
              networks may offer theories of perception, cognition and action
              for biological brains. This approach has the potential to
              radically reshape our approach to understanding neural systems,
              because the computations performed by deep networks are learned
              from experience, and not endowed by the researcher. If so, how
              can neuroscientists use deep networks to model and understand
              biological brains? What is the outlook for neuroscientists who
              seek to characterize computations or neural codes, or who wish to
              understand perception, attention, memory and executive functions?
              In this Perspective, our goal is to offer a road map for systems
              neuroscience research in the age of deep learning. We discuss the
              conceptual and methodological challenges of comparing behaviour,
              learning dynamics and neural representations in artificial and
              biological systems, and we highlight new research questions that
              have emerged for neuroscience as a direct consequence of recent
              advances in machine learning.",
  journal  = "Nat. Rev. Neurosci.",
  volume   =  22,
  number   =  1,
  pages    = "55--67",
  month    =  jan,
  year     =  2021,
  keywords = "Bio-med;Neuroscience / Mind",
  language = "en",
  issn     = "1471-003X, 1471-0048",
  pmid     = "33199854",
  doi      = "10.1038/s41583-020-00395-8"
}

@ARTICLE{Seminar2014-fp,
  title    = "The Next Generation Neural Networks : Deep Learning and Spiking
              Neural Networks",
  author   = "Seminar, Advanced",
  abstract = "Deep Learning and Spike Neural Networks are hot topics in
              artificial intelligence\textbackslashr\textbackslashnand human
              brain. By explaining the basic underlying blocks beneath them,
              the\textbackslashr\textbackslashnarchitectures and applications
              of both concepts are discovered.",
  year     =  2014,
  keywords = "Mendeley Import (Apr 20)"
}

@ARTICLE{Izhikevich2003-vb,
  title     = "Simple model of spiking neurons",
  author    = "Izhikevich, Eugene M",
  abstract  = "A model is presented that reproduces spiking and bursting
               behavior of known types of cortical neurons. The model combines
               the biologically plausibility of Hodgkin-Huxley-type dynamics
               and the computational efficiency of integrate-and-fire neurons.
               Using this model, one can simulate tens of thousands of spiking
               cortical neurons in real time (1 ms resolution) using a desktop
               PC.",
  journal   = "IEEE Trans. Neural Netw.",
  publisher = "IEEE",
  volume    =  14,
  number    =  6,
  pages     = "1569--1572",
  year      =  2003,
  keywords  = "Bursting; Cortex; Hodgkin-Huxley; PCNN; Quadratic
               integrate-and-fire; Spiking; Thalamus;Mendeley Import (Apr
               20)/SNN",
  issn      = "1045-9227",
  pmid      = "18244602",
  doi       = "10.1109/TNN.2003.820440"
}

@MISC{Halliday_David2017-sz,
  title        = "Year 4 Electronics for Medicine: Notes for Computational
                  Neuroscience",
  author       = "{Halliday David} and {Robinson Martin}",
  year         =  2017,
  howpublished = "\url{https://www.elec.york.ac.uk/internal_web/meng/yr4/modules/Elec_Medicine/EfM_lectureA5_mpr2017_notes.pdf}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@MISC{Brette2007-qs,
  title    = "Simulation of networks of spiking neurons: A review of tools and
              strategies",
  author   = "Brette, Romain and Rudolph, Michelle and Carnevale, Ted and
              Hines, Michael and Beeman, David and Bower, James M and Diesmann,
              Markus and Morrison, Abigail and Goodman, Philip H and Harris,
              Frederick C and Zirpe, Milind and Natschl{\"a}ger, Thomas and
              Pecevski, Dejan and Ermentrout, Bard and Djurfeldt, Mikael and
              Lansner, Anders and Rochel, Olivier and Vieville, Thierry and
              Muller, Eilif and Davison, Andrew P and El Boustani, Sami and
              Destexhe, Alain",
  abstract = "We review different aspects of the simulation of spiking neural
              networks. We start by reviewing the different types of simulation
              strategies and algorithms that are currently implemented. We next
              review the precision of those simulation strategies, in
              particular in cases where plasticity depends on the exact timing
              of the spikes. We overview different simulators and simulation
              environments presently available (restricted to those freely
              available, open source and documented). For each simulation tool,
              its advantages and pitfalls are reviewed, with an aim to allow
              the reader to identify which simulator is appropriate for a given
              task. Finally, we provide a series of benchmark simulations of
              different types of networks of spiking neurons, including
              Hodgkin-Huxley type, integrate-and-fire models, interacting with
              current-based or conductance-based synapses, using clock-driven
              or event-driven integration strategies. The same set of models
              are implemented on the different simulators, and the codes are
              made available. The ultimate goal of this review is to provide a
              resource to facilitate identifying the appropriate integration
              strategy and simulation tool to use for a given modeling problem
              related to spiking neural networks.",
  journal  = "Journal of Computational Neuroscience",
  year     =  2007,
  keywords = "Clock-driven; Event-driven; Integration strategies; Simulation
              tools; Spiking neural networks;Mendeley Import (Apr 20)/SNN",
  issn     = "0929-5313",
  pmid     = "17629781",
  arxivid  = "q-bio/0611089",
  doi      = "10.1007/s10827-007-0038-6"
}

@ARTICLE{Roberts2002-es,
  title    = "Spike timing dependent synaptic plasticity in biological systems",
  author   = "Roberts, Patrick D and Bell, Curtis C",
  abstract = "Association of a presynaptic spike with a postsynaptic spike can
              lead to changes in synaptic efficacy that are highly dependent on
              the relative timing of the pre- and postsynaptic spikes.
              Different synapses show varying forms of such spike-timing
              dependent learning rules. This review describes these different
              rules, the cellular mechanisms that may be responsible for them,
              and the computational consequences of these rules for information
              processing and storage in the nervous system.",
  journal  = "Biol. Cybern.",
  year     =  2002,
  keywords = "Mendeley Import (Apr 20)/SNN",
  issn     = "0340-1200",
  pmid     = "12461629",
  doi      = "10.1007/s00422-002-0361-y"
}

@ARTICLE{Viswanathan_undated-ul,
  title    = "Applications of Image Processing and {Real-Time} embedded Systems
              in Autonomous Cars: A Short Review",
  author   = "Viswanathan, Vidya and Hussein, Rania",
  abstract = "As many of the latest technologists have predicted, Self-driving
              autonomous cars are going to be the future in the transportation
              sector. Many of the billion dollar companies including Google,
              Uber, Apple, NVIDIA, and Tesla are pioneering in this field to
              invent fully autonomous vehicles. This paper presents a
              literature review on some of the important segments in an
              autonomous vehicle development arena which touches real time
              embedded systems applications. This paper surveyed research
              papers on the technologies used in autonomous vehicles which
              includes lane detection, traffic signal identification, and speed
              bump detection. The paper focuses on the significance of image
              processing and real time embedded systems in driving the
              automotive industry towards autonomy and high security pathways.",
  journal  = "Vidya Viswanathan \& Rania Hussein International Journal of Image
              Processing",
  number   =  112,
  pages    = "2017--2035",
  keywords = "Canny Edge; Computer Vision; Hough Transform; Image Processing;
              Open CV; Polygonal Approximation;Mendeley Import (Apr 20)/SNN"
}

@INPROCEEDINGS{Florian2005-ct,
  title     = "A reinforcement learning algorithm for spiking neural networks",
  booktitle = "Seventh International Symposium on Symbolic and Numeric
               Algorithms for Scientific Computing ({SYNASC'05})",
  author    = "Florian, R V",
  abstract  = "The paper presents a new reinforcement learning mechanism for
               spiking neural networks. The algorithm is derived for networks
               of stochastic integrate-and-fire neurons, but it can be also
               applied to generic spiking neural networks. Learning is achieved
               by synaptic changes that depend on the firing of pre- and
               postsynaptic neurons, and that are modulated with a global
               reinforcement signal. The efficacy of the algorithm is verified
               in a biologically-inspired experiment, featuring a simulated
               worm that searches for food. Our model recovers a form of neural
               plasticity experimentally observed in animals, combining
               spike-timing-dependent synaptic changes of one sign with
               non-associative synaptic changes of the opposite sign determined
               by presynaptic spikes. The model also predicts that the time
               constant of spike-timing-dependent synaptic changes is equal to
               the membrane time constant of the neuron, in agreement with
               experimental observations in the brain. This study also led to
               the discovery of a biologically-plausible reinforcement learning
               mechanism that works by modulating spike-timing-dependent
               plasticity (STDP) with a global reward signal.",
  year      =  2005,
  keywords  = "Mendeley Import (Apr 20)/SNN",
  doi       = "10.1109/SYNASC.2005.13"
}

@ARTICLE{Fager_undated-cl,
  title    = "Online {Policy-Gradient} Reinforcement Learning using {OLGARB}
              for {SpaceWar}",
  author   = "Fager, Jason",
  abstract = "The goal of this project is to explore the use of reinforcement
              learning techniques to address a difficult problem domain. The
              SpaceWar task is a competitive, continuous-valued, partially
              observable problem domain that provides a fun and interesting
              chal-lenge for machine learning algorithms. This project focuses
              on the application of online policy-gradient reinforcement
              learning tech-niques to train a neural net controller for a ship.
              This paper shows that the OLGARB algorithm is effective for
              learning obstacle avoidance strategies for SpaceWar, and
              com-pares results across several values of the main tuning
              parameter for the algorithm.",
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Sussillo2009-jj,
  title    = "Generating Coherent Patterns of Activity from Chaotic Neural
              Networks",
  author   = "Sussillo, David and Abbott, L F",
  abstract = "Neural circuits display complex activity patterns both
              spontaneously and when responding to a stimulus or generating a
              motor output. How are these two forms of activity related? We
              develop a procedure called FORCE learning for modifying synaptic
              strengths either external to or within a model neural network to
              change chaotic spontaneous activity into a wide variety of
              desired activity patterns. FORCE learning works even though the
              networks we train are spontaneously chaotic and we leave feedback
              loops intact and unclamped during learning. Using this approach,
              we construct networks that produce a wide variety of complex
              output patterns, input-output transformations that require
              memory, multiple outputs that can be switched by control inputs,
              and motor patterns matching human motion capture data. Our
              results reproduce data on premovement activity in motor and
              premotor cortex, and suggest that synaptic plasticity may be a
              more rapid and powerful modulator of network activity than
              generally appreciated. \copyright{} 2009 Elsevier Inc. All rights
              reserved.",
  journal  = "Neuron",
  year     =  2009,
  keywords = "SYSNEURO;Mendeley Import (Apr 20)/SNN",
  issn     = "0896-6273",
  pmid     = "19709635",
  arxivid  = "1406.6247",
  doi      = "10.1016/j.neuron.2009.07.018"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Orhan2012-lb,
  title    = "The Leaky {Integrate-and-Fire} Neuron Model",
  author   = "Orhan, Emin",
  abstract = "In this note, I review the behavior of a leaky integrate-and-fire
              (LIF) neuron under different stimulation conditions. I closely
              follow chapter 4.1 of Gerstner and Kistler (2002). I consider
              three different stimulation conditions below and show how each
              condition can be implemented in the Brian spiking neural network
              simulator for Python (Goodman \& Brette, 2008). Introduction: The
              leaky integrate-and-fire (LIF) neuron is probably one of the
              simplest spiking neuron models, but it is still very popular due
              to the ease with which it can be analyzed and simulated. In its
              simplest form, a neuron is modeled as a `` leaky integrator '' of
              its input I(t): $\tau$ m dv dt = v(t) + RI(t) (1)",
  year     =  2012,
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@INPROCEEDINGS{Li2015-rg,
  title     = "Lane Detection Based on Spiking Neural Network and Hough
               Transform",
  booktitle = "2015 8th International Congress on Image and Signal Processing
               ({CISP})",
  author    = "Li, Xue and Wu, Qingxiang and Kou, Yu and Hou, Lei and Yang,
               Heng",
  abstract  = "---In the field of the unmanned automobile and the automobile
               auxiliary driving system, the real-time and accurate detection
               of the lane is very important. Based on the previous research on
               the lane detection, the paper introduces the spiking neural
               network with the parallel mechanism to detect the lane. Firstly,
               the region of interests (ROI) is set on the origin image that
               collected by a vehicle on-board camera. In order to reduce
               processing time, areas outside the road are excluded in the ROI.
               Then the image preprocessing is applied to the ROI, including
               RGB to grayscale, gray stretch and median filtering to eliminate
               noise. Edge detection of the lane is the key to determine
               whether the Hough transform can detect the lane. In this paper,
               the spiking neural network is used to detect the edge of the
               lane. Finally, Hough transform is used to detect the lane.
               Experimental results show that this method is more accurate and
               robust than other methods.",
  publisher = "IEEE",
  year      =  2015,
  address   = "Shenyang, China",
  keywords  = "-lane detection; hough transform; region of intrests; spiking
               neural network;Mendeley Import (Apr 20)/SNN",
  doi       = "10.1109/CISP.2015.7407954"
}

@ARTICLE{Alemi2017-hu,
  title    = "Learning arbitrary dynamics in efficient, balanced spiking
              networks using local plasticity rules",
  author   = "Alemi, Alireza and Machens, Christian and Den{\`e}ve, Sophie and
              Slotine, Jean-Jacques",
  abstract = "Understanding how recurrent neural circuits can learn to
              implement dynamical systems is a fundamental challenge in
              neuroscience. The credit assignment problem, i.e. determining the
              local contribution of each synapse to the network's global output
              error, is a major obstacle in deriving biologically plausible
              local learning rules. Moreover, spiking recurrent networks
              implementing such tasks should not be hugely costly in terms of
              number of neurons and spikes, as they often are when adapted from
              rate models. Finally, these networks should be robust to noise
              and neural deaths in order to sustain these representations in
              the face of such naturally occurring perturbation. We approach
              this problem by fusing the theory of efficient, balanced spiking
              networks (EBN) with nonlinear adaptive control theory. Local
              learning rules are ensured by feeding back into the network its
              own error, resulting in a synaptic plasticity rule depending
              solely on presynaptic inputs and post-synaptic feedback. The
              spiking efficiency and robustness of the network are guaranteed
              by maintaining a tight excitatory/inhibitory balance, ensuring
              that each spike represents a local projection of the global
              output error and minimizes a loss function. The resulting
              networks can learn to implement complex dynamics with very small
              numbers of neurons and spikes, exhibit the same spike train
              variability as observed experimentally, and are extremely robust
              to noise and neuronal loss.",
  year     =  2017,
  keywords = "Mendeley Import (Apr 20)/SNN",
  arxivid  = "1705.08026"
}

@BOOK{Gerstner2002-xl,
  title     = "Spiking Neuron Models Single Neurons, Populations, Plasticity",
  author    = "Gerstner, Wulfram and Kistler, Werner M",
  publisher = "Cambridge University Press",
  pages     = "43--48",
  year      =  2002,
  address   = "Cambridge",
  keywords  = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Silver_undated-md,
  title    = "Lecture 2: Markov Decision Processes",
  author   = "Silver, David",
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@INPROCEEDINGS{Han2016-nz,
  title     = "On the energy benefits of spiking deep neural networks: A case
               study",
  booktitle = "Proceedings of the International Joint Conference on Neural
               Networks",
  author    = "Han, Bing and Sengupta, Abhronil and Roy, Kaushik",
  abstract  = "Deep learning neural networks have achieved success in a large
               number of visual processing tasks and are currently utilized for
               many real-world applications like image search and speech
               recognition among others. However, in spite of achieving high
               accuracy in such classification problems, they involve
               significant computational resources. Over the past few years,
               artificial neural network models have evolved into the
               biologically realistic and event-driven spiking neural networks.
               Recent research efforts have been directed at developing
               mechanisms to convert traditional deep artificial nets to
               spiking nets where the neurons communicate by means of spikes.
               However, there have been limited studies providing insights on
               the specific power, area and energy benefits offered by deep
               spiking neural nets in comparison to their non-spiking
               counterparts. In this paper, we perform a case study for a
               hardware implementation of a spiking/non-spiking deep net on the
               MNIST dataset and clearly outline the design prospects involved
               in implementing neural computing platforms in the spiking mode
               of operation.",
  volume    = "2016-Octob",
  pages     = "971--976",
  year      =  2016,
  keywords  = "Mendeley Import (Apr 20)/SNN",
  isbn      = "9781509006199",
  doi       = "10.1109/IJCNN.2016.7727303"
}

@ARTICLE{Brendel2017-fx,
  title    = "Learning to represent signals spike by spike",
  author   = "Brendel, Wieland and Bourdoukan, Ralph and Vertechi, Pietro and
              Machens, Christian K and Den{\'e}ve, Sophie",
  abstract = "A key question in neuroscience is at which level functional
              meaning emerges from biophysical phenomena. In most vertebrate
              systems, precise functions are assigned at the level of neural
              populations, while single-neurons are deemed unreliable and
              redundant. Here we challenge this view and show that many
              single-neuron quantities, including voltages, firing thresholds,
              excitation, inhibition, and spikes, acquire precise functional
              meaning whenever a network learns to transmit information
              parsimoniously and precisely to the next layer. Based on the
              hypothesis that neural circuits generate precise population codes
              under severe constraints on metabolic costs, we derive synaptic
              plasticity rules that allow a network to represent its
              time-varying inputs with maximal accuracy. We provide exact
              solutions to the learnt optimal states, and we predict the
              properties of an entire network from its input distribution and
              the cost of activity. Single-neuron variability and tuning curves
              as typically observed in cortex emerge over the course of
              learning, but paradoxically coincide with a precise,
              non-redundant spike-based population code. Our work suggests that
              neural circuits operate far more accurately than previously
              thought, and that no spike is fired in vain.",
  year     =  2017,
  keywords = "Mendeley Import (Apr 20)/SNN",
  arxivid  = "1703.03777"
}

@ARTICLE{Khademian_undated-rj,
  title    = "Practical applications of spiking neural network in information
              processing and learning",
  author   = "Khademian, Fariborz and Khanbabaie, Reza",
  abstract = "Historically, much of the research effort to contemplate the
              neural mechanisms involved in information processing in the brain
              has been spent with neuronal circuits and synaptic organization,
              basically neglecting the electrophysiological properties of the
              neurons. In this paper we present instances of a practical
              application using spiking neurons and temporal coding to process
              information, building a spiking neural network -- SNN to perform
              a clustering task. The input is encoded by means of receptive
              fields. The delay and weight adaptation uses a multiple synapse
              approach. Dividing each synapse into sub-synapses, each one with
              a different fixed delay. The delay selection is then performed by
              a Hebbian reinforcement learning algorithm, also keeping
              resemblance with biological neural networks.",
  keywords = "Information processing; Spiking neural network;Mendeley Import
              (Apr 20)/SNN"
}

@PHDTHESIS{Tim_Utz_Krause2014-lj,
  title    = "Rate Coding and Temporal Coding in a Neural Network",
  author   = "{Tim Utz Krause}",
  year     =  2014,
  school   = "Ruhr-University Bochum",
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Urbanczik2009-ll,
  title    = "Reinforcement learning in populations of spiking neurons",
  author   = "Urbanczik, Robert and Senn, Walter",
  abstract = "Population coding is widely regarded as an important mechanism
              for achieving reliable behavioral responses despite neuronal
              variability. However, standard reinforcement learning slows down
              with increasing population size, as the global reward signal
              becomes less and less related to the performance of any single
              neuron. We found that learning speeds up with increasing
              population size if, in addition to global reward, feedback about
              the population response modulates synaptic plasticity.",
  journal  = "Nat. Neurosci.",
  year     =  2009,
  keywords = "Mendeley Import (Apr 20)/SNN",
  issn     = "1097-6256",
  pmid     = "19219040",
  doi      = "10.1038/nn.2264"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Azvan_undated-um,
  title    = "{LNAI} 4095 - Spiking Neural Controllers for Pushing Objects
              Around",
  author   = "Azvan, R and Florian, V",
  abstract = "We evolve spiking neural networks that implement a
              seek-push-release drive for a simple simulated agent interacting
              with objects. The evolved agents display minimally-cognitive
              behavior, by switching as a function of context between the three
              sub-behaviors and by being able to discriminate relative object
              size. The neural controllers have either static synapses or
              synapses featuring spike-timing-dependent plasticity (STDP). Both
              types of networks are able to solve the task with similar
              efficacy, but networks with plastic synapses evolved faster. In
              the evolved networks, plasticity plays a minor role during the
              interaction with the environment and is used mostly to tune
              synapses when networks start to function.",
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@INPROCEEDINGS{Kaiser2017-qa,
  title     = "Towards a framework for end-to-end control of a simulated
               vehicle with spiking neural networks",
  booktitle = "2016 {IEEE} International Conference on Simulation, Modeling,
               and Programming for Autonomous Robots, {SIMPAR} 2016",
  author    = "Kaiser, Jacques and Tieck, J C V and Hubschneider, Christian and
               Wolf, Peter and Weber, Michael and Hoff, Michael and Friedrich,
               Alexander and Wojtasik, Konrad and Roennau, Arne and Kohlhaas,
               Ralf and Dillmann, Rudiger and Zollner, J Marius",
  abstract  = "Spiking neural networks are in theory more computationally
               powerful than rate-based neural networks often used in deep
               learning architectures. However, unlike rate-based neural
               networks, it is yet unclear how to train spiking networks to
               solve complex problems. There are still no standard algorithms
               and it is preventing roboticists to use spiking networks,
               yielding a lack of Neurorobotics applications. The contribution
               of this paper is twofold. First, we present a modular framework
               to evaluate neural self-driving vehicle applications. It
               provides a visual encoder from camera images to spikes inspired
               by the silicon retina (DVS), and a steering wheel decoder based
               on an agonist antagonist muscle model. Secondly, using this
               framework, we demonstrate a spiking neural network which
               controls a vehicle end-to-end for lane following behavior. The
               network is feed-forward and relies on hand-crafted feature
               detectors. In future work, this framework could be used to
               design more complex networks and use the evaluation metrics for
               learning.",
  publisher = "IEEE",
  pages     = "127--134",
  month     =  dec,
  year      =  2017,
  keywords  = "Mendeley Import (Apr 20)/SNN",
  isbn      = "9781509046164",
  doi       = "10.1109/SIMPAR.2016.7862386"
}

@ARTICLE{Yu2016-la,
  title    = "A Spiking Neural Network System for Robust Sequence Recognition",
  author   = "Yu, Qiang and Yan, Rui and Tang, Huajin and Tan, Kay Chen and Li,
              Haizhou",
  abstract = "--- This paper proposes a biologically plausible network
              architecture with spiking neurons for sequence recog-nition. This
              architecture is a unified and consistent system with functional
              parts of sensory encoding, learning, and decoding. This is the
              first systematic model attempting to reveal the neural mechanisms
              considering both the upstream and the downstream neurons
              together. The whole system is a consistent temporal framework,
              where the precise timing of spikes is employed for information
              processing and cognitive computing. Experimental results show
              that the system is competent to perform the sequence recognition,
              being robust to noisy sensory inputs and invariant to changes in
              the intervals between input stimuli within a certain range. The
              classification ability of the temporal learning rule used in the
              system is investigated through two benchmark tasks that
              outperform the other two widely used learning rules for
              classification. The results also demonstrate the computational
              power of spiking neurons over perceptrons for processing
              spatiotemporal patterns. In summary, the system provides a
              general way with spiking neurons to encode external stimuli into
              spatiotemporal spikes, to learn the encoded spike patterns with
              temporal learning rules, and to decode the sequence order with
              downstream neurons. The system structure would be beneficial for
              developments in both hardware and software.",
  journal  = "IEEE Transactions on Neural Networks and Learning Systems",
  year     =  2016,
  keywords = "Encoding; Temporal learning; pattern recognition; sequence
              recognition; spiking neural networks (SNNs);Mendeley Import (Apr
              20)/SNN",
  issn     = "2162-2388",
  doi      = "10.1109/TNNLS.2015.2416771"
}

@ARTICLE{Markowska-Kaczmar2015-xm,
  title    = "Spiking neural network vs multilayer perceptron: who is the
              winner in the racing car computer game",
  author   = "Markowska-Kaczmar, Urszula and Koldowski, Mateusz",
  abstract = "The paper presents two neural based controllers for the computer
              car racing game. The controllers represent two generations of
              neural networks---a multilayer perceptron and a spiking neural
              network. They are trained by an evolutionary algorithm.
              Efficiency of both approaches is experimentally tested and
              statistically analyzed.",
  journal  = "Soft Computing",
  volume   =  19,
  number   =  12,
  pages    = "3465--3478",
  month    =  "3~" # dec,
  year     =  2015,
  keywords = "Computer game controller; Evolutionary algorithm; Multilayer
              perceptron; Spiking neural network;Mendeley Import (Apr 20)/SNN",
  issn     = "1433-7479",
  doi      = "10.1007/s00500-014-1515-2"
}

@ARTICLE{Nicola2017-ru,
  title    = "Supervised learning in spiking neural networks with {FORCE}
              training",
  author   = "Nicola, Wilten and Clopath, Claudia",
  abstract = "Populations of neurons display an extraordinary diversity in the
              types of problems they solve and behaviors they display.
              Techniques have recently emerged that allow us to create networks
              of model neurons that solve tasks of similar complexity. Examples
              include the FORCE method, a novel technique that harnesses chaos
              to perform computations. We demonstrate the direct applicability
              of FORCE training to spiking neurons by training networks to
              mimic various dynamical systems in addition to reproducing more
              elaborate tasks such as input classification, storing sequences,
              reproducing the singing behavior of songbirds, and recalling a
              scene from a movie. Post-training network analysis reveals
              behaviors that are consistent with electrophysiological data,
              such as the stereotypical decrease in voltage variance upon input
              presentation, reproducing firing rate distributions from songbird
              data, and reproducing locations of incorrect recall in sequence
              replay. Finally, we demonstrate that theta oscillations are
              critical for both learning and recall of episodic memories.",
  journal  = "Nat. Commun.",
  year     =  2017,
  keywords = "Mendeley Import (Apr 20)/SNN",
  issn     = "2041-1723",
  pmid     = "19842989",
  arxivid  = "1609.02545",
  doi      = "10.1038/s41467-017-01827-3"
}

@ARTICLE{Tang_undated-kh,
  title    = "Spiking Neural Network with {RRAM}: Can We Use It for
              {Real-World} Application?",
  author   = "Tang, Tianqi and Xia, Lixue and Li, Boxun and Luo, Rong and Chen,
              Yiran and Wang, Yu and Yang, Huazhong",
  abstract = "---The spiking neural network (SNN) provides a promis-ing
              solution to drastically promote the performance and effi-ciency
              of computing systems. Previous work of SNN mainly focus on
              increasing the scalability and level of realism in a neural
              simulation, while few of them support practical cognitive
              applications with acceptable performance. At the same time, based
              on the traditional CMOS technology, the efficiency of SNN systems
              is also unsatisfactory. In this work, we explore different
              training algorithms of SNN for real-world applications, and
              demonstrate that the Neural Sampling method is much more
              effective than Spiking Time Dependent Plasticity (STDP) and
              Remote Supervision Method (ReSuMe). We also propose an energy
              efficient implementation of SNN with the emerging metal-oxide
              resistive random access memory (RRAM) devices, which includes an
              RRAM crossbar array works as network synapses, an analog design
              of the spike neuron, and an input encoding scheme. A parameter
              mapping algorithm is also introduced to configure the RRAM-based
              SNN. Simulation results illustrate that the system achieves
              91.2\% accuracy on the MNIST dataset with an ultra-low power
              consumption of 3.5mW. Moreover, the RRAM-based SNN system
              demonstrates great robustness to 20\% process variation with less
              than 1\% accuracy decrease, and can tolerate 20\% signal
              fluctuation with about 2\% accuracy loss. These results reveal
              that the RRAM-based SNN will be quite easy to be physically
              realized.",
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@MISC{Weisstein2018-fk,
  title        = "Turing Machine",
  author       = "Weisstein, Eric W",
  abstract     = "A Turing machine is a theoretical computing machine invented
                  by Alan Turing (1937) to serve as an idealized model for
                  mathematical calculation. A Turing machine consists of a line
                  of cells known as a ``tape'' that can be moved back and
                  forth, an active element known as the ``head'' that possesses
                  a property known as ``state'' and that can change the
                  property known as ``color'' of the active cell underneath it,
                  and a set of instructions for how the head should...",
  publisher    = "Wolfram Research, Inc.",
  year         =  2018,
  howpublished = "\url{http://mathworld.wolfram.com/TuringMachine.html}",
  keywords     = "68Q; Mathematics:Discrete Mathematics:Computational Systems;
                  Mathematics:Discrete Mathematics:Computer Science:Theory of
                  Computation; Mathematics:History and Terminology:Wolfram
                  Language Commands;Mendeley Import (Apr 20)/SNN"
}

@BOOK{Domingos_Pedro2015-xr,
  title     = "The Master Algorithm",
  author    = "{Domingos Pedro}",
  publisher = "Basic Books",
  year      =  2015,
  address   = "United States",
  keywords  = "Mendeley Import (Apr 20)"
}

@ARTICLE{Mnih2015-cw,
  title    = "Human-level control through deep reinforcement learning",
  author   = "Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and
              Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves,
              Alex and Riedmiller, Martin and Fidjeland, Andreas K and
              Ostrovski, Georg and Petersen, Stig and Beattie, Charles and
              Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran,
              Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis",
  abstract = "The theory of reinforcement learning provides a normative account
              1 , deeply rooted in psychological 2 and neuroscientific 3
              perspectives on animal behaviour, of how agents may optimize
              their control of an environment. To use reinforcement learning
              successfully in situations approaching real-world complexity,
              however, agents are confronted with a difficult task: they must
              derive efficient representations of the environment from
              high-dimensional sensory inputs, and use these to generalize past
              experience to new situations. Remarkably, humans and other
              animals seem to solve this problem through a harmonious
              combination of reinforcement learning and hierarchical sensory
              pro-cessing systems 4,5 , the former evidenced by a wealth of
              neural data revealing notable parallels between the phasic
              signals emitted by dopa-minergic neurons and temporal difference
              reinforcement learning algorithms 3 . While reinforcement
              learning agents have achieved some successes in a variety of
              domains 6--8 , their applicability has previously been limited to
              domains in which useful features can be handcrafted, or to
              domains with fully observed, low-dimensional state spaces. Here
              we use recent advances in training deep neural networks 9--11 to
              develop a novel artificial agent, termed a deep Q-network, that
              can learn successful policies directly from high-dimensional
              sensory inputs using end-to-end reinforcement learning. We tested
              this agent on the challenging domain of classic Atari 2600 games
              12",
  year     =  2015,
  keywords = "Mendeley Import (Apr 20)",
  doi      = "10.1038/nature14236"
}

@INPROCEEDINGS{Awais2013-ma,
  title     = "The high level architecture {RTI} as a master to the functional
               mock-up interface components",
  booktitle = "2013 International Conference on Computing, Networking and
               Communications, {ICNC} 2013",
  author    = "Awais, Muhammad Usman and Palensky, Peter and Elsheikh, Atiyah
               and Widl, Edmund and Matthias, Stifter",
  abstract  = "Recently many commercial and non-commercial Simulation Packages
               (SPs) have agreed to use the Functional Mockup Interface (FMI)
               as the medium of interoperability. FMI presents numerous
               opportunities to utilize highly specialized SPs for modeling,
               and simulating multidisciplinary applications with several
               components of various types. However there is one thing missing
               in the FMI; the master algorithm. The paper proposes to use, the
               High Level Architecture (HLA) compliant Run Time Infrastructure
               (RTI), as a master for the FMI compatible simulation components.
               The ultimate goal is to provide a completely generic and
               standalone master for the FMI, making FMI-based simulation
               components usable as plug and play components, on variety of
               distributed environments including grids and clouds. Towards
               this promising goal an initial methodology is outlined.",
  year      =  2013,
  keywords  = "Functional Mockup Interface (FMI); High Level Architecture
               (HLA); co-simulation; distributed simulation; simulation
               interoperability;Mendeley Import (Apr 20)",
  isbn      = "9781467352888",
  doi       = "10.1109/ICCNC.2013.6504102"
}

@ARTICLE{Vasu2017-ep,
  title    = "Information Bottleneck in Control Tasks with Recurrent Spiking
              Neural Networks",
  author   = "Vasu, Madhavun Candadai and Izquierdo, Eduardo",
  abstract = "The nervous system encodes continuous information from the
              environment in the form of discrete spikes, and then decodes
              these to produce smooth motor actions. Understanding how spikes
              integrate, represent, and process information to produce behavior
              is one of the greatest challenges in neuroscience. Information
              theory has the potential to help us address this challenge.
              Informational analyses of deep and feed-forward artificial neural
              networks solving static input-output tasks, have led to the
              proposal of the \textbackslashemph\{Information Bottleneck\}
              principle, which states that deeper layers encode more relevant
              yet minimal information about the inputs. Such an analyses on
              networks that are recurrent, spiking, and perform control tasks
              is relatively unexplored. Here, we present results from a Mutual
              Information analysis of a recurrent spiking neural network that
              was evolved to perform the classic pole-balancing task. Our
              results show that these networks deviate from the
              \textbackslashemph\{Information Bottleneck\} principle prescribed
              for feed-forward networks.",
  month    =  "6~" # jun,
  year     =  2017,
  keywords = "Mendeley Import (Apr 20)/SNN",
  arxivid  = "1706.01831",
  doi      = "10.1007/978-3-319-68600-4\_28"
}

@INPROCEEDINGS{Spuler_undated-vq,
  title     = "A Spiking Neuronal Model Learning a Motor Control Task by
               Reinforcement Learning and Structural Synaptic Plasticity",
  booktitle = "2015 International Joint Conference on Neural Networks ({IJCNN})",
  author    = "Sp{\"u}ler, Martin and Nagel, Sebastian and Rosenstiel, Wolfgang",
  abstract  = "---In this paper, we present a spiking neuronal model that
               learns to perform a motor control task. Since the long-term goal
               of this project is the application of such a neuronal model to
               study the mutual adaptation between a Brain-Computer Interface
               (BCI) and its user, neurobiological plausibility of the model is
               a key aspect. Therefore, the model was trained using
               reinforcement learning similar to that of the dopamine system,
               in which a global reward and punishment signal controlled
               spike-timing dependent plasticity (STDP). Based on this method,
               the majority of the randomly generated models were able to learn
               the motor control task. Although the models were only trained on
               two targets, they were able to reach arbitrary targets after
               learning. By introducing structural synaptic plasticity (SSP),
               which dynamically restructures the connections between neurons,
               the number of models that successfully learned the task could be
               significantly improved.",
  publisher = "IEEE",
  address   = "Killarney, Ireland",
  keywords  = "Mendeley Import (Apr 20)/SNN",
  doi       = "10.1109/IJCNN.2015.7280521"
}

@ARTICLE{Chadderdon2012-do,
  title    = "Reinforcement learning of targeted movement in a spiking neuronal
              model of motor cortex",
  author   = "Chadderdon, George L and Neymotin, Samuel A and Kerr, Cliff C and
              Lytton, William W",
  editor   = "Cymbalyuk, Gennady",
  abstract = "Sensorimotor control has traditionally been considered from a
              control theory perspective, without relation to neurobiology. In
              contrast, here we utilized a spiking-neuron model of motor cortex
              and trained it to perform a simple movement task, which consisted
              of rotating a single-joint ``forearm'' to a target. Learning was
              based on a reinforcement mechanism analogous to that of the
              dopamine system. This provided a global reward or punishment
              signal in response to decreasing or increasing distance from hand
              to target, respectively. Output was partially driven by Poisson
              motor babbling, creating stochastic movements that could then be
              shaped by learning. The virtual forearm consisted of a single
              segment rotated around an elbow joint, controlled by flexor and
              extensor muscles. The model consisted of 144 excitatory and 64
              inhibitory event-based neurons, each with AMPA, NMDA, and GABA
              synapses. Proprioceptive cell input to this model encoded the 2
              muscle lengths. Plasticity was only enabled in feedforward
              connections between input and output excitatory units, using
              spike-timing-dependent eligibility traces for synaptic credit or
              blame assignment. Learning resulted from a global 3-valued
              signal: reward (+1), no learning (0), or punishment (-1),
              corresponding to phasic increases, lack of change, or phasic
              decreases of dopaminergic cell firing, respectively. Successful
              learning only occurred when both reward and punishment were
              enabled. In this case, 5 target angles were learned successfully
              within 180 s of simulation time, with a median error of 8
              degrees. Motor babbling allowed exploratory learning, but
              decreased the stability of the learned behavior, since the hand
              continued moving after reaching the target. Our model
              demonstrated that a global reinforcement signal, coupled with
              eligibility traces for synaptic plasticity, can train a spiking
              sensorimotor network to perform goal-directed motor behavior.",
  journal  = "PLoS One",
  volume   =  7,
  number   =  10,
  pages    = "e47251",
  month    =  "19~" # oct,
  year     =  2012,
  keywords = "Mendeley Import (Apr 20)/SNN",
  issn     = "1932-6203",
  pmid     = "23094042",
  doi      = "10.1371/journal.pone.0047251"
}

@ARTICLE{Seung2003-pq,
  title    = "Viewpoint Learning in Spiking Neural Networks by Reinforcement of
              Stochastic Synaptic Transmission",
  author   = "Seung, H Sebastian",
  abstract = "prising and potentially detrimental to brain function. But
              another possibility is that synaptic unreliability is used by the
              brain for the purposes of learning (Minsky, 1954; Hinton, 1989),
              in analogy to the way in which unreliable genetic replication is
              used for evolution. Here I propose a specific implementation of
              this idea. According to the proposal, synapses are `` hedonistic,
              '' responding to a global reward signal by increasing their
              Summary probabilities of release or failure, depending on which
              action immediately preceded reward. Remarkably, if It is
              well-known that chemical synaptic transmission is an unreliable
              process, but the function of such unre-each synapse in a network
              behaves hedonistically, self-ishly seeking reward, then the
              network as a whole be-liability remains unclear. Here I consider
              the hypothe-sis that the randomness of synaptic transmission is
              haves hedonistically, learning to increase its average reward by
              generating appropriate collective actions. harnessed by the brain
              for learning, in analogy to the way that genetic mutation is
              utilized by Darwinian evo-This statement can be formulated and
              justified mathe-matically and defines the sense in which
              hedonistic syn-lution. This is possible if synapses are ``
              hedonistic, '' responding to a global reward signal by increasing
              apses serve the function of optimization. The concept of the
              hedonistic synapse is potentially their probabilities of vesicle
              release or failure, de-pending on which action immediately
              preceded re-relevant to any brain area in which a reinforcement
              or supervisory signal is broadcast globally. For example, ward.
              Hedonistic synapses learn by computing a sto-chastic
              approximation to the gradient of the average there is evidence
              that the neuromodulator octopamine functions as a reward signal
              in the mushroom bodies, reward. They are compatible with synaptic
              dynamics such as short-term facilitation and depression and a
              locus of olfactory learning in the insect brain (Menzel, 2001).
              Octopamine is delivered by the VUM mx1 neuron, with the
              intricacies of dendritic integration and action potential
              generation. A network of hedonistic syn-which arborizes diffusely
              over the mushroom bodies. Similarly, the vertebrate striatum
              receives dense projec-apses can be trained to perform a desired
              computation by administering reward appropriately, as illustrated
              tions from dopamine neurons in the substantia nigra, which appear
              to carry a common reward signal (Mon-here through numerical
              simulations of integrate-and-fire model neurons. tague et al.,
              1996; Schultz, 2002). Climbing fiber input to the cerebellum may
              provide an error signal for the adaptation of gaze-stabilizing
              behaviors such as the Introduction vestibuloocular reflex (Ito,
              2001). In brain areas that receive such a global reinforcement
              Many types of learning can be regarded as optimiza-tions. For
              example, operant conditioning can be viewed signal, it is
              plausible that synaptic plasticity is driven by interactions
              between the global signal and other signals as a process by which
              animals adapt their behaviors so as to maximize reward. The adage
              that `` practice makes that are local to the synapse. Finding the
              exact rules governing these interactions is an important
              challenge. perfect '' refers to the iterative improvement of
              complex motor skills like playing the piano or serving a tennis
              Hypotheses like the hedonistic synapse may prove use-ful in the
              search for learning rules that combine global ball. It is widely
              believed that learning is based at least in part on plasticity of
              the synaptic organization of the and local signals in the brain.
              It should be noted that numerous methods of optimiz-brain.
              Therefore, it seems plausible that there are types of synaptic
              plasticity that are tailored for the function ing the synaptic
              connectivity of a model neural network have been explored in the
              field of machine learning. of optimizing neural circuits. What
              specific forms could such synaptic plasticity A famous example is
              the backpropagation algorithm, take? To stimulate the
              imagination, it is helpful to draw which computes the gradient of
              an objective function inspiration from evolution, the best-known
              example of with respect to the synaptic strengths of a network an
              optimizing process in biology. A fascinating aspect of (Rumelhart
              et al., 1986). Many alternatives to backpropa-evolution is that
              it requires imperfect genetic replication. gation have also been
              proposed (Barto et al., 1983; Such unreliability might otherwise
              seem undesirable, Narendra and Thathachar, 1989; Mazzoni et al.,
              1991; but random mutation and recombination are actually
              Williams, 1992; Jabri and Flower, 1992; Cauwenberghs, essential
              for generating variation, which allows evolution 1993;
              Unnikrishnan and Venugopal, 1994). to search for improved
              genotypes. However, all of these learning rules were formulated
              An unreliable process also lies at the heart of neural for model
              networks that fail to incorporate two basic computation: synaptic
              transmission. When depolarized neurobiological facts. First,
              biological synapses are by an action potential, a presynaptic
              terminal may re-driven by presynaptic action potentials and
              modulate lease neurotransmitter, or it may fail to release
              (Stevens, the membrane conductances of their postsynaptic
              tar-1993). At first glance, such unreliability may seem sur-gets.
              Second, the efficacy of synaptic transmission var-ies dynamically
              over time from spike to spike, due to short-term facilitation and
              depression (Thomson, 2000). *Correspondence: seung@mit.edu Neuron
              1064 The learning rules studied in this paper are compatible with
              both of these features of biological synapses. By its nature, the
              present work is speculative. The particular form of plasticity
              hypothesized here may turn out to exist in the brain. Even if it
              does not, the general concept of biological synapses that rely on
              microscopic randomness for the purposes of optimization could
              still be correct. One can imagine many possible realizations of
              the concept, of which the hedonistic synapse is just one. The
              wider goal of this paper is to stimulate theorists to imagine
              these possibilities and experimentalists to search for them.
              Results",
  journal  = "Neuron",
  volume   =  40,
  pages    = "1063--1073",
  year     =  2003,
  keywords = "Mendeley Import (Apr 20)/SNN",
  issn     = "0896-6273"
}

@ARTICLE{Deneve_undated-wi,
  title    = "Bayesian inference in spiking neurons",
  author   = "Deneve, Sophie",
  abstract = "We propose a new interpretation of spiking neurons as Bayesian
              integra-tors accumulating evidence over time about events in the
              external world or the body, and communicating to other neurons
              their certainties about these events. In this model, spikes
              signal the occurrence of new infor-mation, i.e. what cannot be
              predicted from the past activity. As a result, firing statistics
              are close to Poisson, albeit providing a deterministic
              rep-resentation of probabilities. We proceed to develop a theory
              of Bayesian inference in spiking neural networks, recurrent
              interactions implement-ing a variant of belief propagation. Many
              perceptual and motor tasks performed by the central nervous
              system are probabilis-tic, and can be described in a Bayesian
              framework [4, 3]. A few important but hidden properties, such as
              direction of motion, or appropriate motor commands, are inferred
              from many noisy, local and ambiguous sensory cues. These
              evidences are combined with priors about the sensory world and
              body. Importantly, because most of these inferences should lead
              to quick and irreversible decisions in a perpetually changing
              world, noisy cues have to be integrated on-line, but in a way
              that takes into account unpredictable events, such as a sudden
              change in motion direction or the appearance of a new stimulus.",
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Carrillo2008-lp,
  title    = "A real-time spiking cerebellum model for learning robot control",
  author   = "Carrillo, Richard R and Ros, Eduardo and Boucheny, Christian and
              J-MD Coenen, Olivier",
  abstract = "a b s t r a c t We describe a neural network model of the
              cerebellum based on integrate-and-fire spiking neurons with
              conductance-based synapses. The neuron characteristics are
              derived from our earlier detailed models of the different
              cerebellar neurons. We tested the cerebellum model in a real-time
              control application with a robotic platform. Delays were
              introduced in the different sensorimotor pathways according to
              the biological system. The main plasticity in the cerebellar
              model is a spike-timing dependent plasticity (STDP) at the
              parallel fiber to Purkinje cell connections. This STDP is driven
              by the inferior olive (IO) activity, which encodes an error
              signal using a novel probabilistic low frequency model. We
              demonstrate the cerebellar model in a robot control system using
              a target-reaching task. We test whether the system learns to
              reach different target positions in a non-destructive way,
              therefore abstracting a general dynamics model. To test the
              system's ability to self-adapt to different dynamical situations,
              we present results obtained after changing the dynamics of the
              robotic platform significantly (its friction and load). The
              experimental results show that the cerebellar-based system is
              able to adapt dynamically to different contexts.",
  journal  = "Biosystems.",
  volume   =  94,
  pages    = "18--27",
  year     =  2008,
  keywords = "Adaptive; Cerebellum; Inferior olive; Learning; Neuron;
              Probabilistic; Real time; Robot; Simulation; Spiking;Mendeley
              Import (Apr 20)/SNN",
  issn     = "0303-2647",
  doi      = "10.1016/j.biosystems.2008.05.008"
}

@INPROCEEDINGS{Sanchez2011-cq,
  title     = "Control of a center-out reaching task using a reinforcement
               learning {Brain-Machine} Interface",
  booktitle = "2011 5th International {IEEE/EMBS} Conference on Neural
               Engineering",
  author    = "Sanchez, Justin C and Tarigoppula, Aditya and Choi, John S and
               Marsh, Brandi T and Chhatbar, Pratik Y and Mahmoudi, Babak and
               Francis, Joseph T",
  abstract  = "In this work, we develop an experimental primate test bed for a
               center-out reaching task to test the performance of
               reinforcement learning based decoders for Brain-Machine
               Interfaces. Neural recordings obtained from the primary motor
               cortex were used...",
  publisher = "IEEE",
  pages     = "525--528",
  month     =  apr,
  year      =  2011,
  keywords  = "Mendeley Import (Apr 20)",
  issn      = "1948-3546",
  isbn      = "9781424441402",
  doi       = "10.1109/NER.2011.5910601"
}

@ARTICLE{Fuster_undated-qq,
  title    = "Upper processing stages of the perception -- action cycle",
  author   = "Fuster, Joaqu{\'\i}n M",
  abstract = "The neural substrate for behavioral, cognitive and linguistic
              actions is hierarchically organized in the cor-tex of the frontal
              lobe. In their methodologically impec-cable study, Koechlin et
              al. reveal the neural dynamics of the frontal hierarchy in
              behavioral action. Progress-ively higher areas control the
              performance of actions requiring the integration of progressively
              more complex and temporally dispersed information. The study
              sub-stantiates the crucial role of the prefrontal cortex in the
              temporal organization of behavior. In 1874, the Russian
              neuroanatomist W. Betz [1] was the first to note a major
              functional dichotomy of structures along the nerve axis.
              Posterior structures are largely devoted to sensory functions,
              anterior structures to motor functions. This division of labor is
              most obvious in the spinal cord. We can also discern it in the
              cerebral cortex, however, if we expand sensory functions to
              include representations acquired through the senses and motor
              functions to include executive representations. A wealth of
              physiological and neuropsychological evidence points to a
              hierarchy of executive areas in the lateral cortex of the frontal
              lobe [2]. The primary motor and premotor areas constitute the
              lowest levels of that hierarchy. Above them in the hierarchy lie
              a series of progressively higher, anatomically more anterior
              areas of association cortex that are designated 'prefrontal'.
              Using fMRI on human subjects performing visuomotor tasks,
              Koechlin et al. [3] expose for the first time the cascading
              neurodynamics of the executive frontal hierarchy in motor action.
              Motor processing and control proceed from anterior prefrontal,
              through caudal prefrontal, to premotor cortex. At each level, the
              processing is informed by the processing at higher levels and by
              controlling sensory information which, as it moves down the
              hierarchy, is progressively simpler, more demanding of immediate
              action and less of temporal integration. The tasks of Koechlin et
              al. consisted of sequences of manual reactions to visual stimuli
              of varying complexity. The reaction to each stimulus depended on
              its visual features (e.g. color with or without a pattern
              'context') and an instructional cue that preceded the sequence to
              which that stimulus belonged. All motor reactions and the
              significance of each instructional cue were part of a set of
              rules that the subject had learned before the experi-ment. The
              key measurement was the degree of activation in anterior
              (rostral) and posterior (caudal) prefrontal cortex, and in
              premotor cortex. The authors used a computational model based on
              Shannon's information theory [4] and a hierarchical model of
              frontal organization and processing [2]. By factor analysis of
              the fMRI data, they determined that rostral prefrontal cortex
              controls behavior mainly in accordance with the instructional cue
              ('temporal episode'), caudal prefrontal cortex with the context
              of the stimulus, and premotor cortex with the stimulus itself.",
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Saraiva_De_Queiroz_undated-go,
  title    = "Reinforcement Learning of a Simple Control Task Using the Spike
              Response Model",
  author   = "Saraiva De Queiroz, Murilo",
  abstract = "In this work, we propose a variation of a direct reinforce-ment
              learning algorithm, suitable for usage with spiking neurons based
              on the Spike Response Model (SRM). The SRM is a
              biologically-inspired, flexible model of spiking neuron based on
              kernel functions that describe the effect of spike reception and
              emission on the membrane potential of the neuron. In our
              experiments, the spikes emitted by a SRM neuron are used as input
              signals in a simple con-trol task. The reinforcement signal
              obtained from the en-vironment is used by the direct
              reinforcement learning al-gorithm, that modifies the synaptic
              weights of the neuron, adjusting the spiking firing times in
              order to obtain a better performance at the given problem. The
              obtained results are comparable to those from classic methods
              based on value function approximation and temporal difference,
              for simple control tasks.",
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Fremaux2013-cq,
  title    = "Reinforcement Learning Using a Continuous Time {Actor-Critic}
              Framework with Spiking Neurons",
  author   = "Fr{\'e}maux, Nicolas and Sprekeler, Henning and Gerstner, Wulfram",
  abstract = "Animals repeat rewarded behaviors, but the physiological basis of
              reward-based learning has only been partially elucidated. On one
              hand, experimental evidence shows that the neuromodulator
              dopamine carries information about rewards and affects synaptic
              plasticity. On the other hand, the theory of reinforcement
              learning provides a framework for reward-based learning. Recent
              models of reward-modulated spike-timing-dependent plasticity have
              made first steps towards bridging the gap between the two
              approaches, but faced two problems. First, reinforcement learning
              is typically formulated in a discrete framework, ill-adapted to
              the description of natural situations. Second, biologically
              plausible models of reward-modulated spike-timing-dependent
              plasticity require precise calculation of the reward prediction
              error, yet it remains to be shown how this can be computed by
              neurons. Here we propose a solution to these problems by
              extending the continuous temporal difference (TD) learning of
              Doya (2000) to the case of spiking neurons in an actor-critic
              network operating in continuous time, and with continuous state
              and action representations. In our model, the critic learns to
              predict expected future rewards in real time. Its activity,
              together with actual rewards, conditions the delivery of a
              neuromodulatory TD signal to itself and to the actor, which is
              responsible for action choice. In simulations, we show that such
              an architecture can solve a Morris water-maze-like navigation
              task, in a number of trials consistent with reported animal
              performance. We also use our model to solve the acrobot and the
              cartpole problems, two complex motor control tasks. Our model
              provides a plausible way of computing reward prediction error in
              the brain. Moreover, the analytically derived learning rule is
              consistent with experimental evidence for dopamine-modulated
              spike-timing-dependent plasticity.",
  journal  = "PLoS Comput. Biol.",
  year     =  2013,
  keywords = "Mendeley Import (Apr 20)",
  issn     = "1553-734X",
  pmid     = "23592970",
  doi      = "10.1371/journal.pcbi.1003024"
}

@ARTICLE{Xie_undated-au,
  title    = "Learning in neural networks by reinforcement of irregular spiking",
  author   = "Xie, Xiaohui and Seung, H Sebastian",
  abstract = "Artificial neural networks are often trained by using the back
              propagation algorithm to compute the gradient of an objective
              function with respect to the synaptic strengths. For a biological
              neural network, such a gradient computation would be difficult to
              implement, because of the complex dynamics of intrinsic and
              synaptic conductances in neurons. Here we show that irregular
              spiking similar to that observed in biological neurons could be
              used as the basis for a learning rule that calculates a
              stochastic approximation to the gradient. The learning rule is
              derived based on a special class of model networks in which
              neurons fire spike trains with Poisson statistics. The learning
              is compatible with forms of synaptic dynamics such as short-term
              facilitation and depression. By correlating the fluctuations in
              irregular spiking with a reward signal, the learning rule
              performs stochastic gradient ascent on the expected reward. It is
              applied to two examples, learning the XOR computation and
              learning direction selectivity using depressing synapses. We also
              show in simulation that the learning rule is applicable to a
              network of noisy integrate-and-fire neurons.",
  keywords = "Mendeley Import (Apr 20)/SNN",
  doi      = "10.1103/PhysRevE.69.041909"
}

@ARTICLE{Lee2008-el,
  title    = "Synaptic plasticity model of a spiking neural network for
              reinforcement learning",
  author   = "Lee, Kyoobin and Kwon, Dong-Soo",
  abstract = "This paper presents a reward-related synaptic modification method
              of a spiking neuron model. The proposed algorithm determines
              which synapse is eligible for reinforcement by a reward signal.
              According to the proposed algorithm, a synapse is determined to
              be eligible when a presynaptic spike occurs shortly before a
              postsynaptic spike. A pre-and postsynaptic spike correlator
              (PPSC) is defined and used to determine synaptic eligibility, and
              to modify synaptic efficacy in cooperation with a reward signal.
              A simulation is conducted to demonstrate how the interaction
              between the PPSC and the reward signal influences synaptic
              plasticity.",
  journal  = "Neurocomputing",
  volume   =  71,
  pages    = "3037--3043",
  year     =  2008,
  keywords = "Reinforcement learning; Spiking neural network; Synaptic
              plasticity;Mendeley Import (Apr 20)/SNN",
  issn     = "0925-2312",
  doi      = "10.1016/j.neucom.2007.09.009"
}

@ARTICLE{Bouganis_undated-zb,
  title    = "Training a Spiking Neural Network to Control a {4-DoF} Robotic
              Arm based on Spike {Timing-Dependent} Plasticity",
  author   = "Bouganis, Alexandros and Shanahan, Murray",
  abstract = "--- In this paper, we present a spiking neural network
              architecture that autonomously learns to control a 4
              degree-of-freedom robotic arm after an initial period of motor
              babbling. Its aim is to provide the joint commands that will move
              the end-effector in a desired spatial direction, given the joint
              con-figuration of the arm. The spiking neurons have been
              simulated according to Izhikevich's model, which exhibits
              biologically realistic behaviour and yet is computationally
              efficient. The architecture is a feed-forward network where the
              input layers encode the intended movement direction of the
              end-effector in spatial coordinates, as well as the information
              that is given by proprioception about the current joint angles of
              the arm. The motor commands are determined by decoding the firing
              patterns in the output layers. Both excitatory and inhibitory
              synapses connect the input and output layers, and their initial
              weights are set to random values. The network learns to map input
              stimuli to motor commands during a phase of repetitive
              action-perception cycles, in which Spike Timing-Dependent
              Plasticity (STDP) strengthens synapses between neurons that are
              correlated and weakens synapses between uncorrelated ones. The
              trained spiking neural network has been successfully tested on a
              kinematic model of the arm of an iCub humanoid robot.",
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Mahmoudi2011-ri,
  title    = "A Symbiotic {Brain-Machine} Interface through Value- Based
              Decision Making",
  author   = "Mahmoudi, Babak and Sanchez, Justin C",
  abstract = "Background: In the development of Brain Machine Interfaces
              (BMIs), there is a great need to enable users to interact with
              changing environments during the activities of daily life. It is
              expected that the number and scope of the learning tasks
              encountered during interaction with the environment as well as
              the pattern of brain activity will vary over time. These
              conditions, in addition to neural reorganization, pose a
              challenge to decoding neural commands for BMIs. We have developed
              a new BMI framework in which a computational agent symbiotically
              decoded users' intended actions by utilizing both motor commands
              and goal information directly from the brain through a continuous
              Perception-Action-Reward Cycle (PARC). Methodology: The control
              architecture designed was based on Actor-Critic learning, which
              is a PARC-based reinforcement learning method. Our
              neurophysiology studies in rat models suggested that Nucleus
              Accumbens (NAcc) contained a rich representation of goal
              information in terms of predicting the probability of earning
              reward and it could be translated into an evaluative feedback for
              adaptation of the decoder with high precision. Simulated neural
              control experiments showed that the system was able to maintain
              high performance in decoding neural motor commands during novel
              tasks or in the presence of reorganization in the neural input.
              We then implanted a dual micro-wire array in the primary motor
              cortex (M1) and the NAcc of rat brain and implemented a full
              closed-loop system in which robot actions were decoded from the
              single unit activity in M1 based on an evaluative feedback that
              was estimated from NAcc. Conclusions: Our results suggest that
              adapting the BMI decoder with an evaluative feedback that is
              directly extracted from the brain is a possible solution to the
              problem of operating BMIs in changing environments with dynamic
              neural signals. During closed-loop control, the agent was able to
              solve a reaching task by capturing the action and reward
              interdependency in the brain. Citation: Mahmoudi B, Sanchez JC
              (2011) A Symbiotic Brain-Machine Interface through Value-Based
              Decision Making. PLoS ONE 6(3): e14760.",
  year     =  2011,
  keywords = "Mendeley Import (Apr 20)/SNN",
  doi      = "10.1371/"
}

@ARTICLE{Zhang_undated-np,
  title    = "A Deeper Look at Experience Replay",
  author   = "Zhang, Shangtong and Sutton, Richard S",
  abstract = "Experience replay plays an important role in the success of deep
              reinforcement learning (RL) by helping stabilize the neural
              networks. It has become a new norm in deep RL algorithms. In this
              paper, however, we showcase that varying the size of the
              experience replay buffer can hurt the performance even in very
              simple tasks. The size of the replay buffer is actually a
              hyper-parameter which needs careful tuning. Moreover, our study
              of experience replay leads to the formulation of the Combined DQN
              algorithm, which can significantly outperform primitive DQN in
              some tasks.",
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@INPROCEEDINGS{Schaul2016-lw,
  title     = "Prioritized experience replay",
  booktitle = "4th International Conference on Learning Representations, {ICLR}
               2016 - Conference Track Proceedings",
  author    = "Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver,
               David",
  abstract  = "Experience replay lets online reinforcement learning agents
               remember and reuse experiences from the past. In prior work,
               experience transitions were uniformly sampled from a replay
               memory. However, this approach simply replays transitions at the
               same frequency that they were originally experienced, regardless
               of their significance. In this paper we develop a framework for
               prioritizing experience, so as to replay important transitions
               more frequently, and therefore learn more efficiently. We use
               prioritized experience replay in Deep Q-Networks (DQN), a
               reinforcement learning algorithm that achieved human-level
               performance across many Atari games. DQN with prioritized
               experience replay achieves a new state-of-the-art, outperforming
               DQN with uniform replay on 41 out of 49 games.",
  year      =  2016,
  keywords  = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Izhikevich2004-iw,
  title    = "Which Model to Use for Cortical Spiking Neurons?",
  author   = "Izhikevich, Eugene M",
  abstract = "---We discuss the biological plausibility and computa-tional
              efficiency of some of the most useful models of spiking and
              bursting neurons. We compare their applicability to large-scale
              simulations of cortical neural networks. Index Terms---Chaos,
              Hodgkin--Huxley, pulse-coupled neural network (PCNN), quadratic
              integrate-and-fire (I\&F), spike-timing.",
  journal  = "IEEE Trans. Neural Netw.",
  volume   =  15,
  number   =  5,
  year     =  2004,
  keywords = "Mendeley Import (Apr 20)/SNN",
  issn     = "1045-9227",
  doi      = "10.1109/TNN.2004.832719"
}

@INPROCEEDINGS{Shah2017-qi,
  title     = "{AirSim}: {High-Fidelity} Visual and Physical Simulation for
               Autonomous Vehicles",
  booktitle = "Field and Service Robotics",
  author    = "Shah, Shital and Dey, Debadeepta and Lovett, Chris and Kapoor,
               Ashish",
  abstract  = "Developing and testing algorithms for autonomous vehicles in
               real world is an expensive and time consuming process. Also, in
               order to utilize recent advances in machine intelligence and
               deep learning we need to collect a large amount of annotated
               training data in a variety of conditions and environments. We
               present a new simulator built on Unreal Engine that offers
               physically and visually realistic simulations for both of these
               goals. Our simulator includes a physics engine that can operate
               at a high frequency for real-time hardware-in-the-loop (HITL)
               simulations with support for popular protocols (e.g. MavLink).
               The simulator is designed from the ground up to be extensible to
               accommodate new types of vehicles, hardware platforms and
               software protocols. In addition, the modular design enables
               various components to be easily usable independently in other
               projects. We demonstrate the simulator by first implementing a
               quadrotor as an autonomous vehicle and then experimentally
               comparing the software components with real-world flights.",
  year      =  2017,
  keywords  = "Mendeley Import (Apr 20)/SNN"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Jaromir_Janisch2016-tz,
  title        = "Let's make a {DQN}: Theory | ",
  author       = "{Jarom{\'\i}r Janisch}",
  year         =  2016,
  howpublished = "\url{https://jaromiru.com/2016/09/27/lets-make-a-dqn-theory/}",
  keywords     = "Mendeley Import (Apr 20)/SNN;Mendeley Import (Apr 20)"
}

@MISC{Shital_Shah2017-bc,
  title        = "Reinforcement Learning in {AirSim}",
  author       = "{Shital Shah}",
  year         =  2017,
  howpublished = "\url{https://github.com/Microsoft/AirSim/blob/master/docs/reinforcement_learning.md}",
  keywords     = "Mendeley Import (Apr 20)"
}

@MISC{Microsoft_undated-gb,
  title        = "{AirSim} Releases",
  author       = "{Microsoft}",
  howpublished = "\url{https://github.com/Microsoft/AirSim/releases}",
  keywords     = "Mendeley Import (Apr 20)"
}

@TECHREPORT{Department_for_Transport2017-ej,
  title    = "Reported road casualties in Great Britain: 2016 annual report",
  author   = "{Department for Transport}",
  year     =  2017,
  keywords = "Mendeley Import (Apr 20)"
}

@MISC{Khan_Academy_undated-eg,
  title        = "The synapse",
  author       = "{Khan Academy}",
  howpublished = "\url{https://www.khanacademy.org/science/biology/human-biology/neuron-nervous-system/a/the-synapse}",
  keywords     = "Mendeley Import (Apr 20)"
}

@ARTICLE{Cao2015-wj,
  title     = "Spiking Deep Convolutional Neural Networks for
               {Energy-Efficient} Object Recognition",
  author    = "Cao, Yongqiang and Chen, Yang and Khosla, Deepak",
  journal   = "Int. J. Comput. Vis.",
  publisher = "Springer US",
  volume    =  113,
  number    =  1,
  pages     = "54--66",
  month     =  "23~" # may,
  year      =  2015,
  keywords  = "Mendeley Import (Apr 20)",
  issn      = "0920-5691",
  doi       = "10.1007/s11263-014-0788-3"
}

@ARTICLE{Mnih_undated-pq,
  title    = "Playing Atari with Deep Reinforcement Learning",
  author   = "Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and
              Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and
              Riedmiller, Martin",
  abstract = "We present the first deep learning model to successfully learn
              control policies di-rectly from high-dimensional sensory input
              using reinforcement learning. The model is a convolutional neural
              network, trained with a variant of Q-learning, whose input is raw
              pixels and whose output is a value function estimating future
              rewards. We apply our method to seven Atari 2600 games from the
              Arcade Learn-ing Environment, with no adjustment of the
              architecture or learning algorithm. We find that it outperforms
              all previous approaches on six of the games and surpasses a human
              expert on three of them.",
  keywords = "Mendeley Import (Apr 20)"
}

@MISC{Khan_Academy_undated-ee,
  title        = "Overview of neuron structure and function",
  author       = "{Khan Academy}",
  howpublished = "\url{https://www.khanacademy.org/science/biology/human-biology/neuron-nervous-system/a/overview-of-neuron-structure-and-function}",
  keywords     = "Mendeley Import (Apr 20)"
}

@BOOK{Hebb_Donald1949-nn,
  title     = "Organization of Behavior",
  author    = "Hebb, Donald, Olding",
  publisher = "Wiley \& Sons.",
  year      =  1949,
  address   = "New York",
  keywords  = "Mendeley Import (Apr 20)"
}

@ARTICLE{Nicholls1972-fq,
  title     = "A comparison of chemical and electrical synaptic transmission
               between single sensory cells and a motoneurone in the central
               nervous system of the leech",
  author    = "Nicholls, J G and Purves, D",
  abstract  = "In leech ganglia, three sensory cells of different modality
               converge on a motoneurone, where they form chemical and
               electrical synapses. Each of these synapses behaves in a
               characteristic manner and the nature of the transmission
               mechanism has significant functional consequences for the
               operation of the reflexes. An analysis has been made of the
               effects of trains of impulses on synaptic transmission through
               these pathways, using frequencies that correspond to natural
               firing.1. At the chemical synapse between the nociceptive
               sensory cell and the motoneurone, two opposing events occur:
               facilitation and depression. Thus, with trains of impulses, the
               synaptic potentials first increase in amplitude and then
               decrease. The two processes could be separated by altering the
               Mg and Ca content of the bathing fluid. In concentrations of Mg
               that reduced the amplitude of a single control chemical synaptic
               potential, pure facilitation occurred during a train. Depression
               predominated during brief trains in raised concentrations of Ca,
               although synaptic potentials were initially larger. These
               results suggest that changes in the amount of transmitter
               released by each presynaptic action potential can account for
               the changes observed in chemical synaptic transmission.2. In
               contrast, electrical transmission between the sensory cell
               responding to touch and the same motoneurone did not show
               facilitation or depression. The electrical coupling potential in
               the motoneurone was relatively constant when the touch cell
               fired at high or low frequencies in normal Ringer fluid, high
               Mg, or high Ca fluid.3. Further differences between chemical and
               electrical synapses were apparent when the preparation was
               cooled to 4 degrees C. In the cold the latency of chemically
               evoked synaptic potentials in the motoneurone increased and
               their amplitude declined drastically with repetitive
               stimulation, while electrical coupling potentials were
               unaffected.4. A brief hyperpolarization of the presynaptic cell
               by injected current produced a marked and prolonged increase in
               chemically evoked synaptic potentials, but did not influence
               electrical synaptic transmission.5. The synapses of the sensory
               cell responding to pressure, which are both chemical and
               electrical, behaved as expected: the chemical synaptic
               potentials showed facilitation and depression while electrical
               transmission remained relatively constant.6. These experiments
               emphasize the different functional consequences of electrical or
               chemical synapses in reflex pathways for the transmission of
               signals that arise as a result of natural sensory stimuli.",
  journal   = "J. Physiol.",
  publisher = "Wiley-Blackwell",
  volume    =  225,
  number    =  3,
  pages     = "637--656",
  month     =  sep,
  year      =  1972,
  keywords  = "Mendeley Import (Apr 20)/SNN",
  issn      = "0022-3751",
  pmid      = "4342522"
}

@MISC{Khan_Academy_undated-cx,
  title        = "The membrane potential",
  booktitle    = "Khan Academy",
  author       = "{Khan Academy}",
  howpublished = "\url{https://www.khanacademy.org/science/biology/human-biology/neuron-nervous-system/a/the-membrane-potential}",
  keywords     = "Mendeley Import (Apr 20)"
}

@BOOK{Purves2001-lf,
  title     = "Neuroscience - {Voltage-Gated} Ion Channels",
  author    = "Purves, Dale and Augustine, George J and Fitzpatrick, David and
               Katz, Lawrence C and LaMantia, Anthony-Samuel and McNamara,
               James O and Williams, S Mark",
  publisher = "Sinauer Associates",
  edition   =  2,
  year      =  2001,
  address   = "Sunderland (MA)",
  keywords  = "Mendeley Import (Apr 20)/SNN"
}

@BOOK{Rye_Connie2013-nw,
  title     = "Biology - Nervous System",
  author    = "{Rye Connie} and {Wise Robert} and {Jurukovski Vladimir} and
               {Desaix Jean} and {Choi Jung} and {Avissar Yael}",
  publisher = "OpenStax",
  pages     = "985--1027",
  year      =  2013,
  address   = "Houston",
  keywords  = "Mendeley Import (Apr 20)/SNN"
}

@BOOK{Purves2001-lj,
  title     = "Neuroscience - Excitatory and Inhibitory Postsynaptic Potentials",
  author    = "Purves, Dale and Augustine, George J and Fitzpatrick, David and
               Katz, Lawrence C and LaMantia, Anthony-Samuel and McNamara,
               James O and Williams, S Mark",
  publisher = "Sinauer Associates",
  edition   =  2,
  year      =  2001,
  address   = "Sunderland (MA)",
  keywords  = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Takeuchi2014-sk,
  title     = "The synaptic plasticity and memory hypothesis: encoding, storage
               and persistence",
  author    = "Takeuchi, Tomonori and Duszkiewicz, Adrian J and Morris, Richard
               G M",
  abstract  = "The synaptic plasticity and memory hypothesis asserts that
               activity-dependent synaptic plasticity is induced at appropriate
               synapses during memory formation and is both necessary and
               sufficient for the encoding and trace storage of the type of
               memory mediated by the brain area in which it is observed.
               Criteria for establishing the necessity and sufficiency of such
               plasticity in mediating trace storage have been identified and
               are here reviewed in relation to new work using some of the
               diverse techniques of contemporary neuroscience. Evidence
               derived using optical imaging, molecular-genetic and optogenetic
               techniques in conjunction with appropriate behavioural analyses
               continues to offer support for the idea that changing the
               strength of connections between neurons is one of the major
               mechanisms by which engrams are stored in the brain.",
  journal   = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  publisher = "The Royal Society",
  volume    =  369,
  number    =  1633,
  pages     = "20130288",
  month     =  "5~" # jan,
  year      =  2014,
  keywords  = "dopamine; engram; initial consolidation; long-term potentiation;
               memory; synaptic plasticity;Mendeley Import (Apr 20)/SNN",
  issn      = "0962-8436, 1471-2970",
  pmid      = "24298167",
  doi       = "10.1098/rstb.2013.0288"
}

@ARTICLE{Deisseroth1995-rg,
  title     = "Synaptic Plasticity: A molecular mechanism for metaplasticity",
  author    = "Deisseroth, K and Bito, H and Schulman, H and Tsien, R W",
  abstract  = "The results of expressing a constitutive form of a prominent
               synaptic kinase in transgenic mice suggest how there can be a
               sliding threshold for synapse modification, an important element
               in some learning theories.",
  journal   = "Curr. Biol.",
  publisher = "Cell Press",
  volume    =  5,
  number    =  12,
  pages     = "1334--1338",
  month     =  "1~" # dec,
  year      =  1995,
  keywords  = "Mendeley Import (Apr 20)/SNN",
  issn      = "0960-9822",
  doi       = "10.1016/S0960-9822(95)00262-4"
}

@ARTICLE{Song2000-xn,
  title     = "Competitive Hebbian learning through spike-timing-dependent
               synapticplasticity",
  author    = "Song, Sen and Miller, Kenneth D and Abbott, L F",
  abstract  = "Competitive Hebbian learning through spike-timing-dependent
               synaptic plasticity",
  journal   = "Nat. Neurosci.",
  publisher = "Nature Publishing Group",
  volume    =  3,
  number    =  9,
  pages     = "919--926",
  month     =  "1~" # sep,
  year      =  2000,
  keywords  = "Mendeley Import (Apr 20)/SNN",
  issn      = "1097-6256",
  doi       = "10.1038/78829"
}

@ARTICLE{Schultz1998-vk,
  title    = "Predictive Reward Signal of Dopamine Neurons",
  author   = "Schultz, Wolfram",
  abstract = "The effects of lesions, receptor blocking, electrical
              self-stimulation, and drugs of abuse suggest that midbrain
              dopamine systems are involved in processing reward information
              and learning approach behavior. Most dopamine neurons show phasic
              activations after primary liquid and food rewards and
              conditioned, reward-predicting visual and auditory stimuli. They
              show biphasic, activation-depression responses after stimuli that
              resemble reward-predicting stimuli or are novel or particularly
              salient. However, only few phasic activations follow aversive
              stimuli. Thus dopamine neurons label environmental stimuli with
              appetitive value, predict and detect rewards and signal alerting
              and motivating events. By failing to discriminate between
              different rewards, dopamine neurons appear to emit an alerting
              message about the surprising presence or absence of rewards. All
              responses to rewards and reward-predicting stimuli depend on
              event predictability. Dopamine neurons are activated by rewarding
              events that are better than predicted, remain uninfluenced by
              events that are as good as predicted, and are depressed by events
              that are worse than predicted. By signaling rewards according to
              a prediction error, dopamine responses have the formal
              characteristics of a teaching signal postulated by reinforcement
              learning theories. Dopamine responses transfer during learning
              from primary rewards to reward-predicting stimuli. This may
              contribute to neuronal mechanisms underlying the retrograde
              action of rewards, one of the main puzzles in reinforcement
              learning. The impulse response releases a short pulse of dopamine
              onto many dendrites, thus broadcasting a rather global
              reinforcement signal to postsynaptic neurons. This signal may
              improve approach behavior by providing advance reward information
              before the behavior occurs, and may contribute to learning by
              modifying synaptic transmission. The dopamine reward signal is
              supplemented by activity in neurons in striatum, frontal cortex,
              and amygdala, which process specific reward information but do
              not emit a global reward prediction error signal. A cooperation
              between the different reward signals may assure the use of
              specific rewards for selectively reinforcing behaviors. Among the
              other projection systems, noradrenaline neurons predominantly
              serve attentional mechanisms and nucleus basalis neurons code
              rewards heterogeneously. Cerebellar climbing fibers signal errors
              in motor performance or errors in the prediction of aversive
              events to cerebellar Purkinje cells. Most deficits following
              dopamine-depleting lesions are not easily explained by a
              defective reward signal but may reflect the absence of a general
              enabling function of tonic levels of extracellular dopamine. Thus
              dopamine systems may have two functions, the phasic transmission
              of reward information and the tonic enabling of postsynaptic
              neurons.",
  journal  = "J. Neurophysiol.",
  volume   =  80,
  number   =  1,
  pages    = "1--27",
  month    =  jul,
  year     =  1998,
  keywords = "Mendeley Import (Apr 20)/SNN",
  issn     = "0022-3077",
  pmid     = "9658025",
  doi      = "10.1152/jn.1998.80.1.1"
}

@ARTICLE{Izhikevich2007-pc,
  title    = "Solving the Distal Reward Problem through Linkage of {STDP} and
              Dopamine Signaling",
  author   = "Izhikevich, E M",
  abstract = "In Pavlovian and instrumental conditioning, reward typically
              comes seconds after reward-triggering actions, creating an
              explanatory conundrum known as ``distal reward problem'': How
              does the brain know what firing patterns of what neurons are
              responsible for the reward if 1) the patterns are no longer there
              when the reward arrives and 2) all neurons and synapses are
              active during the waiting period to the reward? Here, we show how
              the conundrum is resolved by a model network of cortical spiking
              neurons with spike-timing-dependent plasticity (STDP) modulated
              by dopamine (DA). Although STDP is triggered by nearly coincident
              firing patterns on a millisecond timescale, slow kinetics of
              subsequent synaptic plasticity is sensitive to changes in the
              extracellular DA concentration during the critical period of a
              few seconds. Random firings during the waiting period to the
              reward do not affect STDP and hence make the network insensitive
              to the ongoing activity-the key feature that distinguishes our
              approach from previous theoretical studies, which implicitly
              assume that the network be quiet during the waiting period or
              that the patterns be preserved until the reward arrives. This
              study emphasizes the importance of precise firing patterns in
              brain dynamics and suggests how a global diffusive reinforcement
              signal in the form of extracellular DA can selectively influence
              the right synapses at the right time.",
  journal  = "Cereb. Cortex",
  volume   =  17,
  number   =  10,
  pages    = "2443--2452",
  month    =  "1~" # oct,
  year     =  2007,
  keywords = "Mendeley Import (Apr 20)/SNN",
  issn     = "1047-3211",
  pmid     = "17220510",
  doi      = "10.1093/cercor/bhl152"
}

@BOOK{Pavlov1927-je,
  title     = "Conditioned reflexes: an investigation of the physiological
               activity of the cerebral cortex",
  author    = "Pavlov, I P",
  abstract  = "The present volume is the first complete discussion of
               conditioned reflexes to be translated into one of the more
               familiar European languages. It contains 23 lectures, most of
               which were delivered in the spring of 1924 at the Military
               Medical Academy in Leningrad. After an initial discussion of
               historical background and of the technical methods employed,
               Pavlov discusses the following topics: the formation of
               conditioned reflexes by means of conditioned and direct stimuli;
               external and internal inhibition of conditioned reflexes; the
               analyzing and synthesizing activity of the cerebral hemisphere;
               irradiation and concentration of nervous processes in the
               cerebral cortex; mutual induction of excitation and inhibition;
               interaction of irradiation and concentration with induction; the
               cortex as a mosaic of functions; development of inhibition in
               the cortex under the influence of conditioned stimuli; internal
               inhibition and sleep as one and the same process with regard to
               their intimate mechanism; transition stages between the alert
               state and complete sleep-hypnotic stages; different types of
               nervous system; pathological disturbances of the cortex, result
               of functional and surgical interference; general characteristics
               of the present investigation and its special difficulties;
               discovery of certain errors necessitating the modification of
               some earlier interpretations; and the experimental results
               obtained with animals in their application to man. Attention is
               drawn to the similarity of the neuroses and psychoses to
               behavior observed in the dog during certain of the experiments.
               A bibliography is given of all papers published from Pavlov's
               laboratories upon the physiology of conditioned reflexes.
               (PsycINFO Database Record (c) 2016 APA, all rights reserved)",
  publisher = "Oxford Univ. Press",
  pages     = "430, xv, 430--xv",
  year      =  1927,
  address   = "Oxford, England",
  keywords  = "Mendeley Import (Apr 20)"
}

@INCOLLECTION{Paugam-Moisy_Helene2012-kz,
  title     = "Computing with Spiking Neuron Networks",
  booktitle = "Handbook of Natural Computing",
  author    = "{Paugam-Moisy H{\'e}l{\`e}ne} and and Bohte, Sander",
  editor    = "{Rozenberg Grzegorz} and and B{\"a}ck, Thomas and {and Kok Joost
               N}",
  abstract  = "Spiking Neuron Networks (SNNs) are often referred to as the
               third generation of neural networks. Highly inspired by natural
               computing in the brain and recent advances in neurosciences,
               they derive their strength and interest from an accurate
               modeling of synaptic interactions between neurons, taking into
               account the time of spike firing. SNNs overcome the
               computational power of neural networks made of threshold or
               sigmoidal units. Based on dynamic event-driven processing, they
               open up new horizons for developing models with an exponential
               capacity to memorize and a strong ability to do fast adaptation.
               Today, the main challenge is to discover efficient learning
               rules that might take advantage of the specific features of SNNs
               while keeping the nice properties (general-purpose, easy-to-use,
               available simulators, etc.) of traditional connectionist models.
               This chapter relates the history of the ``spiking neuron'' in
               Sect. 1 and summarizes the most currently-in-use models of
               neurons and synaptic plasticity in Sect. 2. The computational
               power of SNNs is addressed in Sect. 3 and the problem of
               learning in networks of spiking neurons is tackled in Sect. 4,
               with insights into the tracks currently explored for solving it.
               Finally, Sect. 5 discusses application domains, implementation
               issues and proposes several simulation frameworks.",
  publisher = "Springer Berlin Heidelberg",
  pages     = "335--376",
  year      =  2012,
  address   = "Berlin, Heidelberg",
  keywords  = "Mendeley Import (Apr 20)",
  isbn      = "9783540929109",
  doi       = "10.1007/978-3-540-92910-9\_10"
}

@ARTICLE{Thorpe1996-bp,
  title     = "Speed of processing in the human visual system",
  author    = "Thorpe, Simon and Fize, Denis and Marlot, Catherine",
  abstract  = "Speed of processing in the human visual system",
  journal   = "Nature",
  publisher = "Nature Publishing Group",
  volume    =  381,
  number    =  6582,
  pages     = "520--522",
  month     =  "6~" # jun,
  year      =  1996,
  keywords  = "Mendeley Import (Apr 20)/SNN",
  issn      = "0028-0836",
  doi       = "10.1038/381520a0"
}

@INBOOK{Fujii2006-kx,
  title     = "Temporal Data Encoding and {SequenceLearning} with Spiking
               Neural Networks",
  author    = "Fujii, Robert H and Oozeki, Kenjyu",
  publisher = "Springer, Berlin, Heidelberg",
  pages     = "780--789",
  year      =  2006,
  keywords  = "Mendeley Import (Apr 20)/SNN",
  doi       = "10.1007/11840817\_81"
}

@BOOK{Gerstner2014-pb,
  title     = "Neuronal Dynamics",
  author    = "Gerstner, Wulfram and Kistler, Werner M and {Naud Richard} and
               {Paninski Liam}",
  publisher = "Cambridge University Press",
  year      =  2014,
  address   = "Cambridge",
  keywords  = "Mendeley Import (Apr 20)/SNN"
}

@MISC{Halliday_David2017-au,
  title        = "Neural Networks Supplementary Notes",
  author       = "{Halliday David}",
  year         =  2017,
  howpublished = "\url{https://www.elec.york.ac.uk/internal_web/meng/yr3/modules/Neural_Networks/NN_Notes.pdf}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@PHDTHESIS{John_Wesley_Hill2017-in,
  title    = "Deep Learning for Emotion Recognition in Cartoons",
  author   = "{John Wesley Hill}",
  abstract = "Emotion Recognition is a field that computers are getting very
              good at identifying; whether it's through images, video or audio.
              Emotion Recognition has shown promising improvements when
              combined with classifiers and Deep Neural Networks showing a
              validation rate as high as 59\% and a recognition rate of 56\%.
              The focus of this dissertation will be on facial based emotion
              recognition. This consists of detecting facial expressions in
              images and videos. While the majority of research uses human
              faces in an attempt to recognise basic emotions, there has been
              little research on whether the same deep learning techniques can
              be applied to faces in cartoons. The system implemented in this
              paper, aims to classify at most three emotions (happiness, anger
              and surprise) of the 6 basic emotions proposed by psychologists
              Ekman and Friesen, with an accuracy of 80\% for the 3 emotions.
              Showing promise of applications of deep learning and cartoons.
              This project is an attempt to examine if emotions in cartoons can
              be detected in the same way that human faces can.",
  year     =  2017,
  school   = "University of Lincoln",
  keywords = "Mendeley Import (Apr 20)"
}

@MISC{Jiaconda2013-ue,
  title        = "A Concise History of Neural Networks -- Jiaconda -- Medium",
  author       = "{Jiaconda}",
  year         =  2013,
  howpublished = "\url{https://medium.com/@Jaconda/a-concise-history-of-neural-networks-2070655d3fec}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Apple2017-pm,
  title    = "Hey Siri: An On-device {DNN-powered} Voice Trigger for Apple's
              Personal Assistant - Apple",
  author   = "{Apple} and {Siri Team}",
  journal  = "Apple Machine Learning Journal",
  volume   =  1,
  number   =  6,
  year     =  2017,
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Huh2017-rr,
  title    = "Gradient Descent for Spiking Neural Networks",
  author   = "Huh, Dongsung and Sejnowski, Terrence J",
  abstract = "Much of studies on neural computation are based on network models
              of static neurons that produce analog output, despite the fact
              that information processing in the brain is predominantly carried
              out by dynamic neurons that produce discrete pulses called
              spikes. Research in spike-based computation has been impeded by
              the lack of efficient supervised learning algorithm for spiking
              networks. Here, we present a gradient descent method for
              optimizing spiking network models by introducing a differentiable
              formulation of spiking networks and deriving the exact gradient
              calculation. For demonstration, we trained recurrent spiking
              networks on two dynamic tasks: one that requires optimizing fast
              (~millisecond) spike-based interactions for efficient encoding of
              information, and a delayed memory XOR task over extended duration
              (~second). The results show that our method indeed optimizes the
              spiking network dynamics on the time scale of individual spikes
              as well as behavioral time scales. In conclusion, our result
              offers a general purpose supervised learning algorithm for
              spiking neural networks, thus advancing further investigations on
              spike-based computation.",
  month    =  "14~" # jun,
  year     =  2017,
  keywords = "Mendeley Import (Apr 20)",
  arxivid  = "1706.04698"
}

@ARTICLE{Bohte2002-pr,
  title     = "Error-backpropagation in temporally encoded networks of spiking
               neurons",
  author    = "Bohte, Sander M and Kok, Joost N and La Poutr{\'e}, Han",
  abstract  = "For a network of spiking neurons that encodes information in the
               timing of individual spike times, we derive a supervised
               learning rule, SpikeProp, akin to traditional
               error-backpropagation. With this algorithm, we demonstrate how
               networks of spiking neurons with biologically reasonable action
               potentials can perform complex non-linear classification in fast
               temporal coding just as well as rate-coded networks. We perform
               experiments for the classical XOR problem, when posed in a
               temporal setting, as well as for a number of other benchmark
               datasets. Comparing the (implicit) number of spiking neurons
               required for the encoding of the interpolated XOR problem, the
               trained networks demonstrate that temporal coding is a viable
               code for fast neural information processing, and as such
               requires less neurons than instantaneous rate-coding.
               Furthermore, we find that reliable temporal computation in the
               spiking networks was only accomplished when using spike response
               functions with a time constant longer than the coding interval,
               as has been predicted by theoretical considerations.",
  journal   = "Neurocomputing",
  publisher = "Elsevier",
  volume    =  48,
  number    = "1-4",
  pages     = "17--37",
  month     =  "1~" # oct,
  year      =  2002,
  keywords  = "Mendeley Import (Apr 20)/SNN",
  issn      = "0925-2312",
  doi       = "10.1016/S0925-2312(01)00658-0"
}

@ARTICLE{Le2011-eo,
  title    = "Building high-level features using large scale unsupervised
              learning",
  author   = "Le, Quoc V and Ranzato, Marc'aurelio and Monga, Rajat and Devin,
              Matthieu and Chen, Kai and Corrado, Greg S and Dean, Jeff and Ng,
              Andrew Y",
  abstract = "We consider the problem of building high-level, class-specific
              feature detectors from only unlabeled data. For example, is it
              possible to learn a face detector using only unlabeled images? To
              answer this, we train a 9-layered locally connected sparse
              autoencoder with pooling and local contrast normalization on a
              large dataset of images (the model has 1 billion connections, the
              dataset has 10 million 200x200 pixel images downloaded from the
              Internet). We train this network using model parallelism and
              asynchronous SGD on a cluster with 1,000 machines (16,000 cores)
              for three days. Contrary to what appears to be a widely-held
              intuition, our experimental results reveal that it is possible to
              train a face detector without having to label images as
              containing a face or not. Control experiments show that this
              feature detector is robust not only to translation but also to
              scaling and out-of-plane rotation. We also find that the same
              network is sensitive to other high-level concepts such as cat
              faces and human bodies. Starting with these learned features, we
              trained our network to obtain 15.8\% accuracy in recognizing
              20,000 object categories from ImageNet, a leap of 70\% relative
              improvement over the previous state-of-the-art.",
  month    =  "28~" # dec,
  year     =  2011,
  keywords = "Mendeley Import (Apr 20)",
  arxivid  = "1112.6209"
}

@MISC{Cornell_University_undated-me,
  title        = "Approach to the Problem ({IRL}) : Machine Learning for {ICS}",
  author       = "{Cornell University}",
  howpublished = "\url{http://blogs.cornell.edu/ml4ics/2011/05/09/approach-to-the-problem-irl/}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@MISC{Wikimedia_Commons_undated-yw,
  title        = "{RL} Systme Image",
  author       = "{Wikimedia Commons}",
  howpublished = "\url{https://commons.wikimedia.org/wiki/File:Reinforcement_learning_diagram.svg}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@MISC{Tambet_Matiisen2015-hl,
  title        = "Guest Post (Part I): Demystifying Deep Reinforcement Learning
                  - Intel {AI}",
  booktitle    = "Intel {AI}",
  author       = "{Tambet Matiisen}",
  year         =  2015,
  howpublished = "\url{https://ai.intel.com/demystifying-deep-reinforcement-learning/}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Silver2017-sw,
  title     = "Mastering the game of Go without human knowledge",
  author    = "Silver, David and Schrittwieser, Julian and Simonyan, Karen and
               Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert,
               Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and
               Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre,
               Laurent and van den Driessche, George and Graepel, Thore and
               Hassabis, Demis",
  abstract  = "To beat world champions at the game of Go, the computer program
               AlphaGo has relied largely on supervised learning from millions
               of human expert moves. David Silver and colleagues have now
               produced a system called AlphaGo Zero, which is based purely on
               reinforcement learning and learns solely from self-play.
               Starting from random moves, it can reach superhuman level in
               just a couple of days of training and five million games of
               self-play, and can now beat all previous versions of AlphaGo.
               Because the machine independently discovers the same fundamental
               principles of the game that took humans millennia to
               conceptualize, the work suggests that such principles have some
               universal character, beyond human bias.",
  journal   = "Nature",
  publisher = "Nature Publishing Group",
  volume    =  550,
  number    =  7676,
  pages     = "354--359",
  month     =  "18~" # oct,
  year      =  2017,
  keywords  = "Computational science; Computer science; Reward;Mendeley Import
               (Apr 20)/SNN",
  issn      = "0028-0836",
  doi       = "10.1038/nature24270"
}

@ARTICLE{Evans2015-yk,
  title    = "Reinforcement Learning in a Neurally Controlled Robot Using
              Dopamine Modulated {STDP}",
  author   = "Evans, Richard",
  abstract = "Recent work has shown that dopamine-modulated STDP can solve many
              of the issues associated with reinforcement learning, such as the
              distal reward problem. Spiking neural networks provide a useful
              technique in implementing reinforcement learning in an embodied
              context as they can deal with continuous parameter spaces and as
              such are better at generalizing the correct behaviour to perform
              in a given context. In this project we implement a version of
              DA-modulated STDP in an embodied robot on a food foraging task.
              Through simulated dopaminergic neurons we show how the robot is
              able to learn a sequence of behaviours in order to achieve a food
              reward. In tests the robot was able to learn food-attraction
              behaviour, and subsequently unlearn this behaviour when the
              environment changed, in all 50 trials. Moreover we show that the
              robot is able to operate in an environment whereby the optimal
              behaviour changes rapidly and so the agent must constantly
              relearn. In a more complex environment, consisting of
              food-containers, the robot was able to learn food-container
              attraction in 95\% of trials, despite the large temporal distance
              between the correct behaviour and the reward. This is achieved by
              shifting the dopamine response from the primary stimulus (food)
              to the secondary stimulus (food-container). Our work provides
              insights into the reasons behind some observed biological
              phenomena, such as the bursting behaviour observed in
              dopaminergic neurons. As well as demonstrating how spiking neural
              network controlled robots are able to solve a range of
              reinforcement learning tasks.",
  month    =  "21~" # feb,
  year     =  2015,
  keywords = "Mendeley Import (Apr 20)",
  arxivid  = "1502.06096"
}

@MISC{Weisstein_undated-bc,
  title        = "Markov Chain",
  author       = "Weisstein, Eric W",
  publisher    = "Wolfram Research, Inc.",
  howpublished = "\url{http://mathworld.wolfram.com/MarkovChain.html}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Melo_undated-yz,
  title    = "Convergence of Q-learning: a simple proof",
  author   = "Melo, Francisco S",
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@MISC{noauthor_2017-fj,
  title        = "The Race for {Self-Driving} Cars - The New York Times",
  booktitle    = "The New York Times",
  abstract     = "Guilbert Gates Kevin Granville John Markoff Karl Russell
                  Anjali Singhvi Neal Boudette",
  year         =  2017,
  howpublished = "\url{https://www.nytimes.com/interactive/2016/12/14/technology/how-self-driving-cars-work.html?_r=0}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Bagloee2016-ot,
  title     = "Autonomous vehicles: challenges, opportunities, and future
               implications for transportation policies",
  author    = "Bagloee, Saeed Asadi and Tavana, Madjid and Asadi, Mohsen and
               Oliver, Tracey",
  journal   = "Journal of Modern Transportation",
  publisher = "Springer Berlin Heidelberg",
  volume    =  24,
  number    =  4,
  pages     = "284--303",
  month     =  "29~" # dec,
  year      =  2016,
  keywords  = "Mendeley Import (Apr 20)",
  issn      = "2095-087X",
  doi       = "10.1007/s40534-016-0117-3"
}

@MISC{Murray_Campbell2017-aw,
  title        = "20 Years After Deep Blue, a New Era in {Human-Machine}
                  Collaboration - {THINK} Blog",
  author       = "{Murray Campbell}",
  year         =  2017,
  howpublished = "\url{https://www.ibm.com/blogs/think/2017/05/deep-blue/}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@MISC{Michael_Barnard2016-ee,
  title        = "Tesla and Google Disagree About {LIDAR} -- Which Is Right? |
                  {CleanTechnica}",
  booktitle    = "Clean Technica",
  author       = "{Michael Barnard}",
  year         =  2016,
  howpublished = "\url{https://cleantechnica.com/2016/07/29/tesla-google-disagree-lidar-right/}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@MISC{Lex_Fridman2018-sl,
  title        = "{MIT} 6.S094: Deep Learning for {Self-Driving} Cars",
  booktitle    = "massachusetts institute of technology",
  author       = "{Lex Fridman} and {Benedikt Jenik} and {Li Ding} and {Spencer
                  Dodd} and {Dan Brown} and {Michael Glazer} and {Jack
                  Terwilliger} and {Julia Kindelsberger}",
  year         =  2018,
  howpublished = "\url{https://selfdrivingcars.mit.edu/}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@MISC{SmartmicroGroup2017-jo,
  title    = "Smartmicro Automotive Radar {79GHz} High Resolution {3DHD} Multi
              Radar Sensor Data Fusion - {YouTube}",
  author   = "{SmartmicroGroup}",
  year     =  2017,
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@INPROCEEDINGS{Wang2017-em,
  title     = "{DeepVO}: Towards end-to-end visual odometry with deep Recurrent
               Convolutional Neural Networks",
  booktitle = "2017 {IEEE} International Conference on Robotics and Automation
               ({ICRA})",
  author    = "Wang, Sen and Clark, Ronald and Wen, Hongkai and Trigoni, Niki",
  publisher = "IEEE",
  pages     = "2043--2050",
  month     =  may,
  year      =  2017,
  keywords  = "Mendeley Import (Apr 20)/SNN",
  isbn      = "9781509046331",
  doi       = "10.1109/ICRA.2017.7989236"
}

@MISC{Dharmendra_S_Modha_undated-is,
  title        = "{IBM} Research: Brain-inspired Chip",
  author       = "{Dharmendra S. Modha}",
  howpublished = "\url{http://www.research.ibm.com/articles/brain-chip.shtml}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Furber2013-ch,
  title    = "Overview of the {SpiNNaker} System Architecture",
  author   = "Furber, Steve B and Lester, David R and Plana, Luis A and
              Garside, Jim D and Painkras, Eustace and Temple, Steve and Brown,
              Andrew D",
  journal  = "IEEE Trans. Comput.",
  volume   =  62,
  number   =  12,
  pages    = "2454--2467",
  month    =  dec,
  year     =  2013,
  keywords = "Mendeley Import (Apr 20)/SNN",
  issn     = "0018-9340",
  doi      = "10.1109/TC.2012.142"
}

@MISC{Asirt_undated-sb,
  title        = "Road Crash Statistics",
  author       = "{Asirt}",
  howpublished = "\url{http://asirt.org/initiatives/informing-road-users/road-safety-facts/road-crash-statistics}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Lanctot2017-af,
  title     = "Autonomous Vehicle Service",
  author    = "Lanctot, Roger",
  abstract  = "Intel has engaged Strategy Analytics as a partner in the
               preparation of this report to validate the hypothesis that a ``
               Passenger Economy '' based on pilotless vehicles is on the
               horizon and that it holds massive economic potential. In
               assessing this opportunity, Strategy Analytics and Intel aim to
               start a conversation that explores the catalysts for change,
               frames the value or economic opportunity, and begins to build
               use cases that can enable business decision makers to explore
               and develop actionable change strategies.",
  journal   = "Autonomous Vehicle Service",
  publisher = "AVS",
  year      =  2017,
  keywords  = "Mendeley Import (Apr 20)/SNN"
}

@MISC{noauthor_undated-fn,
  title        = "{GM} Will Launch a {Self-Driving} Car Without a Steering
                  Wheel in 2019 | {WIRED}",
  booktitle    = "Wired",
  howpublished = "\url{https://www.wired.com/story/gm-cruise-self-driving-car-launch-2019/}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@MISC{Guardian_undated-ks,
  title        = "Tesla car that crashed and killed driver was running on
                  Autopilot, firm says | Technology | The Guardian",
  author       = "{Guardian}",
  howpublished = "\url{https://www.theguardian.com/technology/2018/mar/31/tesla-car-crash-autopilot-mountain-view}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@MISC{noauthor_undated-gm,
  title        = "Details about the fatal Tesla Autopilot crash released -
                  Business Insider",
  howpublished = "\url{http://uk.businessinsider.com/details-about-the-fatal-tesla-autopilot-accident-released-2017-6}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@MISC{noauthor_undated-wq,
  title        = "Self-driving Uber kills Arizona woman in first fatal crash
                  involving pedestrian | Technology | The Guardian",
  booktitle    = "Guardian",
  howpublished = "\url{https://www.theguardian.com/technology/2018/mar/19/uber-self-driving-car-kills-woman-arizona-tempe}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@MISC{OpenAi_undated-cu,
  title        = "Universe",
  author       = "{OpenAi}",
  howpublished = "\url{https://blog.openai.com/universe/}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@MISC{Alex_Nichol2017-rn,
  title    = "niverse",
  author   = "{Alex Nichol} and {Unixpickle}",
  year     =  2017,
  keywords = "Mendeley Import (Apr 20)"
}

@MISC{Udacity2017-uk,
  title    = "Self driving car sim",
  author   = "{Udacity}",
  year     =  2017,
  keywords = "Mendeley Import (Apr 20)"
}

@MISC{Commaai_undated-jf,
  title    = "openpilot",
  author   = "{Commaai}",
  keywords = "Mendeley Import (Apr 20)"
}

@ARTICLE{Beattie2016-go,
  title    = "{DeepMind} Lab",
  author   = "Beattie, Charles and Leibo, Joel Z and Teplyashin, Denis and
              Ward, Tom and Wainwright, Marcus and K{\"u}ttler, Heinrich and
              Lefrancq, Andrew and Green, Simon and Vald{\'e}s, V{\'\i}ctor and
              Sadik, Amir and Schrittwieser, Julian and Anderson, Keith and
              York, Sarah and Cant, Max and Cain, Adam and Bolton, Adrian and
              Gaffney, Stephen and King, Helen and Hassabis, Demis and Legg,
              Shane and Petersen, Stig",
  abstract = "DeepMind Lab is a first-person 3D game platform designed for
              research and development of general artificial intelligence and
              machine learning systems. DeepMind Lab can be used to study how
              autonomous artificial agents may learn complex tasks in large,
              partially observed, and visually diverse worlds. DeepMind Lab has
              a simple and flexible API enabling creative task-designs and
              novel AI-designs to be explored and quickly iterated upon. It is
              powered by a fast and widely recognised game engine, and tailored
              for effective use by the research community.",
  year     =  2016,
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Dosovitskiy_undated-hv,
  title    = "{CARLA}: An Open Urban Driving Simulator",
  author   = "Dosovitskiy, Alexey and Ros, German and Codevilla, Felipe and
              L{\'o}pez, Antonio and Koltun, Vladlen",
  abstract = "We introduce CARLA, an open-source simulator for autonomous
              driv-ing research. CARLA has been developed from the ground up to
              support devel-opment, training, and validation of autonomous
              urban driving systems. In ad-dition to open-source code and
              protocols, CARLA provides open digital assets (urban layouts,
              buildings, vehicles) that were created for this purpose and can
              be used freely. The simulation platform supports flexible
              specification of sensor suites and environmental conditions. We
              use CARLA to study the performance of three approaches to
              autonomous driving: a classic modular pipeline, an end-to-end
              model trained via imitation learning, and an end-to-end model
              trained via reinforcement learning. The approaches are evaluated
              in controlled scenarios of increasing difficulty, and their
              performance is examined via metrics provided by CARLA,
              illustrating the platform's utility for autonomous driving
              research.",
  keywords = "Autonomous driving; sensorimotor control; simulation;Mendeley
              Import (Apr 20)/SNN"
}

@MISC{Microsoft2017-ls,
  title    = "{AirSim}",
  author   = "{Microsoft}",
  year     =  2017,
  keywords = "Mendeley Import (Apr 20)"
}

@MISC{NumPy2018-bd,
  title        = "{NumPy} --- {NumPy}",
  author       = "{NumPy}",
  year         =  2018,
  howpublished = "\url{http://www.numpy.org/}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@MISC{Google_undated-uw,
  title    = "{TensorBoard}: Visualizing Learning | {TensorFlow}",
  author   = "{Google}",
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@MISC{Microsoft_undated-ys,
  title    = "Microsoft Cognitive Toolkit",
  author   = "{Microsoft}",
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@MISC{noauthor_2018-bg,
  title        = "{AirSim} Issue 1009",
  year         =  2018,
  howpublished = "\url{https://github.com/Microsoft/AirSim/issues/1009}",
  keywords     = "Mendeley Import (Apr 20)"
}

@MISC{Udacity_undated-jv,
  title        = "{Self-Driving} Car | Udacity",
  author       = "{Udacity}",
  howpublished = "\url{https://eu.udacity.com/course/self-driving-car-engineer-nanodegree--nd013}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Tobin2017-of,
  title    = "Domain Randomization for Transferring Deep Neural Networks from
              Simulation to the Real World",
  author   = "Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas
              and Zaremba, Wojciech and Abbeel, Pieter",
  abstract = "Bridging the 'reality gap' that separates simulated robotics from
              experiments on hardware could accelerate robotic research through
              improved data availability. This paper explores domain
              randomization, a simple technique for training models on
              simulated images that transfer to real images by randomizing
              rendering in the simulator. With enough variability in the
              simulator, the real world may appear to the model as just another
              variation. We focus on the task of object localization, which is
              a stepping stone to general robotic manipulation skills. We find
              that it is possible to train a real-world object detector that is
              accurate to $1.5$cm and robust to distractors and partial
              occlusions using only data from a simulator with non-realistic
              random textures. To demonstrate the capabilities of our
              detectors, we show they can be used to perform grasping in a
              cluttered environment. To our knowledge, this is the first
              successful transfer of a deep neural network trained only on
              simulated RGB images (without pre-training on real images) to the
              real world for the purpose of robotic control.",
  month    =  "20~" # mar,
  year     =  2017,
  keywords = "Mendeley Import (Apr 20)",
  arxivid  = "1703.06907"
}

@MISC{Michael_Gygli2018-ig,
  title        = "Tensorboard logging",
  author       = "{Michael Gygli}",
  abstract     = "Logging to tensorboard without tensorflow operations. Uses
                  manually generated summaries instead of summary ops",
  year         =  2018,
  howpublished = "\url{https://gist.github.com/gyglim/1f8dfb1b5c82627ae3efcfbbadb9f514}",
  keywords     = "Mendeley Import (Apr 20)"
}

@MISC{Unreal_Engine_undated-ry,
  title        = "Packaging Projects",
  author       = "{Unreal Engine}",
  howpublished = "\url{https://docs.unrealengine.com/en-US/Engine/Basics/Projects/Packaging}",
  keywords     = "Mendeley Import (Apr 20)/SNN",
  doi          = "https://docs.unrealengine.com/en-US/Engine/Basics/Projects/Packaging"
}

@MISC{noauthor_undated-qf,
  title        = "Free {3D} Models download - {Free3D}",
  howpublished = "\url{https://free3d.com/3d-models/}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@MISC{Vlad_Ungureanu_undated-ux,
  title        = "Final Year Project - {YouTube}",
  author       = "{Vlad Ungureanu}",
  howpublished = "\url{https://www.youtube.com/playlist?list=PL8SVA7tuW4LpZ_ux4ARlDnDL-MOsU27RL}",
  keywords     = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Pearl_undated-yo,
  title    = "The Seven Pillars of Causal Reasoning with Reflections on Machine
              Learning",
  author   = "Pearl, Judea",
  abstract = "Systems that operate in purely statistical mode of inference
              entails theoretical limits on their power and performance. Such
              systems cannot reason about interventions and retrospection and,
              therefore, cannot serve as the basis for strong AI. To achieve
              human-level intelligence, learning machines need the guidance of
              a model of external reality, similar to the ones used in causal
              inference tasks. To demonstrate the essential role of such
              models, this paper presents a summary of seven tasks which are
              beyond reach of associational learning systems and which have
              been accomplished using the tools of causal modeling.",
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Aytar_undated-uj,
  title    = "Playing hard exploration games by watching {YouTube}",
  author   = "Aytar, Yusuf and Pfaff, Tobias and Budden, David and Le Paine,
              Tom and Wang, Ziyu and De Freitas, Nando",
  abstract = "Deep reinforcement learning methods traditionally struggle with
              tasks where en-vironment rewards are particularly sparse. One
              successful method of guiding exploration in these domains is to
              imitate trajectories provided by a human demon-strator. However,
              these demonstrations are typically collected under artificial
              conditions, i.e. with access to the agent's exact environment
              setup and the demon-strator's action and reward trajectories.
              Here we propose a two-stage method that overcomes these
              limitations by relying on noisy, unaligned footage without access
              to such data. First, we learn to map unaligned videos from
              multiple sources to a common representation using self-supervised
              objectives constructed over both time and modality (i.e. vision
              and sound). Second, we embed a single YouTube video in this
              representation to construct a reward function that encourages an
              agent to imitate human gameplay. This method of one-shot
              imitation allows our agent to convincingly exceed human-level
              performance on the infamously hard exploration games MONTEZUMA'S
              REVENGE, PITFALL! and PRIVATE EYE for the first time , even if
              the agent is not presented with any environment rewards.",
  keywords = "Mendeley Import (Apr 20)/SNN"
}

@ARTICLE{Fabbri_undated-dl,
  title    = "{D-GAN}: Autonomous Driving using Generative Adversarial Networks",
  author   = "Fabbri, Cameron and Sharma, Jayant",
  keywords = "Mendeley Import (Apr 20)"
}

@ARTICLE{Zhang2018-jm,
  title    = "{DeepRoad}: {GAN-based} Metamorphic Autonomous Driving System
              Testing",
  author   = "Zhang, Mengshi and Zhang, Yuqun and Zhang, Lingming and Liu, Cong
              and Khurshid, Sarfraz",
  abstract = "While Deep Neural Networks (DNNs) have established the
              fundamentals of DNN-based autonomous driving systems, they may
              exhibit erroneous behaviors and cause fatal accidents. To resolve
              the safety issues of autonomous driving systems, a recent set of
              testing techniques have been designed to automatically generate
              test cases, e.g., new input images transformed from the original
              ones. Unfortunately, many such generated input images often
              render inferior authenticity, lacking accurate semantic
              information of the driving scenes and hence compromising the
              resulting efficacy and reliability. In this paper, we propose
              DeepRoad, an unsupervised framework to automatically generate
              large amounts of accurate driving scenes to test the consistency
              of DNN-based autonomous driving systems across different scenes.
              In particular, DeepRoad delivers driving scenes with various
              weather conditions (including those with rather extreme
              conditions) by applying the Generative Adversarial Networks
              (GANs) along with the corresponding real-world weather scenes.
              Moreover, we have implemented DeepRoad to test three
              well-recognized DNN-based autonomous driving systems.
              Experimental results demonstrate that DeepRoad can detect
              thousands of behavioral inconsistencies in these systems.",
  month    =  "6~" # feb,
  year     =  2018,
  keywords = "Mendeley Import (Apr 20)",
  arxivid  = "1802.02295"
}

@INPROCEEDINGS{Mohapatra2019-ri,
  title     = "Exploring deep spiking neural networks for automated driving
               applications",
  booktitle = "{VISIGRAPP} 2019 - Proceedings of the 14th International Joint
               Conference on Computer Vision, Imaging and Computer Graphics
               Theory and Applications",
  author    = "Mohapatra, Sambit and Gotzig, Heinrich and Yogamani, Senthil and
               Milz, Stefan and Z{\"o}llner, Raoul",
  abstract  = "Neural networks have become the standard model for various
               computer vision tasks in automated driving including semantic
               segmentation, moving object detection, depth estimation, visual
               odometry, etc. The main flavors of neural networks which are
               used commonly are convolutional (CNN) and recurrent (RNN). In
               spite of rapid progress in embedded processors, power
               consumption and cost is still a bottleneck. Spiking Neural
               Networks (SNNs) are gradually progressing to achieve low-power
               event-driven hardware architecture which has a potential for
               high efficiency. In this paper, we explore the role of deep
               spiking neural networks (SNN) for automated driving
               applications. We provide an overview of progress on SNN and
               argue how it can be a good fit for automated driving
               applications.",
  year      =  2019,
  keywords  = "Automated Driving; Efficient Networks; Visual
               Perception;Mendeley Import (Apr 20)",
  isbn      = "9789897583544"
}

@MISC{Tavanaei2019-qo,
  title    = "Deep learning in spiking neural networks",
  author   = "Tavanaei, Amirhossein and Ghodrati, Masoud and Kheradpisheh,
              Saeed Reza and Masquelier, Timoth{\'e}e and Maida, Anthony",
  abstract = "In recent years, deep learning has revolutionized the field of
              machine learning, for computer vision in particular. In this
              approach, a deep (multilayer) artificial neural network (ANN) is
              trained, most often in a supervised manner using backpropagation.
              Vast amounts of labeled training examples are required, but the
              resulting classification accuracy is truly impressive, sometimes
              outperforming humans. Neurons in an ANN are characterized by a
              single, static, continuous-valued activation. Yet biological
              neurons use discrete spikes to compute and transmit information,
              and the spike times, in addition to the spike rates, matter.
              Spiking neural networks (SNNs) are thus more biologically
              realistic than ANNs, and are arguably the only viable option if
              one wants to understand how the brain computes at the neuronal
              description level. The spikes of biological neurons are sparse in
              time and space, and event-driven. Combined with bio-plausible
              local learning rules, this makes it easier to build low-power,
              neuromorphic hardware for SNNs. However, training deep SNNs
              remains a challenge. Spiking neurons' transfer function is
              usually non-differentiable, which prevents using backpropagation.
              Here we review recent supervised and unsupervised methods to
              train deep SNNs, and compare them in terms of accuracy and
              computational cost. The emerging picture is that SNNs still lag
              behind ANNs in terms of accuracy, but the gap is decreasing, and
              can even vanish on some tasks, while SNNs typically require many
              fewer operations and are the better candidates to process
              spatio-temporal data.",
  journal  = "Neural Networks",
  year     =  2019,
  keywords = "Biological plausibility; Deep learning; Machine learning;
              Power-efficient architecture; Spiking neural network;Mendeley
              Import (Apr 20)",
  issn     = "1879-2782",
  doi      = "10.1016/j.neunet.2018.12.002"
}

@ARTICLE{Merolla2014-mb,
  title    = "A million spiking-neuron integrated circuit with a scalable
              communication network and interface",
  author   = "Merolla, Paul A and Arthur, John V and Alvarez-Icaza, Rodrigo and
              Cassidy, Andrew S and Sawada, Jun and Akopyan, Filipp and
              Jackson, Bryan L and Imam, Nabil and Guo, Chen and Nakamura,
              Yutaka and Brezzo, Bernard and Vo, Ivan and Esser, Steven K and
              Appuswamy, Rathinakumar and Taba, Brian and Amir, Arnon and
              Flickner, Myron D and Risk, William P and Manohar, Rajit and
              Modha, Dharmendra S",
  abstract = "Inspired by the brain's structure, we have developed an
              efficient, scalable, and flexible non-von Neumann architecture
              that leverages contemporary silicon technology. To demonstrate,
              we built a 5.4-billion-transistor chip with 4096 neurosynaptic
              cores interconnected via an intrachip network that integrates 1
              million programmable spiking neurons and 256 million configurable
              synapses. Chips can be tiled in two dimensions via an interchip
              communication interface, seamlessly scaling the architecture to a
              cortexlike sheet of arbitrary size. The architecture is well
              suited to many applications that use complex neural networks in
              real time, for example, multiobject detection and classification.
              With 400-pixel-by-240-pixel video input at 30 frames per second,
              the chip consumes 63 milliwatts.",
  journal  = "Science",
  volume   =  345,
  number   =  6197,
  pages    = "668--673",
  month    =  "8~" # aug,
  year     =  2014,
  keywords = "Mendeley Import (Apr 20)",
  issn     = "0036-8075",
  doi      = "10.1126/science.1254642"
}

@ARTICLE{Wunderlich2019-er,
  title    = "Demonstrating Advantages of Neuromorphic Computation: A Pilot
              Study",
  author   = "Wunderlich, Timo and Kungl, Akos F and M{\"u}ller, Eric and
              Hartel, Andreas and Stradmann, Yannik and Aamir, Syed Ahmed and
              Gr{\"u}bl, Andreas and Heimbrecht, Arthur and Schreiber,
              Korbinian and St{\"o}ckel, David and Pehle, Christian and
              Billaudelle, Sebastian and Kiene, Gerd and Mauch, Christian and
              Schemmel, Johannes and Meier, Karlheinz and Petrovici, Mihai A",
  abstract = "Neuromorphic devices represent an attempt to mimic aspects of the
              brain's architecture and dynamics with the aim of replicating its
              hallmark functional capabilities in terms of computational power,
              robust learning and energy efficiency. We employ a single-chip
              prototype of the BrainScaleS 2 neuromorphic system to implement a
              proof-of-concept demonstration of reward-modulated
              spike-timing-dependent plasticity in a spiking network that
              learns to play the Pong video game by smooth pursuit. This system
              combines an electronic mixed-signal substrate for emulating
              neuron and synapse dynamics with an embedded digital processor
              for on-chip learning, which in this work also serves to simulate
              the virtual environment and learning agent. The analog emulation
              of neuronal membrane dynamics enables a 1000-fold acceleration
              with respect to biological real-time, with the entire chip
              operating on a power budget of 57mW. Compared to an equivalent
              simulation using state-of-the-art software, the on-chip emulation
              is at least one order of magnitude faster and three orders of
              magnitude more energy-efficient. We demonstrate how on-chip
              learning can mitigate the effects of fixed-pattern noise, which
              is unavoidable in analog substrates, while making use of temporal
              variability for action exploration. Learning compensates
              imperfections of the physical substrate, as manifested in
              neuronal parameter variability, by adapting synaptic weights to
              match respective excitability of individual neurons.",
  journal  = "Front. Neurosci.",
  volume   =  13,
  month    =  "26~" # mar,
  year     =  2019,
  keywords = "Mendeley Import (Apr 20)",
  issn     = "1662-4548, 1662-453X",
  doi      = "10.3389/fnins.2019.00260"
}

@ARTICLE{Stringer2006-fj,
  title    = "Learning invariant object recognition in the visual system with
              continuous transformations",
  author   = "Stringer, S M and Perry, G and Rolls, E T and Proske, J H",
  abstract = "The cerebral cortex utilizes spatiotemporal continuity in the
              world to help build invariant representations. In vision, these
              might be representations of objects. The temporal continuity
              typical of objects has been used in an associative learning rule
              with a short-term memory trace to help build invariant object
              representations. In this paper, we show that spatial continuity
              can also provide a basis for helping a system to self-organize
              invariant representations. We introduce a new learning paradigm
              ``continuous transformation learning'' which operates by mapping
              spatially similar input patterns to the same postsynaptic neurons
              in a competitive learning system. As the inputs move through the
              space of possible continuous transforms (e.g. translation,
              rotation, etc.), the active synapses are modified onto the set of
              postsynaptic neurons. Because other transforms of the same
              stimulus overlap with previously learned exemplars, a common set
              of postsynaptic neurons is activated by the new transforms, and
              learning of the new active inputs onto the same postsynaptic
              neurons is facilitated. We demonstrate that a hierarchical model
              of cortical processing in the ventral visual system can be
              trained with continuous transform learning, and highlight
              differences in the learning of invariant representations to those
              achieved by trace learning.",
  journal  = "Biol. Cybern.",
  volume   =  94,
  number   =  2,
  pages    = "128--142",
  month    =  "21~" # feb,
  year     =  2006,
  keywords = "Mendeley Import (Apr 20)",
  issn     = "0340-1200",
  doi      = "10.1007/s00422-005-0030-z"
}

@ARTICLE{Asaad2000-hg,
  title    = "{Task-Specific} Neural Activity in the Primate Prefrontal Cortex",
  author   = "Asaad, Wael F and Rainer, Gregor and Miller, Earl K",
  abstract = "Real-world behavior is typically more complicated than a
              one-to-one mapping between a stimulus and response; the same
              stimulus can lead to different behaviors depending on the
              situation, or the same behavior may be cued by different stimuli.
              In such cases, knowledge of the formal demands of the task at
              hand is required. We found that in monkeys trained to alternate
              between three tasks, the activity of many neurons in the
              prefrontal cortex was task dependent. This included changes in
              overall firing rate, in firing- rate profiles (shape of responses
              over time), and in stimulus and response selectivity. These
              findings support the hypothesis that a major prefrontal function
              is the acquisition and implementation of task context and the
              'rules' used to guide behavior.",
  journal  = "J. Neurophysiol.",
  volume   =  84,
  number   =  1,
  pages    = "451--459",
  month    =  jul,
  year     =  2000,
  keywords = "Mendeley Import (Apr 20)",
  issn     = "0022-3077",
  doi      = "10.1152/jn.2000.84.1.451"
}

@ARTICLE{Hung2012-pr,
  title    = "Medial Axis Shape Coding in Macaque Inferotemporal Cortex",
  author   = "Hung, Chia Chun and Carlson, Eric T and Connor, Charles E",
  abstract = "The basic, still unanswered question about visual object
              representation is this: what specific information is encoded by
              neural signals? Theorists have long predicted that neurons would
              encode medial axis or skeletal object shape, yet recent studies
              reveal instead neural coding of boundary or surface shape. Here,
              we addressed this theoretical/experimental disconnect, using
              adaptive shape sampling to demonstrate explicit coding of medial
              axis shape in high-level object cortex (macaque monkey
              inferotemporal cortex or IT). Our metric shape analyses revealed
              a coding continuum, along which most neurons represent a
              configuration of both medial axis and surface components. Thus,
              IT response functions embody a rich basis set for simultaneously
              representing skeletal and external shape of complex objects. This
              would be especially useful for representing biological shapes,
              which are often characterized by both complex, articulated
              skeletal structure and specific surface features.",
  journal  = "Neuron",
  pages    = "1099--1113",
  year     =  2012,
  keywords = "Mendeley Import (Apr 20)",
  issn     = "0896-6273",
  pmid     = "22726839",
  doi      = "10.1016/j.neuron.2012.04.029"
}

@ARTICLE{Lescroart2013-tn,
  title    = "Cortical Representation of Medial Axis Structure",
  author   = "Lescroart, Mark D and Biederman, Irving",
  abstract = "The identity of an object is not only specified by its parts but
              also by the relations among the parts. Rearranging parts can
              produce a completely different object, in the same manner as
              rearranging the phonemes in ``fur'' can yield ``rough.'' How does
              the visual system represent the relative positions of parts?
              Between-part relations can be characterized by specifying the
              relations between the medial axes (imaginary lines through the
              centers) of an object's parts. A functional magnetic resonance
              imaging multivoxel classification study tested whether the medial
              axis structure is represented in the human visual system
              independent of part identity and overall object orientation.
              Stimuli were line drawings of novel 3-part geometrical objects,
              which differed in the relations between their parts' medial axes
              (i.e., in their medial axis structures), the geons that composed
              each object, and the objects' orientations in plane and in depth.
              In regions of interest throughout visual cortex, a support vector
              machine classifier was trained to distinguish objects that shared
              either the same medial axis structures or the same orientations.
              By the level of V3, different medial axis structures were more
              accurately classified than different orientations, indicating a
              change in the representation of shape compared with earlier
              visual areas. \copyright{} 2012 The Author.",
  journal  = "Cereb. Cortex",
  volume   =  23,
  number   =  3,
  pages    = "629--637",
  month    =  mar,
  year     =  2013,
  keywords = "MVPA; V3; fMRI; object recognition; shape recognition;Mendeley
              Import (Apr 20)",
  issn     = "1047-3211, 1460-2199",
  doi      = "10.1093/cercor/bhs046"
}

@ARTICLE{Rainer1998-lw,
  title    = "Selective representation of relevant information by neurons in
              the primate prefrontal cortex",
  author   = "Rainer, Gregor and Asaad, Wael F and Miller, Earl K",
  abstract = "The severe limitation of the capacity of working memory, the
              ability to store temporarily and manipulate information,
              necessitates mechanisms that restrict access to it. Here we
              report tests to discover whether the activity of neurons in the
              prefrontal (PF) cortex, the putative neural correlate of working
              memory, might reflect these mechanisms and preferentially
              represent behaviourally relevant information. Monkeys performed a
              'delayed-matching- to-sample' task with an array of three
              objects. Only one of the objects in the array was relevant for
              task performance and the monkeys needed to find that object (the
              target) and remember its location. For many PF neurons, activity
              to physically identical arrays varied with the target location;
              the location of the non-target objects had little or no influence
              on activity. Information about the target location was present in
              activity as early as 140 ms after array onset. Also, information
              about which object was the target was reflected in the sustained
              activity of many PF neurons. These results suggest that the
              prefrontal cortex is involved in selecting and maintaining
              behaviourally relevant information.",
  journal  = "Nature",
  volume   =  393,
  number   =  6685,
  pages    = "577--579",
  month    =  jun,
  year     =  1998,
  keywords = "Mendeley Import (Apr 20)",
  issn     = "0028-0836",
  pmid     = "9634233",
  doi      = "10.1038/31235"
}

@ARTICLE{Biederman1987-ek,
  title    = "Recognition-by-components: a theory of human image understanding",
  author   = "Biederman, Irving",
  abstract = "The perceptual recognition of objects is conceptualized to be a
              process in which the image of the input is segmented at regions
              of deep concavity into an arrangement of simple geometric
              components, such as blocks, cylinders, wedges, and cones. The
              fundamental assumption of the proposed theory,
              recognition-by-components (RBC), is that a modest set of
              generalized-cone components, called geons (N $\leq$ 36), can be
              derived from contrasts of five readily detectable properties of
              edges in a two-dimensional image: curvature, collinearity,
              symmetry, parallelism, and cotermination. The detection of these
              properties is generally invariant over viewing position and image
              quality and consequently allows robust object perception when the
              image is projected from a novel viewpoint or is degraded. RBC
              thus provides a principled account of the heretofore undecided
              relation between the classic principles of perceptual
              organization and pattern recognition: The constraints toward
              regularization (Pragnanz) characterize not the complete object
              but the object's components. Representational power derives from
              an allowance of free combinations of the geons. A Principle of
              Componential Recovery can account for the major phenomena of
              object recognition: If an arrangement of two or three geons can
              be recovered from the input, objects can be quickly recognized
              even when they are occluded, novel, rotated in depth, or
              extensively degraded. The results from experiments on the
              perception of briefly presented pictures by human observers
              provide empirical support for the theory. \copyright{} 1987
              American Psychological Association.",
  journal  = "Psychol. Rev.",
  volume   =  94,
  number   =  2,
  pages    = "115--147",
  month    =  apr,
  year     =  1987,
  keywords = "Mendeley Import (Apr 20)",
  issn     = "0033-295X",
  pmid     = "3575582",
  doi      = "10.1037/0033-295X.94.2.115"
}

@ARTICLE{Uzzell2004-fr,
  title    = "Precision of Spike Trains in Primate Retinal Ganglion Cells",
  author   = "Uzzell, V J and Chichilnisky, E J",
  abstract = "Recent studies have revealed striking precision in the spike
              trains of retinal ganglion cells in several species and suggested
              that this precision could be an important aspect of visual
              signaling. However, the precision of spike trains has not yet
              been described in primate retina. The spike time and count
              variability of parasol (magnocellular-projecting) retinal
              ganglion cells was examined in isolated macaque monkey retinas
              stimulated with repeated presentations of high contrast,
              spatially uniform intensity modulation. At the onset of clearly
              delineated periods of firing, retinal ganglion cells fired spikes
              time-locked to the stimulus with a variability across trials as
              low as 1 ms. Spike count variance across trials was much lower
              than the mean and sometimes approached the minimum variance
              possible with discrete counts, inconsistent with Poisson
              statistics expected from independently generated spikes. Spike
              time and count variability decreased systematically with stimulus
              strength. These findings were consistent with a model in which
              firing probability was determined by a stimulus-driven free
              firing rate modulated by a recovery function representing the
              action potential absolute and relative refractory period.",
  journal  = "J. Neurophysiol.",
  volume   =  92,
  number   =  2,
  pages    = "780--789",
  month    =  aug,
  year     =  2004,
  keywords = "Mendeley Import (Apr 20)",
  issn     = "0022-3077",
  doi      = "10.1152/jn.01171.2003"
}

@ARTICLE{Diesmann1999-yz,
  title    = "Stable propagation of synchronous spiking in cortical neural
              networks",
  author   = "Diesmann, Markus and Gewaltig, Marc-Oliver and Aertsen, Ad",
  abstract = "The classical view of neural coding has emphasized the importance
              of information carried by the rate at which neurons discharge
              action potentials. More recent proposals that information may be
              carried by precise spike timing have been challenged by the
              assumption that these neurons operate in a noisy fashion -
              presumably reflecting fluctuations in synaptic input and, thus,
              incapable of transmitting signals with millisecond fidelity. Here
              we show that precisely synchronized action potentials can
              propagate within a model of cortical network activity that
              recapitulates many of the features of biological systems. An
              attractor, yielding a stable spiking precision in the
              (sub)millisecond range, governs the dynamics of synchronization.
              Our results indicate that a combinatorial neural code, based on
              rapid associations of groups of neurons co-ordinating their
              activity at the single spike level, is possible within a
              cortical-like network.",
  journal  = "Nature",
  volume   =  402,
  number   =  6761,
  pages    = "529--533",
  month    =  dec,
  year     =  1999,
  keywords = "Mendeley Import (Apr 20)",
  issn     = "0028-0836",
  doi      = "10.1038/990101"
}

@ARTICLE{Wallis1997-gv,
  title    = "{INVARIANT} {FACE} {AND} {OBJECT} {RECOGNITION} {IN} {THE}
              {VISUAL} {SYSTEM}",
  author   = "Wallis, Guy and Rolls, Edmund T",
  abstract = "Neurophysiological evidence is described, showing that some
              neurons in the macaque temporal cortical visual areas have
              responses that are invariant with respect to the position, size
              and view of faces and objects, and that these neurons show rapid
              processing and rapid learning. A theory is then described of how
              such invariant representations may be produced in a
              hierarchically organized set of visual cortical areas with
              convergent connectivity. The theory proposes that neurons in
              these visual areas use a modified Hebb synaptic modification rule
              with a short-term memory trace to capture whatever can be
              captured at each stage that is invariant about objects as the
              object changes in retinal position, size, rotation and view.
              Simulations are then described which explore the operation of the
              architecture. The simulations show that such a processing system
              can build invariant representations of objects.",
  journal  = "Prog. Neurobiol.",
  volume   =  51,
  number   =  2,
  pages    = "167--194",
  month    =  feb,
  year     =  1997,
  keywords = "Mendeley Import (Apr 20)",
  issn     = "0301-0082",
  pmid     = "9247963",
  doi      = "10.1016/S0301-0082(96)00054-8"
}

@ARTICLE{Abeles1993-cr,
  title    = "Spatiotemporal firing patterns in the frontal cortex of behaving
              monkeys",
  author   = "Abeles, M and Bergman, H and Margalit, E and Vaadia, E",
  abstract = "1. Activity of up to 10 single units was recorded in parallel
              from frontal areas of behaving monkeys. 2. Spatiotemporal firing
              patterns were revealed by a method that detects all excessively
              repeating patterns regardless of their complexity or single-unit
              composition. 3. Excess of repeating patterns was found in 30-60\%
              of the cases examined when timing jitter of 1-3 ms was allowed.
              4. An independent test refuted the hypothesis that these patterns
              represented chance events. 5. In a given behavioral condition
              there were usually many different patterns, each repeating
              several times, and not one (or a few) pattern repeating many
              times. 6. In 13 out of 20 cases, when a single unit elevated its
              firing rate in association with an external event beyond 40/s,
              most of the spikes within that period were associated with
              excessively repeating spatiotemporal patterns. 7. Of 157 types of
              patterns whose excess was most marked, 107 were composed of
              spikes from one single unit, 45 of the patterns contained spikes
              from two single units, and only one was composed of spikes from
              three different single units. 8. These properties suggest that
              the patterns were generated by reverberations in a synfire mode
              within self-exciting cell assemblies.",
  journal  = "J. Neurophysiol.",
  volume   =  70,
  number   =  4,
  pages    = "1629--1638",
  month    =  "1~" # oct,
  year     =  1993,
  keywords = "Mendeley Import (Apr 20)/Neurophisiological studies",
  issn     = "0022-3077",
  pmid     = "8283219",
  doi      = "10.1152/jn.1993.70.4.1629"
}

@ARTICLE{Prut1998-xu,
  title    = "Spatiotemporal Structure of Cortical Activity: Properties and
              Behavioral Relevance",
  author   = "Prut, Yifat and Vaadia, Eilon and Bergman, Hagai and Haalman,
              Iris and Slovin, Hamutal and Abeles, Moshe",
  abstract = "Prut, Yifat, Eilon Vaadia, Hagai Bergman, Iris Haalman, Hamutal
              Slovin, and Moshe Abeles. Spatiotemporal structure of cortical
              activity: properties and behavioral relevance. J. Neurophysiol.
              79: 2857--2874, 1998. The study was designed to reveal
              occurrences of precise firing sequences (PFSs) in cortical
              activity and to test their behavioral relevance. Two monkeys were
              trained to perform a delayed-response paradigm and to open puzzle
              boxes. Extracellular activity was recorded from neurons in
              premotor and prefrontal areas with an array of six
              microelectrodes. An algorithm was developed to detect PFSs,
              defined as a set of three spikes and two intervals with a
              precision of $\pm$1 ms repeating significantly more than expected
              by chance. The expected level of repetition was computed based on
              the firing rate and the pairwise correlation of the participating
              units, assuming a Poisson distribution of event counts.
              Accordingly, the search for PFSs was corrected for rate
              modulations. PFSs were found in 24/25 recording sessions. Most
              PFSs (76\%) were composed of spikes of more than one unit but
              usually not more than two units (67\%). The PFSs spanned hundreds
              of milliseconds, and the average interval between two events
              within the PFSs was 200 ms. No traces of periodic oscillations
              were found in the PFS intervals. The bins of the matrix that were
              defined as PFSs were isolated temporally: the spikes that
              generated PFSs were not associated with high-frequency bursts or
              rapid coherent rate fluctuations. A given PFS tended to be
              correlated with the animal's behavior. Furthermore, for 19\% of
              the PFS pairs that shared the same unit composition, each member
              of the pair was associated with a different type of behavior. The
              PFSs often appeared in clusters that were associated with
              particular phases of the behavior. The firing rate of single
              units did not provide a full explanation for the timing and
              structure of these clusters. A reduced spike train (RST) was
              defined for each unit by taking all spikes of that unit that were
              part of any PFS. In 88\% of the cases the degree of modulation of
              the RST was higher than that of the complete spike train. The
              results suggest that relevant information is carried by the fine
              temporal structure of cortical activity. A coding scheme that
              involves such temporal structures is rich and sufficiently
              flexible to facilitate a rapid organization of cortical neurons
              into functional groups. The results can be accounted for by the
              synfire chain model, which suggests that cortical activity is
              mediated by synchronous activation of neural groups in a
              reverberatory mode.",
  journal  = "J. Neurophysiol.",
  volume   =  79,
  number   =  6,
  pages    = "2857--2874",
  month    =  "1~" # jun,
  year     =  1998,
  keywords = "Mendeley Import (Apr 20)/Neurophisiological studies",
  issn     = "0022-3077",
  doi      = "10.1152/jn.1998.79.6.2857"
}

@ARTICLE{Hubel1962-fg,
  title    = "Receptive fields, binocular interaction and functional
              architecture in the cat's visual cortex",
  author   = "Hubel, D H and Wiesel, T N",
  journal  = "J. Physiol.",
  year     =  1962,
  keywords = "Mendeley Import (Apr 20)",
  issn     = "0022-3751, 1469-7793",
  pmid     = "14449617",
  doi      = "10.1113/jphysiol.1962.sp006837"
}

@PHDTHESIS{Ungureanu_undated-gs,
  title    = "A Proof of Concept Spiking Neural Network in Autonomous Vehicles",
  author   = "Ungureanu, Vlad and Halliday, David and Szymanski, John",
  abstract = "Abstract Spiking Neural Networks (SNN) is the third generation of
              Artificial Neural Networks, the paradigm which fuels the current
              progress made in Artificial Intelligence. Compared to the earlier
              generations of Neural Networks, SNNs are a biologically accurate
              framework, which embodies the time characteristics of the nerve
              cells. These consider the arrival time of the presynaptic action
              potential to the postsynaptic neurone, based on which the
              synapses are weakened or strengthened, process known as
              Spike-Timing Dependent Plasticity (STDP). However, there has been
              little research on applying SNNs to real- life applications, and
              in this project, these artificial networks are applied to
              autonomous vehicles problem. Here we propose a system that uses a
              real-physics engine, AirSim, to simulate a car that is controlled
              by an SNN using STDP. The system uses two separate SNNs, designed
              to emulate the sensory-motor coupling and to control the steering
              and throttle of the vehicle. A circuit track was created for
              testing the system containing two types of challenges, ramps and
              road turns, for which was found that the car can drive a ramp,
              but steering in a road tun was proven to be challenging.
              Throughout these tests, the project illustrates the importance of
              using the appropriate encoding for an SNN, and the results
              suggest the potential applications of a biologically accurate
              framework for autonomous vehicles. The software designed is
              versatile, and with minor modifications, it can be applied to
              other problems. We believe that this project enhances the number
              of areas to which SNN can be utilised and lays the path for
              further research and development in using the third generation of
              Artificial Neural Networks to self-driving cars.",
  school   = "University of York",
  keywords = "Mendeley Import (Apr 20)"
}

@ARTICLE{Furber2014-ot,
  title    = "The {SpiNNaker} Project",
  author   = "Furber, Steve B and Galluppi, Francesco and Temple, Steve and
              Plana, Luis A",
  abstract = "The spiking neural network architecture (SpiNNaker) project aims
              to deliver a massively parallel million-core computer whose
              interconnect architecture is inspired by the connectivity
              characteristics of the mammalian brain, and which is suited to
              the modeling of large-scale spiking neural networks in biological
              real time. Specifically, the interconnect allows the transmission
              of a very large number of very small data packets, each conveying
              explicitly the source, and implicitly the time, of a single
              neural action potential or 'spike.' In this paper, we review the
              current state of the project, which has already delivered systems
              with up to 2500 processors, and present the real-time
              event-driven programming model that supports flexible access to
              the resources of the machine and has enabled its use by a wide
              range of collaborators around the world. \copyright{} 2014 IEEE.",
  journal  = "Proc. IEEE",
  volume   =  102,
  number   =  5,
  pages    = "652--665",
  month    =  may,
  year     =  2014,
  keywords = "Brain modeling; multicast algorithms; multiprocessor
              interconnection networks; neural network hardware; parallel
              programming;Mendeley Import (Apr 20)",
  issn     = "0018-9219",
  doi      = "10.1109/JPROC.2014.2304638"
}

@ARTICLE{Davies2018-kx,
  title    = "Loihi: A Neuromorphic Manycore Processor with {On-Chip} Learning",
  author   = "Davies, Mike and Srinivasa, Narayan and Lin, Tsung-Han and
              Chinya, Gautham and Cao, Yongqiang and Choday, Sri Harsha and
              Dimou, Georgios and Joshi, Prasad and Imam, Nabil and Jain,
              Shweta and Liao, Yuyun and Lin, Chit-Kwan and Lines, Andrew and
              Liu, Ruokun and Mathaikutty, Deepak and McCoy, Steven and Paul,
              Arnab and Tse, Jonathan and Venkataramanan, Guruguhanathan and
              Weng, Yi-Hsin and Wild, Andreas and Yang, Yoonseok and Wang, Hong",
  abstract = "Loihi is a 60-mm2 chip fabricated in Intels 14-nm process that
              advances the state-of-the-art modeling of spiking neural networks
              in silicon. It integrates a wide range of novel features for the
              field, such as hierarchical connectivity, dendritic compartments,
              synaptic delays, and, most importantly, programmable synaptic
              learning rules. Running a spiking convolutional form of the
              Locally Competitive Algorithm, Loihi can solve LASSO optimization
              problems with over three orders of magnitude superior
              energy-delay-product compared to conventional solvers running on
              a CPU iso-process/voltage/area. This provides an unambiguous
              example of spike-based computation, outperforming all known
              conventional solutions.",
  journal  = "IEEE Micro",
  volume   =  38,
  number   =  1,
  pages    = "82--99",
  month    =  jan,
  year     =  2018,
  keywords = "artificial intelligence; machine learning; neuromorphic
              computing;Mendeley Import (Apr 20)",
  issn     = "0272-1732",
  doi      = "10.1109/MM.2018.112130359"
}

@ARTICLE{Smith2007-nb,
  title    = "Diagnosis of Parkinson's disease using evolutionary algorithms",
  author   = "Smith, Stephen L and Gaughan, Patrick and Halliday, David M and
              Ju, Quan and Aly, Nabil M and Playfer, Jeremy R",
  abstract = "This paper describes the novel application of an evolutionary
              algorithm to discriminate Parkinson's patients from age-matched
              controls in their response to simple figure-copying tasks. The
              reliable diagnosis of Parkinson's disease is notoriously
              difficult to achieve with misdiagnosis reported to be as high as
              25\% of cases. The approach described in this paper aims to
              distinguish between the velocity profiles of pen movements of
              patients and controls to identify distinguishing artifacts that
              may be indicative of the Parkinson's symptom bradykinesia.
              Results are presented for 12 patients with Parkinson's disease
              and 10 age-match controls. An algorithm was evolved using half
              the patient and age-matched control responses, which was then
              successfully used to correctly classify the remaining responses.
              A more rigorous ``leave one out'' strategy was also applied to
              the test data with encouraging results. \copyright{} 2007
              Springer Science+Business Media, LLC.",
  journal  = "Genet. Program. Evolvable Mach.",
  volume   =  8,
  number   =  4,
  pages    = "433--447",
  month    =  "12~" # nov,
  year     =  2007,
  keywords = "Cartesian genetic programing; Evolutionary algorithms;
              Parkinson's disease;Mendeley Import (Apr 20)",
  issn     = "1389-2576",
  doi      = "10.1007/s10710-007-9043-9"
}

@INPROCEEDINGS{Papernot2017-dl,
  title     = "Practical {Black-Box} Attacks against Machine Learning",
  booktitle = "Proceedings of the 2017 {ACM} on Asia Conference on Computer and
               Communications Security - {ASIA} {CCS} '17",
  author    = "Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and
               Jha, Somesh and Celik, Z Berkay and Swami, Ananthram",
  abstract  = "Machine learning (ML) models, e.g., deep neural networks (DNNs),
               are vulnerable to adversarial examples: malicious inputs
               modified to yield erroneous model outputs, while appearing
               unmodified to human observers. Potential attacks include having
               malicious content like malware identified as legitimate or
               controlling vehicle behavior. Yet, all existing adversarial
               example attacks require knowledge of either the model internals
               or its training data. We introduce the first practical
               demonstration of an attacker controlling a remotely hosted DNN
               with no such knowledge. Indeed, the only capability of our
               black-box adversary is to observe labels given by the DNN to
               chosen inputs. Our attack strategy consists in training a local
               model to substitute for the target DNN, using inputs
               synthetically generated by an adversary and labeled by the
               target DNN. We use the local substitute to craft adversarial
               examples, and find that they are misclassi fied by the targeted
               DNN. To perform a real-world and properly-blinded evaluation, we
               attack a DNN hosted by MetaMind, an online deep learning API. We
               find that their DNN misclassifies 84.24\% of the adversarial
               examples crafted with our substitute. We demonstrate the general
               applicability of our strategy to many ML techniques by
               conducting the same attack against models hosted by Amazon and
               Google, using logistic regression substitutes. They yield
               adversarial examples misclassified by Amazon and Google at rates
               of 96.19\% and 88.94\%. We also find that this black-box attack
               strategy is capable of evading defense strategies previously
               found to make adversarial example crafting harder.",
  publisher = "ACM Press",
  pages     = "506--519",
  year      =  2017,
  address   = "New York, New York, USA",
  keywords  = "Mendeley Import (Apr 20)",
  isbn      = "9781450349444",
  doi       = "10.1145/3052973.3053009"
}

@ARTICLE{Kurakin2016-tv,
  title    = "Adversarial examples in the physical world",
  author   = "Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy",
  abstract = "Most existing machine learning classifiers are highly vulnerable
              to adversarial examples. An adversarial example is a sample of
              input data which has been modified very slightly in a way that is
              intended to cause a machine learning classifier to misclassify
              it. In many cases, these modifications can be so subtle that a
              human observer does not even notice the modification at all, yet
              the classifier still makes a mistake. Adversarial examples pose
              security concerns because they could be used to perform an attack
              on machine learning systems, even if the adversary has no access
              to the underlying model. Up to now, all previous work have
              assumed a threat model in which the adversary can feed data
              directly into the machine learning classifier. This is not always
              the case for systems operating in the physical world, for example
              those which are using signals from cameras and other sensors as
              an input. This paper shows that even in such physical world
              scenarios, machine learning systems are vulnerable to adversarial
              examples. We demonstrate this by feeding adversarial images
              obtained from cell-phone camera to an ImageNet Inception
              classifier and measuring the classification accuracy of the
              system. We find that a large fraction of adversarial examples are
              classified incorrectly even when perceived through the camera.",
  journal  = "5th International Conference on Learning Representations, ICLR
              2017 - Workshop Track Proceedings",
  month    =  "8~" # jul,
  year     =  2016,
  keywords = "Mendeley Import (Apr 20)",
  arxivid  = "1607.02533"
}

@ARTICLE{Pedregosa2011-ts,
  title    = "Scikit-learn: Machine Learning in Python",
  author   = "Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre
              and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and
              Blondel, Mathieu and M{\"u}ller, Andreas and Nothman, Joel and
              Louppe, Gilles and Prettenhofer, Peter and Weiss, Ron and
              Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and
              Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and
              Duchesnay, {\'E}douard",
  abstract = "Scikit-learn is a Python module integrating a wide range of
              state-of-the-art machine learning algorithms for medium-scale
              supervised and unsupervised problems. This package focuses on
              bringing machine learning to non-specialists using a
              general-purpose high-level language. Emphasis is put on ease of
              use, performance, documentation, and API consistency. It has
              minimal dependencies and is distributed under the simplified BSD
              license, encouraging its use in both academic and commercial
              settings. Source code, binaries, and documentation can be
              downloaded from http://scikit-learn.org.",
  journal  = "J. Mach. Learn. Res.",
  volume   =  12,
  pages    = "2825--2830",
  month    =  "2~" # jan,
  year     =  2011,
  keywords = "Model selection; Python; Supervised learning; Unsupervised
              learning;Mendeley Import (Apr 20)",
  issn     = "1532-4435",
  arxivid  = "1201.0490"
}

@ARTICLE{Zhang1996-fc,
  title    = "{BIRCH}",
  author   = "Zhang, Tian and Ramakrishnan, Raghu and Livny, Miron",
  abstract = "Finding useful patterns in large datasets has attracted
              considerable interest recently, and one of the most widely
              studied problems in this area is the identification of clusters,
              or densely populated regions, in a multi-dimensional dataset.
              Prior work does not adequately address the problem of large
              datasets and minimization of I/O costs. This paper presents a
              data clustering method named BIRCH (Balanced Iterative Reducing
              and Clustering using Hierarchies), and demonstrates that it is
              especially suitable for very large databases. BIRCH incrementally
              and dynamically clusters incoming multi-dimensional metric data
              points to try to produce the best quality clustering with the
              available resources (i.e., available memory and time
              constraints). BIRCH can typically find a good clustering with a
              single scan of the data, and improve the quality further with a
              few additional scans. BIRCH is also the first clustering
              algorithm proposed in the database area to handle ``noise'' (data
              points that are not part of the underlying pattern) effectively.
              We evaluate BIRCH's time/space efficiency, data input order
              sensitivity, and clustering quality through several experiments.
              We also present a performance comparisons of BIRCH versus
              CLARANS, a clustering method proposed recently for large
              datasets, and show that BIRCH is consistently superior.",
  journal  = "ACM SIGMOD Record",
  volume   =  25,
  number   =  2,
  pages    = "103--114",
  month    =  "1~" # jun,
  year     =  1996,
  keywords = "Mendeley Import (Apr 20)",
  issn     = "0163-5808",
  doi      = "10.1145/235968.233324"
}

@ARTICLE{Rousseeuw1987-dn,
  title    = "Silhouettes: A graphical aid to the interpretation and validation
              of cluster analysis",
  author   = "Rousseeuw, Peter J",
  abstract = "A new graphical display is proposed for partitioning techniques.
              Each cluster is represented by a so-called silhouette, which is
              based on the comparison of its tightness and separation. This
              silhouette shows which objects lie well within their cluster, and
              which ones are merely somewhere in between clusters. The entire
              clustering is displayed by combining the silhouettes into a
              single plot, allowing an appreciation of the relative quality of
              the clusters and an overview of the data configuration. The
              average silhouette width provides an evaluation of clustering
              validity, and might be used to select an 'appropriate' number of
              clusters. \copyright{} 1987.",
  journal  = "J. Comput. Appl. Math.",
  volume   =  20,
  pages    = "53--65",
  month    =  nov,
  year     =  1987,
  keywords = "Graphical display; classification; cluster analysis; clustering
              validity;Mendeley Import (Apr 20)",
  issn     = "0377-0427",
  doi      = "10.1016/0377-0427(87)90125-7"
}

@ARTICLE{Johnson2007-qg,
  title    = "Adjusting batch effects in microarray expression data using
              empirical Bayes methods",
  author   = "Johnson, W Evan and Li, Cheng and Rabinovic, Ariel",
  abstract = "Non-biological experimental variation or ``batch effects'' are
              commonly observed across multiple batches of microarray
              experiments, often rendering the task of combining data from
              these batches difficult. The ability to combine microarray data
              sets is advantageous to researchers to increase statistical power
              to detect biological phenomena from studies where logistical
              considerations restrict sample size or in studies that require
              the sequential hybridization of arrays. In general, it is
              inappropriate to combine data sets without adjusting for batch
              effects. Methods have been proposed to filter batch effects from
              data, but these are often complicated and require large batch
              sizes ($\geq$ 25) to implement. Because the majority of
              microarray studies are conducted using much smaller sample sizes,
              existing methods are not sufficient. We propose parametric and
              non-parametric empirical Bayes frameworks for adjusting data for
              batch effects that is robust to outliers in small sample sizes
              and performs comparable to existing methods for large samples. We
              illustrate our methods using two example data sets and show that
              our methods are justifiable, easy to apply, and useful in
              practice. Software for our method is freely available at:
              http://biosun1.harvard.edu/complab/batch/.",
  journal  = "Biostatistics",
  volume   =  8,
  number   =  1,
  pages    = "118--127",
  month    =  "1~" # jan,
  year     =  2007,
  keywords = "Batch effects; Empirical Bayes; Microarrays; Monte Carlo;Mendeley
              Import (Apr 20)",
  issn     = "1465-4644, 1468-4357",
  pmid     = "16632515",
  doi      = "10.1093/biostatistics/kxj037"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Lloyd1982-hi,
  title    = "Least squares quantization in {PCM}",
  author   = "Lloyd, S",
  abstract = "It has long been realized that in pulse-code modulation (PCM),
              with a given ensemble of signals to handle, the quantum values
              should be spaced more closely in the voltage regions where the
              signal amplitude is more likely to fall. It has been shown by
              Panter and Dite that, in the limit as the number of quanta
              becomes infinite, the asymptotic fractional density of quanta per
              unit voltage should vary as the one-third power of the
              probability density per unit voltage of signal amplitudes. In
              this paper the corresponding result for any finite number of
              quanta is derived; that is, necessary conditions are found that
              the quanta and associated quantization intervals of an optimum
              finite quantization scheme must satisfy. The optimization
              criterion used is that the average quantization noise power be a
              minimum. It is shown that the result obtained here goes over into
              the Panter and Dite result as the number of quanta become large.
              The optimum quantization schemes for 2b quanta, b = 1,2, , 7,
              are given numerically for Gaussian and for Laplacian distribution
              of signal amplitudes. \copyright{}1982 IEEE",
  journal  = "IEEE Trans. Inf. Theory",
  volume   =  28,
  number   =  2,
  pages    = "129--137",
  month    =  mar,
  year     =  1982,
  keywords = "Mendeley Import (Apr 20)",
  issn     = "0018-9448",
  doi      = "10.1109/TIT.1982.1056489"
}

@ARTICLE{Calinski1974-uu,
  title    = "A dendrite method for cluster analysis",
  author   = "Calinski, T and Harabasz, J",
  abstract = "A method for identifying clusters of points in a multidimensional
              Euclidean space is described and its application to taxonomy
              considered. It reconciles, in a sense, two different approaches
              to the investigation of the spatial relationships between the
              points, viz., the agglomerative and the divisive methods. A
              graph, the shortest dendrite of Florek et al. (1951a), is
              constructed on a nearest neighbour basis ana then divided in to
              clusters by applying the criterion of minimum within-cluster sum
              of squares. This procedure ensures an effective reduction of the
              number of possible splits. The method may be applied to a
              dichotomous division, but is perfectly suitable also for a global
              division into any number of clusters. An informal indicator of
              the ``best number'' of clusters is suggested. It is a ``variance
              ratio criterion'' giving some insight into the structure of the
              pointa. The method is illustrated by three examples, one of which
              is original. The results obtained bg the dendrite method are
              compared with those obtained by using the agglomerative method of
              'Nard (1963) and the divisive method of Edwards and
              Cavalli-Sforza (1965). \copyright{} 1974, Taylor \& Francis
              Group, LLC. All rights reserved.",
  journal  = "Communications in Statistics - Theory and Methods",
  volume   =  3,
  number   =  1,
  pages    = "1--27",
  year     =  1974,
  keywords = "approximate grouping procedure; cluster analysis; minimum
              variance (WGSS) criterion for optimal grou; numerical taxonomy;
              shortest dendrite = minimum spanning tree; variance ratio
              criterion for best number of groups;Mendeley Import (Apr 20)",
  issn     = "0361-0926",
  doi      = "10.1080/03610927408827101"
}

@ARTICLE{Davies1979-tn,
  title    = "A Cluster Separation Measure",
  author   = "Davies, David L and Bouldin, Donald W",
  abstract = "A measure is presented which indicates the similarity of clusters
              which are assumed to have a data density which is a decreasing
              function of distance from a vector characteristic of the cluster.
              The measure can be used to infer the appropriateness of data
              partitions and can therefore be used to compare relative
              appropriateness of various divisions of the data. The measure
              does not depend on either the number of clusters analyzed nor the
              method of partitioning of the data and can be used to guide a
              cluster seeking algorithm. Copyright \copyright{} 1979 by The
              Institute of Electrical and Electronics Engineers, Inc.",
  journal  = "IEEE Trans. Pattern Anal. Mach. Intell.",
  volume   = "PAMI-1",
  number   =  2,
  pages    = "224--227",
  month    =  apr,
  year     =  1979,
  keywords = "Index Terms-Cluster; data partitions; multidimensional data
              analysis; parametric clustering; partitions; similarity
              measure;Mendeley Import (Apr 20)",
  issn     = "0162-8828",
  doi      = "10.1109/TPAMI.1979.4766909"
}

@ARTICLE{Van_der_Walt2011-kn,
  title    = "The {NumPy} Array: A Structure for Efficient Numerical
              Computation",
  author   = "van der Walt, St{\'e}fan and Colbert, S Chris and Varoquaux,
              Ga{\"e}l",
  abstract = "In the Python world, NumPy arrays are the standard representation
              for numerical data. Here, we show how these arrays enable
              efficient implementation of numerical computations in a
              high-level language. Overall, three techniques are applied to
              improve performance: vectorizing calculations, avoiding copying
              data in memory, and minimizing operation counts. We first present
              the NumPy array structure, then show how to use it for efficient
              computation, and finally how to share array data with other
              libraries.",
  journal  = "Comput. Sci. Eng.",
  volume   =  13,
  number   =  2,
  pages    = "22--30",
  month    =  "8~" # mar,
  year     =  2011,
  keywords = "Mendeley Import (Apr 20)",
  issn     = "1521-9615",
  pmid     = "1000224767",
  arxivid  = "1102.1523",
  doi      = "10.1109/MCSE.2011.37"
}

@ARTICLE{Zimmer2019-vy,
  title    = "Technical report: supervised training of convolutional spiking
              neural networks with {PyTorch}",
  author   = "Zimmer, Romain and Pellegrini, Thomas and Singh, Srisht Fateh and
              Masquelier, Timoth{\'e}e",
  abstract = "Recently, it has been shown that spiking neural networks (SNNs)
              can be trained efficiently, in a supervised manner, using
              backpropagation through time. Indeed, the most commonly used
              spiking neuron model, the leaky integrate-and-fire neuron, obeys
              a differential equation which can be approximated using discrete
              time steps, leading to a recurrent relation for the potential.
              The firing threshold causes optimization issues, but they can be
              overcome using a surrogate gradient. Here, we extend previous
              approaches in two ways. Firstly, we show that the approach can be
              used to train convolutional layers. Convolutions can be done in
              space, time (which simulates conduction delays), or both.
              Secondly, we include fast horizontal connections \textbackslash`a
              la Den\textbackslash`eve: when a neuron N fires, we subtract to
              the potentials of all the neurons with the same receptive the dot
              product between their weight vectors and the one of neuron N. As
              Den\textbackslash`eve et al. showed, this is useful to represent
              a dynamic multidimensional analog signal in a population of
              spiking neurons. Here we demonstrate that, in addition, such
              connections also allow implementing a multidimensional
              send-on-delta coding scheme. We validate our approach on one
              speech classification benchmarks: the Google speech command
              dataset. We managed to reach nearly state-of-the-art accuracy
              (94\%) while maintaining low firing rates (about 5Hz). Our code
              is based on PyTorch and is available in open source at
              http://github.com/romainzimmer/s2net",
  month    =  "22~" # nov,
  year     =  2019,
  keywords = "Mendeley Import (Apr 20)/SNN",
  arxivid  = "1911.10124"
}

@INPROCEEDINGS{Hornby2006-xt,
  title     = "Automated antenna design with evolutionary algorithms",
  booktitle = "Collection of Technical Papers - Space 2006 Conference",
  author    = "Hornby, Gregory S and Globus, Al and Linden, Derek S and Lohn,
               Jason D",
  abstract  = "Whereas the current practice of designing antennas by hand is
               severely limited because it is both time and labor intensive and
               requires a significant amount of domain knowledge, evolutionary
               algorithms can be used to search the design space and
               automatically find novel antenna designs that are more effective
               than would otherwise be developed. Here we present automated
               antenna design and optimization methods based on evolutionary
               algorithms. We have evolved efficient antennas for a variety of
               aerospace applications and here we.describe one proof-of-concept
               study and one project that produced fight antennas that flew on
               NASA's Space Technology 5 (ST5) mission.",
  year      =  2006,
  keywords  = "Mendeley Import (Apr 20)/EA;Mendeley Import (Apr 20)/SNN",
  isbn      = "9781563478246",
  doi       = "10.2514/6.2006-7242"
}

@INPROCEEDINGS{Stanley2002-ze,
  title     = "Efficient evolution of neural network topologies",
  booktitle = "Proceedings of the 2002 Congress on Evolutionary Computation.
               {CEC'02} (Cat. {No.02TH8600})",
  author    = "Stanley, K O and Miikkulainen, Risto",
  abstract  = "Neuroevolution, i.e. evolving artificial neural networks with
               genetic algorithms, has been highly effective in reinforcement
               learning tasks, particularly those with hidden state
               information. An important question in neuroevolution is how to
               gain an advantage from evolving neural network topologies along
               with weights. We present a method, NeuroEvolution of Augmenting
               Topologies (NEAT) that outperforms the best fixed-topology
               methods on a challenging benchmark reinforcement learning task.
               We claim that the increased efficiency is due to (1) employing a
               principled method of crossover of different topologies, (2)
               protecting structural innovation using speciation, and (3)
               incrementally growing from minimal structure. We test this claim
               through a series of ablation studies that demonstrate that each
               component is necessary to the system as a whole and to each
               other. What results is significantly faster learning. NEAT is
               also an important contribution to GAs because it shows how it is
               possible for evolution to both optimize and complexify solutions
               simultaneously, making it possible to evolve increasingly
               complex solutions over time, thereby strengthening the Analogy
               with biological evolution. \copyright{} 2002 IEEE.",
  publisher = "IEEE",
  volume    =  2,
  pages     = "1757--1762",
  year      =  2002,
  keywords  = "Mendeley Import (Apr 20)/EA",
  doi       = "10.1109/CEC.2002.1004508"
}

@ARTICLE{Real2018-yj,
  title    = "Regularized Evolution for Image Classifier Architecture Search",
  author   = "Real, Esteban and Aggarwal, Alok and Huang, Yanping and Le, Quoc
              V",
  abstract = "The effort devoted to hand-crafting neural network image
              classifiers has motivated the use of architecture search to
              discover them automatically. Although evolutionary algorithms
              have been repeatedly applied to neural network topologies, the
              image classifiers thus discovered have remained inferior to
              human-crafted ones. Here, we evolve an image
              classifier---AmoebaNet-A---that surpasses hand-designs for the
              first time. To do this, we modify the tournament selection
              evolutionary algorithm by introducing an age property to favor
              the younger genotypes. Matching size, AmoebaNet-A has comparable
              accuracy to current state-of-the-art ImageNet models discovered
              with more complex architecture-search methods. Scaled to larger
              size, AmoebaNet-A sets a new state-of-the-art 83.9\% / 96.6\%
              top-5 ImageNet accuracy. In a controlled comparison against a
              well known reinforcement learning algorithm, we give evidence
              that evolution can obtain results faster with the same hardware,
              especially at the earlier stages of the search. This is relevant
              when fewer compute resources are available. Evolution is, thus, a
              simple method to effectively discover high-quality architectures.",
  journal  = "Proc. Conf. AAAI Artif. Intell.",
  volume   =  33,
  pages    = "4780--4789",
  month    =  "5~" # feb,
  year     =  2018,
  keywords = "Mendeley Import (Apr 20)/EA",
  issn     = "2159-5399, 2374-3468",
  arxivid  = "1802.01548",
  doi      = "10.1609/aaai.v33i01.33014780"
}

@INPROCEEDINGS{Harding2005-io,
  title     = "Evolution of robot controller using cartesian genetic
               programming",
  booktitle = "Lecture Notes in Computer Science",
  author    = "Harding, Simon and Miller, Julian F",
  abstract  = "Cartesian Genetic Programming is a graph based representation
               that has many benefits over traditional tree based methods,
               including bloat free evolution and faster evolution through
               neutral search. Here, an integer based version of the
               representation is applied to a traditional problem in the field:
               evolving an obstacle avoiding robot controller. The technique is
               used to rapidly evolve controllers that work in a complex
               environment and with a challenging robot design. The
               generalisation of the robot controllers in different
               environments is also demonstrated. A novel fitness function
               based on chemical gradients is presented as a means of improving
               evolvability in such tasks. \copyright{} Springer-Verlag Berlin
               Heidelberg 2005.",
  year      =  2005,
  keywords  = "Mendeley Import (Apr 20)/EA;Mendeley Import (Apr 20)",
  issn      = "0302-9743",
  doi       = "10.1007/978-3-540-31989-4\_6"
}

@INPROCEEDINGS{Liou2020-pw,
  title     = "{GEVO-ML}",
  booktitle = "Proceedings of the 2020 Genetic and Evolutionary Computation
               Conference Companion",
  author    = "Liou, Jhe-Yu and Wang, Xiaodong and Forrest, Stephanie and Wu,
               Carole-Jean",
  abstract  = "Parallel accelerators, such as GPUs, are a key enabler of
               large-scale Machine Learning (ML) applications. However,
               programmers often lack detailed knowledge of the underlying
               architecture and fail to fully leverage their computational
               power. This paper proposes GEVO-ML, a tool for automatically
               discovering optimization opportunities and tuning the
               performance of ML kernels. GEVO-ML extends earlier work on GEVO
               (Gpu optimization using EVOlutionary computation) by focusing
               directly on ML frameworks, intermediate languages, and target
               architectures. It retains the multi-objective evolutionary
               search developed for GEVO, which searches for edits to GPU code
               compiled to LLVM-IR and improves performance on desired criteria
               while retaining required functionality. In earlier work, we
               studied some ML workloads in GPU settings and found that GEVO
               could improve kernel speeds by factors ranging from 1.7X to
               2.9X, even with access to only a small portion of the overall ML
               framework. This workshop paper examines the limitations and
               constraints of GEVO for ML workloads and discusses our GEVO-ML
               design, which we are currently implementing.",
  publisher = "ACM",
  pages     = "1849--1856",
  month     =  "8~" # jul,
  year      =  2020,
  address   = "New York, NY, USA",
  keywords  = "Genetic improvement; Machine learning; Multi-objective
               evolutionary computation;Mendeley Import (Apr 20)/EA",
  isbn      = "9781450371278",
  doi       = "10.1145/3377929.3398139"
}

@INPROCEEDINGS{Da_Silva2018-yq,
  title     = "Cartesian genetic programming with crossover for designing
               combinational logic circuits",
  booktitle = "Proceedings - 2018 Brazilian Conference on Intelligent Systems,
               {BRACIS} 2018",
  author    = "Da Silva, Jose Eduardo and Bernardino, Heder",
  abstract  = "The development of an efficient crossover for Cartesian Genetic
               Programming (CGP) has been widely investigated, but there is not
               a large number of approaches using this type of operator when
               designing combinational logic circuits. In this paper, we
               introduce a new crossover for CGP when using a single genotype
               representation and the desired model has multiple outputs. The
               proposal modifies the standard evolutionary strategy commonly
               adopted in CGP by combining the subgraphs of the best outputs of
               the parent and its offspring in order to generate a new fittest
               individual. The proposed crossover is applied to combinational
               logic circuits with multiple outputs, a parameter analysis is
               performed, and the results obtained are compared to those found
               by a baseline CGP and other techniques from the literature.",
  year      =  2018,
  keywords  = "Cartesian Genetic Programming; Combinational Logic Circuits;
               Crossover;Mendeley Import (Apr 20);Mendeley Import (Apr 20)/EA",
  isbn      = "9781538680230",
  doi       = "10.1109/BRACIS.2018.00033"
}

@ARTICLE{Axler1997-un,
  title    = "Linear Algebra Done Right, Second Edition",
  author   = "Axler, Sheldon and Gehring, F and Ribet, K",
  abstract = "This text for a second course in linear algebra is aimed at math
              majors and graduate students. The novel approach taken here
              banishes determinants to the end of the book and focuses on the
              central goal of linear algebra: understanding the structure of
              linear operators on vector spaces. The author has taken unusual
              care to motivate concepts and to simplify proofs. For example,
              the book presents-without having defined determinants-a clean
              proof that every linear operator on a finite-dimensional complex
              vector space (or an odd-dimensional real vector space) has an
              eigenvalue. A variety of interesting exercises in each chapter
              helps students understand and manipulate the objects of linear
              algebra. No prerequisites are assumed other than the usual demand
              for suitable mathematical maturity. Thus, the text starts by
              discussing vector spaces, linear independence, span, basis, and
              dimension. Students are introduced to inner-product spaces in the
              first half of the book and shortly thereafter to the
              finite-dimensional spectral theorem. This second edition includes
              a new section on orthogonal projections and minimization
              problems. The sections on self-adjoint operators, normal
              operators, and the spectral theorem have been rewritten. New
              examples and new exercises have been added, several proofs have
              been simplified, and hundreds of minor improvements have been
              made throughout the text.",
  journal  = "Comp. Eng. Design",
  year     =  1997,
  keywords = "Linear Algebra;Mendeley Import (Apr 20)/Learning resources",
  issn     = "1000-7024, 1940-6029",
  pmid     = "23086853"
}

@ARTICLE{Parsonson1967-jf,
  title    = "Calculus Made Easy",
  author   = "Parsonson, S L and Thompson, Silvanus P",
  abstract = "Considering how many fools can calculate, it is surprising that
              it should be thought either a dicult or a tedious task for any
              other fool to learn how to master the same tricks. Some
              calculus-tricks are quite easy. Some are enormously dicult. The
              fools who write the textbooks of advanced mathematics|and they
              are mostly clever fools|seldom take the trouble to show you how
              easy the easy calculations are. On the contrary, they seem to
              desire to impress you with their tremendous cleverness by going
              about it in the most dicult way. Being myself a remarkably stupid
              fellow, I have had to unteach myself the diculties, and now beg
              to present to my fellow fools the parts that are not hard. Master
              these thoroughly, and the rest will follow. What one fool can do,
              another can.",
  journal  = "The Mathematical Gazette",
  year     =  1967,
  keywords = "Mendeley Import (Apr 20)/Learning resources",
  issn     = "0025-5572",
  doi      = "10.2307/3613636"
}

@BOOK{Kunin2020-ez,
  title    = "Seeing Theory ({Probabilities/Stats})",
  author   = "Kunin, Daniel and Guo, Jingru and Devlin, Tyler Dae and Xiang,
              Daniel",
  year     =  2020,
  keywords = "Mendeley Import (Apr 20)/Learning resources"
}

@MISC{noauthor_undated-cp,
  title        = "Vectors, what even are they? | Essence of linear algebra,
                  chapter 1 - {YouTube}",
  howpublished = "\url{https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab}",
  keywords     = "Mendeley Import (Apr 20)"
}

@MISC{Grant_Sanderson_undated-rp,
  title        = "{3Blue1Brown} - {YouTube}",
  author       = "{Grant Sanderson}",
  howpublished = "\url{https://www.youtube.com/c/3blue1brown/playlists}",
  keywords     = "Mendeley Import (Apr 20)/Learning resources"
}

@MISC{Academy_undated-bu,
  title        = "Differential Calculus | Khan Academy",
  author       = "Academy, Khan",
  howpublished = "\url{https://www.khanacademy.org/math/differential-calculus}",
  keywords     = "Mendeley Import (Apr 20)/Learning resources"
}

@MISC{Weinstein2013-tn,
  title    = "The cancer genome atlas pan-cancer analysis project",
  author   = "Weinstein, John N and Collisson, Eric A and Mills, Gordon B and
              Shaw, Kenna R Mills and Ozenberger, Brad A and Ellrott, Kyle and
              Sander, Chris and Stuart, Joshua M and Chang, Kyle and Creighton,
              Chad J and Davis, Caleb and Donehower, Lawrence and Drummond,
              Jennifer and Wheeler, David and Ally, Adrian and Balasundaram,
              Miruna and Birol, Inanc and Butterfield, Yaron S N and Chu, Andy
              and Chuah, Eric and Chun, Hye Jung E and Dhalla, Noreen and Guin,
              Ranabir and Hirst, Martin and Hirst, Carrie and Holt, Robert A
              and Jones, Steven J M and Lee, Darlene and Li, Haiyan I and
              Marra, Marco A and Mayo, Michael and Moore, Richard A and
              Mungall, Andrew J and Robertson, A Gordon and Schein, Jacqueline
              E and Sipahimalani, Payal and Tam, Angela and Thiessen, Nina and
              Varhol, Richard J and Beroukhim, Rameen and Bhatt, Ami S and
              Brooks, Angela N and Cherniack, Andrew D and Freeman, Samuel S
              and Gabriel, Stacey B and Helman, Elena and Jung, Joonil and
              Meyerson, Matthew and Ojesina, Akinyemi I and Pedamallu, Chandra
              Sekhar and Saksena, Gordon and Schumacher, Steven E and Tabak,
              Barbara and Zack, Travis and Lander, Eric S and Bristow,
              Christopher A and Hadjipanayis, Angela and Haseley, Psalm and
              Kucherlapati, Raju and Lee, Semin and Lee, Eunjung and Luquette,
              Lovelace J and Mahadeshwar, Harshad S and Pantazi, Angeliki and
              Parfenov, Michael and Park, Peter J and Protopopov, Alexei and
              Ren, Xiaojia and Santoso, Netty and Seidman, Jonathan and Seth,
              Sahil and Song, Xingzhi and Tang, Jiabin and Xi, Ruibin and Xu,
              Andrew W and Yang, Lixing and Zeng, Dong and Auman, J Todd and
              Balu, Saianand and Buda, Elizabeth and Fan, Cheng and Hoadley,
              Katherine A and Jones, Corbin D and Meng, Shaowu and Mieczkowski,
              Piotr A and Parker, Joel S and Perou, Charles M and Roach,
              Jeffrey and Shi, Yan and Silva, Grace O and Tan, Donghui and
              Veluvolu, Umadevi and Waring, Scot and Wilkerson, Matthew D and
              Wu, Junyuan and Zhao, Wei and Bodenheimer, Tom and Hayes, D Neil
              and Hoyle, Alan P and Jeffreys, Stuart R and Mose, Lisle E and
              Simons, Janae V and Soloway, Mathew G and Baylin, Stephen B and
              Berman, Benjamin P and Bootwalla, Moiz S and Danilova, Ludmila
              and Herman, James G and Hinoue, Toshinori and Laird, Peter W and
              Rhie, Suhn K and Shen, Hui and Triche, Timothy and Weisenberger,
              Daniel J and Carter, Scott L and Cibulskis, Kristian and Chin,
              Lynda and Zhang, Jianhua and Sougnez, Carrie and Wang, Min and
              Getz, Gad and Dinh, Huyen and Doddapaneni, Harsha Vardhan and
              Gibbs, Richard and Gunaratne, Preethi and Han, Yi and Kalra,
              Divya and Kovar, Christie and Lewis, Lora and Morgan, Margaret
              and Morton, Donna and Muzny, Donna and Reid, Jeffrey and Xi, Liu
              and Cho, Juok and Dicara, Daniel and Frazer, Scott and
              Gehlenborg, Nils and Heiman, David I and Kim, Jaegil and
              Lawrence, Michael S and Lin, Pei and Liu, Yingchun and Noble,
              Michael S and Stojanov, Petar and Voet, Doug and Zhang, Hailei
              and Zou, Lihua and Stewart, Chip and Bernard, Brady and Bressler,
              Ryan and Eakin, Andrea and Iype, Lisa and Knijnenburg, Theo and
              Kramer, Roger and Kreisberg, Richard and Leinonen, Kalle and Lin,
              Jake and Liu, Yuexin and Miller, Michael and Reynolds, Sheila M
              and Rovira, Hector and Shmulevich, Ilya and Thorsson, Vesteinn
              and Yang, Da and Zhang, Wei and Amin, Samirkumar and Wu, Chang
              Jiun and Wu, Chia Chin and Akbani, Rehan and Aldape, Kenneth and
              Baggerly, Keith A and Broom, Bradley and Casasent, Tod D and
              Cleland, James and Dodda, Deepti and Edgerton, Mary and Han, Leng
              and Herbrich, Shelley M and Ju, Zhenlin and Kim, Hoon and Lerner,
              Seth and Li, Jun and Liang, Han and Liu, Wenbin and Lorenzi,
              Philip L and Lu, Yiling and Melott, James and Nguyen, Lam and Su,
              Xiaoping and Verhaak, Roeland and Wang, Wenyi and Wong, Andrew
              and Yang, Yang and Yao, Jun and Yao, Rong and Yoshihara, Kosuke
              and Yuan, Yuan and Yung, Alfred K and Zhang, Nianxiang and Zheng,
              Siyuan and Ryan, Michael and Kane, David W and Aksoy, B Arman and
              Ciriello, Giovanni and Dresdner, Gideon and Gao, Jianjiong and
              Gross, Benjamin and Jacobsen, Anders and Kahles, Andre and
              Ladanyi, Marc and Lee, William and Van Lehmann, Kjong and Miller,
              Martin L and Ramirez, Ricardo and R{\"a}tsch, Gunnar and Reva,
              Boris and Schultz, Nikolaus and Senbabaoglu, Yasin and Shen,
              Ronglai and Sinha, Rileen and Sumer, S Onur and Sun, Yichao and
              Taylor, Barry S and Weinhold, Nils and Fei, Suzanne and Spellman,
              Paul and Benz, Christopher and Carlin, Daniel and Cline, Melisssa
              and Craft, Brian and Goldman, Mary and Haussler, David and Ma,
              Singer and Ng, Sam and Paull, Evan and Radenbaugh, Amie and
              Salama, Sofie and Sokolov, Artem and Swatloski, Teresa and
              Uzunangelov, Vladislav and Waltman, Peter and Yau, Christina and
              Zhu, Jing and Hamilton, Stanley R and Abbott, Scott and Abbott,
              Rachel and Dees, Nathan D and Delehaunty, Kim and Ding, Li and
              Dooling, David J and Eldred, Jim M and Fronick, Catrina C and
              Fulton, Robert and Fulton, Lucinda L and Kalicki-Veizer, Joelle
              and Kanchi, Krishna Latha and Kandoth, Cyriac and Koboldt, Daniel
              C and Larson, David E and Ley, Timothy J and Lin, Ling and Lu,
              Charles and Magrini, Vincent J and Mardis, Elaine R and McLellan,
              Michael D and McMichael, Joshua F and Miller, Christopher A and
              O'Laughlin, Michelle and Pohl, Craig and Schmidt, Heather and
              Smith, Scott M and Walker, Jason and Wallis, John W and Wendl,
              Michael C and Wilson, Richard K and Wylie, Todd and Zhang,
              Qunyuan and Burton, Robert and Jensen, Mark A and Kahn, Ari and
              Pihl, Todd and Pot, David and Wan, Yunhu and Levine, Douglas A
              and Black, Aaron D and Bowen, Jay and Frick, Jessica and
              Gastier-Foster, Julie M and Harper, Hollie A and Helsel, Carmen
              and Leraas, Kristen M and Lichtenberg, Tara M and McAllister,
              Cynthia and Ramirez, Nilsa C and Sharpe, Samantha and Wise, Lisa
              and Zmuda, Erik and Chanock, Stephen J and Davidsen, Tanja and
              Demchok, John A and Eley, Greg and Felau, Ina and Sheth, Margi
              and Sofia, Heidi and Staudt, Louis and Tarnuzzer, Roy and Wang,
              Zhining and Yang, Liming and Zhang, Jiashan and Omberg, Larsson
              and Margolin, Adam and Raphael, Benjamin J and Vandin, Fabio and
              Wu, Hsin Ta and Leiserson, Mark D M and Benz, Stephen C and
              Vaske, Charles J and Noushmehr, Houtan and Wolf, Denise and Veer,
              Laura Van T and Anastassiou, Dimitris and Yang, Tai Hsien Ou and
              Lopez-Bigas, Nuria and Gonzalez-Perez, Abel and Tamborero, David
              and Xia, Zheng and Li, Wei and Cho, Dong Yeon and Przytycka,
              Teresa and Hamilton, Mark and McGuire, Sean and Nelander, Sven
              and Johansson, Patrik and J{\"o}rnsten, Rebecka and Kling,
              Teresia",
  abstract = "The Cancer Genome Atlas (TCGA) Research Network has profiled and
              analyzed large numbers of human tumors to discover molecular
              aberrations at the DNA, RNA, protein and epigenetic levels. The
              resulting rich data provide a major opportunity to develop an
              integrated picture of commonalities, differences and emergent
              themes across tumor lineages. The Pan-Cancer initiative compares
              the first 12 tumor types profiled by TCGA. Analysis of the
              molecular aberrations and their functional roles across tumor
              types will teach us how to extend therapies effective in one
              cancer type to others with a similar genomic profile.
              \copyright{} 2013 Nature America, Inc. All rights reserved.",
  journal  = "Nature Genetics",
  year     =  2013,
  keywords = "Mendeley Import (Apr 20)",
  issn     = "1546-1718",
  pmid     = "24071849",
  doi      = "10.1038/ng.2764"
}

@ARTICLE{Illing2019-bg,
  title    = "Biologically plausible deep learning -- but how far can we go
              with shallow networks?",
  author   = "Illing, Bernd and Gerstner, Wulfram and Brea, Johanni",
  abstract = "Training deep neural networks with the error backpropagation
              algorithm is considered implausible from a biological
              perspective. Numerous recent publications suggest elaborate
              models for biologically plausible variants of deep learning,
              typically defining success as reaching around 98\% test accuracy
              on the MNIST data set. Here, we investigate how far we can go on
              digit (MNIST) and object (CIFAR10) classification with
              biologically plausible, local learning rules in a network with
              one hidden layer and a single readout layer. The hidden layer
              weights are either fixed (random or random Gabor filters) or
              trained with unsupervised methods (PCA, ICA or Sparse Coding)
              that can be implemented by local learning rules. The readout
              layer is trained with a supervised, local learning rule. We first
              implement these models with rate neurons. This comparison
              reveals, first, that unsupervised learning does not lead to
              better performance than fixed random projections or Gabor filters
              for large hidden layers. Second, networks with localized
              receptive fields perform significantly better than networks with
              all-to-all connectivity and can reach backpropagation performance
              on MNIST. We then implement two of the networks - fixed,
              localized, random \& random Gabor filters in the hidden layer -
              with spiking leaky integrate-and-fire neurons and spike timing
              dependent plasticity to train the readout layer. These spiking
              models achieve > 98.2\% test accuracy on MNIST, which is close to
              the performance of rate networks with one hidden layer trained
              with backpropagation. The performance of our shallow network
              models is comparable to most current biologically plausible
              models of deep learning. Furthermore, our results with a shallow
              spiking network provide an important reference and suggest the
              use of datasets other than MNIST for testing the performance of
              future models of biologically plausible deep learning.",
  journal  = "Neural Netw.",
  month    =  "27~" # feb,
  year     =  2019,
  keywords = "Deep learning; Local learning rules; MNIST; Random projections;
              Spiking networks; Unsupervised feature learning;Mendeley Import
              (Apr 20)/SNN/SNN aplications",
  issn     = "0893-6080, 1879-2782",
  pmid     = "31254771",
  arxivid  = "1905.04101",
  doi      = "10.1016/j.neunet.2019.06.001"
}

@ARTICLE{Murdoch2019-kg,
  title    = "Definitions, methods, and applications in interpretable machine
              learning",
  author   = "Murdoch, W James and Singh, Chandan and Kumbier, Karl and
              Abbasi-Asl, Reza and Yu, Bin",
  abstract = "Machine-learning models have demonstrated great success in
              learning complex patterns that enable them to make predictions
              about unobserved data. In addition to using models for
              prediction, the ability to interpret what a model has learned is
              receiving an increasing amount of attention. However, this
              increased focus has led to considerable confusion about the
              notion of interpretability. In particular, it is unclear how the
              wide array of proposed interpretation methods are related and
              what common concepts can be used to evaluate them. We aim to
              address these concerns by defining interpretability in the
              context of machine learning and introducing the predictive,
              descriptive, relevant (PDR) framework for discussing
              interpretations. The PDR framework provides 3 overarching
              desiderata for evaluation: predictive accuracy, descriptive
              accuracy, and relevancy, with relevancy judged relative to a
              human audience. Moreover, to help manage the deluge of
              interpretation methods, we introduce a categorization of existing
              techniques into model-based and post hoc categories, with
              subgroups including sparsity, modularity, and simulatability. To
              demonstrate how practitioners can use the PDR framework to
              evaluate and understand interpretations, we provide numerous
              real-world examples. These examples highlight the often
              underappreciated role played by human audiences in discussions of
              interpretability. Finally, based on our framework, we discuss
              limitations of existing methods and directions for future work.
              We hope that this work will provide a common vocabulary that will
              make it easier for both practitioners and researchers to discuss
              and choose from the full range of interpretation methods.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  year     =  2019,
  keywords = "Explainability; Interpretability; Machine learning;
              Relevancy;Mendeley Import (Apr 20)/ML interpretability",
  issn     = "0027-8424, 1091-6490",
  pmid     = "31619572",
  doi      = "10.1073/pnas.1900654116"
}

@MISC{Xie2020-rs,
  title    = "Explainable deep learning: A field guide for the uninitiated",
  author   = "Xie, Ning and Ras, Gabri{\"e}lle and van Gerven, Marcel and
              Doran, Derek",
  abstract = "The deep neural network (DNN) is an indispensable machine
              learning tool for achieving human-level performance on many
              learning tasks. Yet, due to its black-box nature, it is
              inherently difficult to understand which aspects of the input
              data drive the decisions of the network. There are various
              real-world scenarios in which humans need to make actionable
              decisions based on the output of a decision support system that
              makes use of DNNs. These decision support systems can be found in
              critical domains, such as legislation, law enforcement, and
              healthcare. It is important that the humans making high-level
              decisions can be sure that the DNN decisions are driven by
              combinations of data features that are appropriate in the context
              of the deployment of the decision support system and that the
              decisions made are legally or ethically defensible. Due to the
              incredible pace at which DNN technology is being developed and
              adopted, the development of new methods and studies on explaining
              the decision-making process of DNNs has blossomed into an active
              research field. A practitioner beginning to study explainable
              deep learning may be intimidated by the plethora of orthogonal
              directions the field is taking. This complexity is further
              exacerbated by the general confusion that exists in defining what
              it means to be able to explain the actions of a deep learning
              system and to evaluate a system's ``ability to explain''. To
              alleviate this problem, this article offers a ``field guide'' to
              deep learning explainability for those uninitiated in the field.
              The field guide: i) Discusses the traits of a deep learning
              system that researchers enhance in explainability research, ii)
              places explainability in the context of other related deep
              learning research areas, and iii) introduces three simple
              dimensions defining the space of foundational methods that
              contribute to explainable deep learning. The guide is designed as
              an easy-to-digest starting point for those just embarking in the
              field.",
  journal  = "arXiv",
  year     =  2020,
  keywords = "Mendeley Import (Apr 20)/ML interpretability",
  arxivid  = "2004.14545"
}

@ARTICLE{Lipton2016-zo,
  title    = "The Mythos of Model Interpretability",
  author   = "Lipton, Zachary C",
  abstract = "Supervised machine learning models boast remarkable predictive
              capabilities. But can you trust your model? Will it work in
              deployment? What else can it tell you about the world? We want
              models to be not only good, but interpretable. And yet the task
              of interpretation appears underspecified. Papers provide diverse
              and sometimes non-overlapping motivations for interpretability,
              and offer myriad notions of what attributes render models
              interpretable. Despite this ambiguity, many papers proclaim
              interpretability axiomatically, absent further explanation. In
              this paper, we seek to refine the discourse on interpretability.
              First, we examine the motivations underlying interest in
              interpretability, finding them to be diverse and occasionally
              discordant. Then, we address model properties and techniques
              thought to confer interpretability, identifying transparency to
              humans and post-hoc explanations as competing notions.
              Throughout, we discuss the feasibility and desirability of
              different notions, and question the oft-made assertions that
              linear models are interpretable and that deep neural networks are
              not.",
  journal  = "Commun. ACM",
  month    =  "10~" # jun,
  year     =  2016,
  keywords = "Mendeley Import (Apr 20)/ML interpretability",
  issn     = "0001-0782, 1557-7317",
  arxivid  = "1606.03490",
  doi      = "10.1145/3233231"
}

@ARTICLE{Coupe2019-cc,
  title    = "Different languages, similar encoding efficiency: Comparable
              information rates across the human communicative niche",
  author   = "Coup{\'e}, Christophe and Oh, Yoon and Dediu, Dan and Pellegrino,
              Fran{\c c}ois",
  abstract = "Language is universal, but it has few indisputably universal
              characteristics, with cross-linguistic variation being the norm.
              For example, languages differ greatly in the number of syllables
              they allow, resulting in large variation in the Shannon
              information per syllable. Nevertheless, all natural languages
              allow their speakers to efficiently encode and transmit
              information. We show here, using quantitative methods on a large
              cross-linguistic corpus of 17 languages, that the coupling
              between language-level (information per syllable) and
              speaker-level (speech rate) properties results in languages
              encoding similar information rates (~39 bits/s) despite wide
              differences in each property individually: Languages are more
              similar in information rates than in Shannon information or
              speech rate. These findings highlight the intimate feedback loops
              between languages' structural properties and their speakers'
              neurocognition and biology under communicative pressures. Thus,
              language is the product of a multiscale communicative niche
              construction process at the intersection of biology, environment,
              and culture.",
  journal  = "Science Advances",
  year     =  2019,
  keywords = "Mendeley Import (Apr 20);Mendeley Import (Apr 20)/others",
  issn     = "2375-2548",
  pmid     = "32047854",
  doi      = "10.1126/sciadv.aaw2594"
}

@MISC{noauthor_undated-xu,
  title        = "{AlphaFold}: a solution to a 50-year-old grand challenge in
                  biology",
  howpublished = "\url{https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology}",
  keywords     = "Mendeley Import (Apr 20)/Learning resources;Mendeley Import
                  (Apr 20)/Biomedical/biomed application"
}

@ARTICLE{Van_den_Oord2016-pv,
  title    = "{WaveNet}: A Generative Model for Raw Audio",
  author   = "van den Oord, Aaron and Dieleman, Sander and Zen, Heiga and
              Simonyan, Karen and Vinyals, Oriol and Graves, Alex and
              Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray",
  abstract = "This paper introduces WaveNet, a deep neural network for
              generating raw audio waveforms. The model is fully probabilistic
              and autoregressive, with the predictive distribution for each
              audio sample conditioned on all previous ones; nonetheless we
              show that it can be efficiently trained on data with tens of
              thousands of samples per second of audio. When applied to
              text-to-speech, it yields state-of-the-art performance, with
              human listeners rating it as significantly more natural sounding
              than the best parametric and concatenative systems for both
              English and Mandarin. A single WaveNet can capture the
              characteristics of many different speakers with equal fidelity,
              and can switch between them by conditioning on the speaker
              identity. When trained to model music, we find that it generates
              novel and often highly realistic musical fragments. We also show
              that it can be employed as a discriminative model, returning
              promising results for phoneme recognition.",
  journal  = "arXiv",
  month    =  "12~" # sep,
  year     =  2016,
  keywords = "Mendeley Import (Apr 20)/Biomedical/biomed application;Mendeley
              Import (Apr 20)",
  arxivid  = "1609.03499"
}

@ARTICLE{De_Fauw2018-hp,
  title     = "Clinically applicable deep learning for diagnosis and referral
               in retinal disease",
  author    = "De Fauw, Jeffrey and Ledsam, Joseph R and Romera-Paredes,
               Bernardino and Nikolov, Stanislav and Tomasev, Nenad and
               Blackwell, Sam and Askham, Harry and Glorot, Xavier and
               O'Donoghue, Brendan and Visentin, Daniel and van den Driessche,
               George and Lakshminarayanan, Balaji and Meyer, Clemens and
               Mackinder, Faith and Bouton, Simon and Ayoub, Kareem and Chopra,
               Reena and King, Dominic and Karthikesalingam, Alan and Hughes,
               C{\'\i}an O and Raine, Rosalind and Hughes, Julian and Sim, Dawn
               A and Egan, Catherine and Tufail, Adnan and Montgomery, Hugh and
               Hassabis, Demis and Rees, Geraint and Back, Trevor and Khaw,
               Peng T and Suleyman, Mustafa and Cornebise, Julien and Keane,
               Pearse A and Ronneberger, Olaf",
  abstract  = "The volume and complexity of diagnostic imaging is increasing at
               a pace faster than the availability of human expertise to
               interpret it. Artificial intelligence has shown great promise in
               classifying two-dimensional photographs of some common diseases
               and typically relies on databases of millions of annotated
               images. Until now, the challenge of reaching the performance of
               expert clinicians in a real-world clinical pathway with
               three-dimensional diagnostic scans has remained unsolved. Here,
               we apply a novel deep learning architecture to a clinically
               heterogeneous set of three-dimensional optical coherence
               tomography scans from patients referred to a major eye hospital.
               We demonstrate performance in making a referral recommendation
               that reaches or exceeds that of experts on a range of
               sight-threatening retinal diseases after training on only 14,884
               scans. Moreover, we demonstrate that the tissue segmentations
               produced by our architecture act as a device-independent
               representation; referral accuracy is maintained when using
               tissue segmentations from a different type of device. Our work
               removes previous barriers to wider clinical use without
               prohibitive training data requirements across multiple
               pathologies in a real-world setting.",
  journal   = "Nat. Med.",
  publisher = "Nature Publishing Group",
  volume    =  24,
  number    =  9,
  pages     = "1342--1350",
  month     =  "1~" # sep,
  year      =  2018,
  keywords  = "Diagnosis; Eye manifestations; Machine learning; Three;
               dimensional imaging;Mendeley Import (Apr 20)/Biomedical/biomed
               application",
  issn      = "1078-8956, 1546-170X",
  pmid      = "30104768",
  doi       = "10.1038/s41591-018-0107-6"
}

@ARTICLE{Yim2020-sq,
  title     = "Predicting conversion to wet age-related macular degeneration
               using deep learning",
  author    = "Yim, Jason and Chopra, Reena and Spitz, Terry and Winkens, Jim
               and Obika, Annette and Kelly, Christopher and Askham, Harry and
               Lukic, Marko and Huemer, Josef and Fasler, Katrin and Moraes,
               Gabriella and Meyer, Clemens and Wilson, Marc and Dixon,
               Jonathan and Hughes, Cian and Rees, Geraint and Khaw, Peng T and
               Karthikesalingam, Alan and King, Dominic and Hassabis, Demis and
               Suleyman, Mustafa and Back, Trevor and Ledsam, Joseph R and
               Keane, Pearse A and De Fauw, Jeffrey",
  abstract  = "Progression to exudative `wet' age-related macular degeneration
               (exAMD) is a major cause of visual deterioration. In patients
               diagnosed with exAMD in one eye, we introduce an artificial
               intelligence (AI) system to predict progression to exAMD in the
               second eye. By combining models based on three-dimensional (3D)
               optical coherence tomography images and corresponding automatic
               tissue maps, our system predicts conversion to exAMD within a
               clinically actionable 6-month time window, achieving a
               per-volumetric-scan sensitivity of 80\% at 55\% specificity, and
               34\% sensitivity at 90\% specificity. This level of performance
               corresponds to true positives in 78\% and 41\% of individual
               eyes, and false positives in 56\% and 17\% of individual eyes at
               the high sensitivity and high specificity points, respectively.
               Moreover, we show that automatic tissue segmentation can
               identify anatomical changes before conversion and high-risk
               subgroups. This AI system overcomes substantial interobserver
               variability in expert predictions, performing better than five
               out of six experts, and demonstrates the potential of using AI
               to predict disease progression.",
  journal   = "Nat. Med.",
  publisher = "Nature Research",
  volume    =  26,
  number    =  6,
  pages     = "892--899",
  month     =  "1~" # jun,
  year      =  2020,
  keywords  = "Machine learning; Preclinical research; Predictive
               markers;Mendeley Import (Apr 20)/Biomedical/biomed application",
  issn      = "1078-8956, 1546-170X",
  pmid      = "32424211",
  doi       = "10.1038/s41591-020-0867-7"
}

@INPROCEEDINGS{Gupta2015-dd,
  title     = "Ischemic stroke detection using image processing and {ANN}",
  booktitle = "Proceedings of 2014 {IEEE} International Conference on Advanced
               Communication, Control and Computing Technologies, {ICACCCT}
               2014",
  author    = "Gupta, Shivangi and Mishra, Archit and Menaka, R",
  abstract  = "Ischemic stroke is a condition in which brain stops working due
               to lack of blood supply resulting in death of brain cells.
               Magnetic Resonance Imaging is widely used to detect Ischemic
               Strokes in brain. This paper gives an automated algorithm to
               detect the stroke using Image processing techniques. The
               algorithm consists of six phases. Data in the form of MRI images
               is collected in first phase. The preprocessing is performed
               including filtering on the raw data collected. Midline is traced
               in third phase for acquiring a symmetrical image. It is followed
               by bifurcation of image in fourth phase. Finally the image
               quality matrix is formed for texture analysis in fifth phase and
               neural network is applied in sixth phase for classification of
               normal and infected brain. The advantage is that the strokes can
               be detected in its early stage. The algorithm proposed is
               simple, efficient and less time consuming. The efficiency is
               found to be 98\%.",
  year      =  2015,
  keywords  = "Gray level co-occurrence matrix (GLCM); Ischemic Stroke; MRI;
               Mid line tracing; Neural network;Mendeley Import (Apr
               20)/Biomedical/biomed application",
  isbn      = "9781479939145",
  doi       = "10.1109/ICACCCT.2014.7019334"
}

@ARTICLE{Kim2016-du,
  title    = "Somatic {ERCC2} mutations are associated with a distinct genomic
              signature in urothelial tumors",
  author   = "Kim, Jaegil and Mouw, Kent W and Polak, Paz and Braunstein, Lior
              Z and Kamburov, Atanas and Kwiatkowski, David J and Rosenberg,
              Jonathan E and Van Allen, Eliezer M and D'Andrea, Alan and Getz,
              Gad",
  abstract = "Alterations in DNA repair pathways are common in tumors and can
              result in characteristic mutational signatures; however, a
              specific mutational signature associated with somatic alterations
              in the nucleotide- excision repair (NER) pathway has not yet been
              identified. Here we examine the mutational processes operating in
              urothelial cancer, a tumor type in which the core NER gene ERCC2
              is significantly mutated. Analysis of three independent
              urothelial tumor cohorts demonstrates a strong association
              between somatic ERCC2 mutations and the activity of a mutational
              signature characterized by a broad spectrum of base changes. In
              addition, we note an association between the activity of this
              signature and smoking that is independent of ERCC2 mutation
              status, providing genomic evidence of tobacco-related mutagenesis
              in urothelial cancer. Together, these analyses identify an
              NER-related mutational signature and highlight the related roles
              of DNA damage and subsequent DNA repair in shaping tumor
              mutational landscape.",
  journal  = "Nat. Genet.",
  volume   =  48,
  number   =  6,
  pages    = "600--606",
  year     =  2016,
  keywords = "Mendeley Import (Apr 20)/Biomedical",
  issn     = "1061-4036, 1546-1718",
  pmid     = "27111033",
  doi      = "10.1038/ng.3557"
}

@ARTICLE{Hong2019-th,
  title    = "Single-cell transcriptomics reveals multi-step adaptations to
              endocrine therapy",
  author   = "Hong, Sung Pil and Chan, Thalia E and Lombardo, Ylenia and
              Corleone, Giacomo and Rotmensz, Nicole and Bravaccini, Sara and
              Rocca, Andrea and Pruneri, Giancarlo and McEwen, Kirsten R and
              Coombes, R Charles and Barozzi, Iros and Magnani, Luca",
  abstract = "Resistant tumours are thought to arise from the action of
              Darwinian selection on genetically heterogenous cancer cell
              populations. However, simple clonal selection is inadequate to
              describe the late relapses often characterising luminal breast
              cancers treated with endocrine therapy (ET), suggesting a more
              complex interplay between genetic and non-genetic factors. Here,
              we dissect the contributions of clonal genetic diversity and
              transcriptional plasticity during the early and late phases of ET
              at single-cell resolution. Using single-cell RNA-sequencing and
              imaging we disentangle the transcriptional variability of plastic
              cells and define a rare subpopulation of pre-adapted (PA) cells
              which undergoes further transcriptomic reprogramming and copy
              number changes to acquire full resistance. We find evidence for
              sub-clonal expression of a PA signature in primary tumours and
              for dominant expression in clustered circulating tumour cells. We
              propose a multi-step model for ET resistance development and
              advocate the use of stage-specific biomarkers.",
  journal  = "Nat. Commun.",
  volume   =  10,
  number   =  1,
  pages    = "3840",
  month    =  "2~" # sep,
  year     =  2019,
  keywords = "Transcriptomics",
  language = "en",
  issn     = "2041-1723",
  pmid     = "31477698",
  doi      = "10.1038/s41467-019-11721-9",
  pmc      = "PMC6718416"
}

@ARTICLE{Fan2020-yb,
  title    = "Single-cell transcriptomics in cancer: computational challenges
              and opportunities",
  author   = "Fan, Jean and Slowikowski, Kamil and Zhang, Fan",
  abstract = "Intratumor heterogeneity is a common characteristic across
              diverse cancer types and presents challenges to current standards
              of treatment. Advancements in high-throughput sequencing and
              imaging technologies provide opportunities to identify and
              characterize these aspects of heterogeneity. Notably,
              transcriptomic profiling at a single-cell resolution enables
              quantitative measurements of the molecular activity that
              underlies the phenotypic diversity of cells within a tumor. Such
              high-dimensional data require computational analysis to extract
              relevant biological insights about the cell types and states that
              drive cancer development, pathogenesis, and clinical outcomes. In
              this review, we highlight emerging themes in the computational
              analysis of single-cell transcriptomics data and their
              applications to cancer research. We focus on downstream
              analytical challenges relevant to cancer research, including how
              to computationally perform unified analysis across many patients
              and disease states, distinguish neoplastic from nonneoplastic
              cells, infer communication with the tumor microenvironment, and
              delineate tumoral and microenvironmental evolution with
              trajectory and RNA velocity analysis. We include discussions of
              challenges and opportunities for future computational
              methodological advancements necessary to realize the
              translational potential of single-cell transcriptomic profiling
              in cancer.",
  journal  = "Exp. Mol. Med.",
  volume   =  52,
  number   =  9,
  pages    = "1452--1465",
  month    =  sep,
  year     =  2020,
  keywords = "Transcriptomics",
  language = "en",
  issn     = "1226-3613, 2092-6413",
  pmid     = "32929226",
  doi      = "10.1038/s12276-020-0422-0"
}

@ARTICLE{Kleppe2021-me,
  title    = "Designing deep learning studies in cancer diagnostics",
  author   = "Kleppe, Andreas and Skrede, Ole-Johan and De Raedt, Sepp and
              Liest{\o}l, Knut and Kerr, David J and Danielsen, H{\aa}vard E",
  abstract = "The number of publications on deep learning for cancer
              diagnostics is rapidly increasing, and systems are frequently
              claimed to perform comparable with or better than clinicians.
              However, few systems have yet demonstrated real-world medical
              utility. In this Perspective, we discuss reasons for the moderate
              progress and describe remedies designed to facilitate transition
              to the clinic. Recent, presumably influential, deep learning
              studies in cancer diagnostics, of which the vast majority used
              images as input to the system, are evaluated to reveal the status
              of the field. By manipulating real data, we then exemplify that
              much and varied training data facilitate the generalizability of
              neural networks and thus the ability to use them clinically. To
              reduce the risk of biased performance estimation of deep learning
              systems, we advocate evaluation in external cohorts and strongly
              advise that the planned analyses, including a predefined primary
              analysis, are described in a protocol preferentially stored in an
              online repository. Recommended protocol items should be
              established for the field, and we present our suggestions.",
  journal  = "Nat. Rev. Cancer",
  volume   =  21,
  number   =  3,
  pages    = "199--211",
  month    =  mar,
  year     =  2021,
  keywords = "ML;Bio-med",
  language = "en",
  issn     = "1474-175X, 1474-1768",
  pmid     = "33514930",
  doi      = "10.1038/s41568-020-00327-9"
}

@ARTICLE{Littmann2020-gs,
  title     = "Validity of machine learning in biology and medicine increased
               through collaborations across fields of expertise",
  author    = "Littmann, Maria and Selig, Katharina and Cohen-Lavi, Liel and
               Frank, Yotam and H{\"o}nigschmid, Peter and Kataka, Evans and
               M{\"o}sch, Anja and Qian, Kun and Ron, Avihai and Schmid,
               Sebastian and Sorbie, Adam and Szlak, Liran and Dagan-Wiener,
               Ayana and Ben-Tal, Nir and Niv, Masha Y and Razansky, Daniel and
               Schuller, Bj{\"o}rn W and Ankerst, Donna and Hertz, Tomer and
               Rost, Burkhard",
  abstract  = "Machine learning (ML) has become an essential asset for the life
               sciences and medicine. We selected 250 articles describing ML
               applications from 17 journals sampling 26 different fields
               between 2011 and 2016. Independent evaluation by two readers
               highlighted three results. First, only half of the articles
               shared software, 64\% shared data and 81\% applied any kind of
               evaluation. Although crucial for ensuring the validity of ML
               applications, these aspects were met more by publications in
               lower-ranked journals. Second, the authors' scientific
               backgrounds highly influenced how technical aspects were
               addressed: reproducibility and computational evaluation methods
               were more prominent with computational co-authors; experimental
               proofs more with experimentalists. Third, 73\% of the ML
               applications resulted from interdisciplinary collaborations
               comprising authors from at least two of the three disciplines:
               computational sciences, biology, and medicine. The results
               suggested collaborations between computational and experimental
               scientists to generate more scientifically sound and impactful
               work integrating knowledge from both domains. Although
               scientifically more valid solutions and collaborations involving
               diverse expertise did not correlate with impact factors, such
               collaborations provide opportunities to both sides:
               computational scientists are given access to novel and
               challenging real-world biological data, increasing the
               scientific impact of their research, and experimentalists
               benefit from more in-depth computational analyses improving the
               technical correctness of work. Applications of machine learning
               in the life sciences and medicine require expertise in
               computational methods and in scientific subject matter. The
               authors surveyed articles in the life sciences that included
               machine learning applications, and found that interdisciplinary
               collaborations increased the scientific validity of published
               research.",
  journal   = "Nature Machine Intelligence",
  publisher = "Nature Publishing Group",
  volume    =  2,
  number    =  1,
  pages     = "18--24",
  month     =  "13~" # jan,
  year      =  2020,
  keywords  = "ML;Bio-med",
  language  = "en",
  issn      = "2522-5839, 2522-5839",
  doi       = "10.1038/s42256-019-0139-8"
}

@ARTICLE{Alber2019-gf,
  title    = "Integrating machine learning and multiscale
              modeling-perspectives, challenges, and opportunities in the
              biological, biomedical, and behavioral sciences",
  author   = "Alber, Mark and Buganza Tepole, Adrian and Cannon, William R and
              De, Suvranu and Dura-Bernal, Salvador and Garikipati, Krishna and
              Karniadakis, George and Lytton, William W and Perdikaris, Paris
              and Petzold, Linda and Kuhl, Ellen",
  abstract = "Fueled by breakthrough technology developments, the biological,
              biomedical, and behavioral sciences are now collecting more data
              than ever before. There is a critical need for time- and
              cost-efficient strategies to analyze and interpret these data to
              advance human health. The recent rise of machine learning as a
              powerful technique to integrate multimodality, multifidelity
              data, and reveal correlations between intertwined phenomena
              presents a special opportunity in this regard. However, machine
              learning alone ignores the fundamental laws of physics and can
              result in ill-posed problems or non-physical solutions.
              Multiscale modeling is a successful strategy to integrate
              multiscale, multiphysics data and uncover mechanisms that explain
              the emergence of function. However, multiscale modeling alone
              often fails to efficiently combine large datasets from different
              sources and different levels of resolution. Here we demonstrate
              that machine learning and multiscale modeling can naturally
              complement each other to create robust predictive models that
              integrate the underlying physics to manage ill-posed problems and
              explore massive design spaces. We review the current literature,
              highlight applications and opportunities, address open questions,
              and discuss potential challenges and limitations in four
              overarching topical areas: ordinary differential equations,
              partial differential equations, data-driven approaches, and
              theory-driven approaches. Towards these goals, we leverage
              expertise in applied mathematics, computer science, computational
              biology, biophysics, biomechanics, engineering mechanics,
              experimentation, and medicine. Our multidisciplinary perspective
              suggests that integrating machine learning and multiscale
              modeling can provide new insights into disease mechanisms, help
              identify new targets and treatment strategies, and inform
              decision making for the benefit of human health.",
  journal  = "NPJ Digit Med",
  volume   =  2,
  pages    = "115",
  month    =  "25~" # nov,
  year     =  2019,
  keywords = "Computational biophysics; Computational science;Bio-med;ML",
  language = "en",
  issn     = "2398-6352",
  pmid     = "31799423",
  doi      = "10.1038/s41746-019-0193-y",
  pmc      = "PMC6877584"
}

@ARTICLE{Feltes2020-bz,
  title    = "{Multi-Approach} Bioinformatics Analysis of Curated Omics Data
              Provides a Gene Expression Panorama for Multiple Cancer Types",
  author   = "Feltes, Bruno C{\'e}sar and Poloni, Joice de Faria and Nunes,
              Itamar Jos{\'e} Guimar{\~a}es and Faria, Sara Socorro and Dorn,
              Marcio",
  abstract = "Studies describing the expression patterns and biomarkers for the
              tumoral process increase in number every year. The availability
              of new datasets, although essential, also creates a confusing
              landscape where common or critical mechanisms are obscured amidst
              the divergent and heterogeneous nature of such results. In this
              work, we manually curated the Gene Expression Omnibus using
              rigorous filtering criteria to select the most homogeneous and
              highest quality microarray and RNA-seq datasets from multiple
              types of cancer. By applying systems biology approaches, combined
              with machine learning analysis, we investigated possible
              frequently deregulated molecular mechanisms underlying the
              tumoral process. Our multi-approach analysis of 99 curated
              datasets, composed of 5,406 samples, revealed 47 differentially
              expressed genes in all analyzed cancer types, which were all in
              agreement with the validation using TCGA data. Results suggest
              that the tumoral process is more related to the overexpression of
              core deregulated machinery than the underexpression of a given
              gene set. Additionally, we identified gene expression
              similarities between different cancer types not described before
              and performed an overall survival analysis using 20 cancer types.
              Finally, we were able to suggest a core regulatory mechanism that
              could be frequently deregulated.",
  journal  = "Front. Genet.",
  volume   =  11,
  pages    = "586602",
  month    =  "23~" # nov,
  year     =  2020,
  keywords = "bioinformatics; cancer; machine learning; omics; overall
              survival; regulatory networks; systems biology;Transcriptomics
              ;Relevant;Bio-med",
  language = "en",
  issn     = "1664-8021",
  pmid     = "33329726",
  doi      = "10.3389/fgene.2020.586602",
  pmc      = "PMC7719697"
}

@ARTICLE{Robertson2017-mg,
  title    = "Comprehensive Molecular Characterization of {Muscle-Invasive}
              Bladder Cancer",
  author   = "Robertson, A Gordon and Kim, Jaegil and Al-Ahmadie, Hikmat and
              Bellmunt, Joaquim and Guo, Guangwu and Cherniack, Andrew D and
              Hinoue, Toshinori and Laird, Peter W and Hoadley, Katherine A and
              Akbani, Rehan and Castro, Mauro A A and Gibb, Ewan A and Kanchi,
              Rupa S and Gordenin, Dmitry A and Shukla, Sachet A and
              Sanchez-Vega, Francisco and Hansel, Donna E and Czerniak, Bogdan
              A and Reuter, Victor E and Su, Xiaoping and de Sa Carvalho,
              Benilton and Chagas, Vinicius S and Mungall, Karen L and Sadeghi,
              Sara and Pedamallu, Chandra Sekhar and Lu, Yiling and Klimczak,
              Leszek J and Zhang, Jiexin and Choo, Caleb and Ojesina, Akinyemi
              I and Bullman, Susan and Leraas, Kristen M and Lichtenberg, Tara
              M and Wu, Catherine J and Schultz, Nicholaus and Getz, Gad and
              Meyerson, Matthew and Mills, Gordon B and McConkey, David J and
              {TCGA Research Network} and Weinstein, John N and Kwiatkowski,
              David J and Lerner, Seth P",
  abstract = "We report a comprehensive analysis of 412 muscle-invasive bladder
              cancers characterized by multiple TCGA analytical platforms.
              Fifty-eight genes were significantly mutated, and the overall
              mutational load was associated with APOBEC-signature mutagenesis.
              Clustering by mutation signature identified a high-mutation
              subset with 75\% 5-year survival. mRNA expression clustering
              refined prior clustering analyses and identified a poor-survival
              ``neuronal'' subtype in which the majority of tumors lacked small
              cell or neuroendocrine histology. Clustering by mRNA, long
              non-coding RNA (lncRNA), and miRNA expression converged to
              identify subsets with differential epithelial-mesenchymal
              transition status, carcinoma in situ scores, histologic features,
              and survival. Our analyses identified 5 expression subtypes that
              may stratify response to different treatments.",
  journal  = "Cell",
  volume   =  171,
  number   =  3,
  pages    = "540--556.e25",
  month    =  "19~" # oct,
  year     =  2017,
  keywords = "APOBEC mutation; DNA methylation; basal mRNA subtype; lncRNA
              transcriptome; luminal mRNA subtype; microRNA; muscle-invasive
              bladder cancer; neoantigen; neuronal subtype;
              regulon;Bio-med;Transcriptomics ;consens;Consensus",
  language = "en",
  issn     = "0092-8674, 1097-4172",
  pmid     = "28988769",
  doi      = "10.1016/j.cell.2017.09.007",
  pmc      = "PMC5687509"
}

@ARTICLE{Kamoun2020-tj,
  title    = "A Consensus Molecular Classification of Muscle-invasive Bladder
              Cancer",
  author   = "Kamoun, Aur{\'e}lie and de Reyni{\`e}s, Aur{\'e}lien and Allory,
              Yves and Sj{\"o}dahl, Gottfrid and Robertson, A Gordon and
              Seiler, Roland and Hoadley, Katherine A and Groeneveld, Clarice S
              and Al-Ahmadie, Hikmat and Choi, Woonyoung and Castro, Mauro A A
              and Fontugne, Jacqueline and Eriksson, Pontus and Mo, Qianxing
              and Kardos, Jordan and Zlotta, Alexandre and Hartmann, Arndt and
              Dinney, Colin P and Bellmunt, Joaquim and Powles, Thomas and
              Malats, N{\'u}ria and Chan, Keith S and Kim, William Y and
              McConkey, David J and Black, Peter C and Dyrskj{\o}t, Lars and
              H{\"o}glund, Mattias and Lerner, Seth P and Real, Francisco X and
              Radvanyi, Fran{\c c}ois and {Bladder Cancer Molecular Taxonomy
              Group}",
  abstract = "BACKGROUND: Muscle-invasive bladder cancer (MIBC) is a
              molecularly diverse disease with heterogeneous clinical outcomes.
              Several molecular classifications have been proposed, but the
              diversity of their subtype sets impedes their clinical
              application. OBJECTIVE: To achieve an international consensus on
              MIBC molecular subtypes that reconciles the published
              classification schemes. DESIGN, SETTING, AND PARTICIPANTS: We
              used 1750 MIBC transcriptomic profiles from 16 published datasets
              and two additional cohorts. OUTCOME MEASUREMENTS AND STATISTICAL
              ANALYSIS: We performed a network-based analysis of six
              independent MIBC classification systems to identify a consensus
              set of molecular classes. Association with survival was assessed
              using multivariable Cox models. RESULTS AND LIMITATIONS: We
              report the results of an international effort to reach a
              consensus on MIBC molecular subtypes. We identified a consensus
              set of six molecular classes: luminal papillary (24\%), luminal
              nonspecified (8\%), luminal unstable (15\%), stroma-rich (15\%),
              basal/squamous (35\%), and neuroendocrine-like (3\%). These
              consensus classes differ regarding underlying oncogenic
              mechanisms, infiltration by immune and stromal cells, and
              histological and clinical characteristics, including outcomes. We
              provide a single-sample classifier that assigns a consensus class
              label to a tumor sample's transcriptome. Limitations of the work
              are retrospective clinical data collection and a lack of complete
              information regarding patient treatment. CONCLUSIONS: This
              consensus system offers a robust framework that will enable
              testing and validation of predictive biomarkers in future
              prospective clinical trials. PATIENT SUMMARY: Bladder cancers are
              heterogeneous at the molecular level, and scientists have
              proposed several classifications into sets of molecular classes.
              While these classifications may be useful to stratify patients
              for prognosis or response to treatment, a consensus
              classification would facilitate the clinical use of molecular
              classes. Conducted by multidisciplinary expert teams in the
              field, this study proposes such a consensus and provides a tool
              for applying the consensus classification in the clinical
              setting.",
  journal  = "Eur. Urol.",
  volume   =  77,
  number   =  4,
  pages    = "420--433",
  month    =  apr,
  year     =  2020,
  keywords = "Consensus; Molecular taxonomy; Muscle-invasive bladder cancer;
              Transcriptomic classifier;Bio-med;consens;Consensus",
  language = "en",
  issn     = "0302-2838, 1873-7560",
  pmid     = "31563503",
  doi      = "10.1016/j.eururo.2019.09.006",
  pmc      = "PMC7690647"
}

@ARTICLE{Baker2021-hn,
  title    = "Does a Novel Mutagenic Process Target {KMT2D} Mutation in the
              Most Common First Event on the Path to Bladder Cancer?",
  author   = "Baker, Simon C and Mason, Andrew S and Southgate, Jennifer",
  journal  = "Eur. Urol.",
  volume   =  79,
  number   =  3,
  pages    = "435--436",
  month    =  mar,
  year     =  2021,
  keywords = "Bio-med",
  language = "en",
  issn     = "0302-2838, 1873-7560",
  pmid     = "33203550",
  doi      = "10.1016/j.eururo.2020.11.008"
}

@ARTICLE{Zhang2016-tw,
  title    = "Characterization and classification of adherent cells in
              monolayer culture using automated tracking and evolutionary
              algorithms",
  author   = "Zhang, Zhen and Bedder, Matthew and Smith, Stephen L and Walker,
              Dawn and Shabir, Saqib and Southgate, Jennifer",
  abstract = "This paper presents a novel method for tracking and
              characterizing adherent cells in monolayer culture. A system of
              cell tracking employing computer vision techniques was applied to
              time-lapse videos of replicate normal human uro-epithelial cell
              cultures exposed to different concentrations of adenosine
              triphosphate (ATP) and a selective purinergic P2X antagonist
              (PPADS), acquired over a 24h period. Subsequent analysis
              following feature extraction demonstrated the ability of the
              technique to successfully separate the modulated classes of cell
              using evolutionary algorithms. Specifically, a Cartesian Genetic
              Program (CGP) network was evolved that identified average
              migration speed, in-contact angular velocity, cohesivity and
              average cell clump size as the principal features contributing to
              the separation. Our approach not only provides non-biased and
              parsimonious insight into modulated class behaviours, but can be
              extracted as mathematical formulae for the parameterization of
              computational models.",
  journal  = "Biosystems.",
  volume   =  146,
  pages    = "110--121",
  month    =  aug,
  year     =  2016,
  keywords = "EA",
  language = "en",
  issn     = "0303-2647, 1872-8324",
  pmid     = "27267455",
  doi      = "10.1016/j.biosystems.2016.05.009",
  pmc      = "PMC5028014"
}

@ARTICLE{Zhang2018-tf,
  title    = "Driver gene mutations based clustering of tumors: methods and
              applications",
  author   = "Zhang, Wensheng and Flemington, Erik K and Zhang, Kun",
  abstract = "Motivation: Somatic mutations in proto-oncogenes and tumor
              suppressor genes constitute a major category of causal genetic
              abnormalities in tumor cells. The mutation spectra of thousands
              of tumors have been generated by The Cancer Genome Atlas (TCGA)
              and other whole genome (exome) sequencing projects. A promising
              approach to utilizing these resources for precision medicine is
              to identify genetic similarity-based sub-types within a cancer
              type and relate the pinpointed sub-types to the clinical outcomes
              and pathologic characteristics of patients. Results: We propose
              two novel methods, ccpwModel and xGeneModel, for mutation-based
              clustering of tumors. In the former, binary variables indicating
              the status of cancer driver genes in tumors and the genes'
              involvement in the core cancer pathways are treated as the
              features in the clustering process. In the latter, the functional
              similarities of putative cancer driver genes and their confidence
              scores as the 'true' driver genes are integrated with the
              mutation spectra to calculate the genetic distances between
              tumors. We apply both methods to the TCGA data of 16 cancer
              types. Promising results are obtained when these methods are
              compared to state-of-the-art approaches as to the associations
              between the determined tumor clusters and patient race (or
              survival time). We further extend the analysis to detect
              mutation-characterized transcriptomic prognostic signatures,
              which are directly relevant to the etiology of carcinogenesis.
              Availability and implementation: R codes and example data for
              ccpwModel and xGeneModel can be obtained from
              http://webusers.xula.edu/kzhang/ISMB2018/ccpw\_xGene\_software.zip.
              Supplementary information: Supplementary data are available at
              Bioinformatics online.",
  journal  = "Bioinformatics",
  volume   =  34,
  number   =  13,
  pages    = "i404--i411",
  month    =  "1~" # jul,
  year     =  2018,
  keywords = "Transcriptomics ;Bio-med;ML",
  language = "en",
  issn     = "1367-4803, 1367-4811",
  pmid     = "29950003",
  doi      = "10.1093/bioinformatics/bty232",
  pmc      = "PMC6022677"
}

@ARTICLE{Scherer2021-pk,
  title     = "Machine learning for deciphering cell heterogeneity and gene
               regulation",
  author    = "Scherer, Michael and Schmidt, Florian and Lazareva, Olga and
               Walter, J{\"o}rn and Baumbach, Jan and Schulz, Marcel H and
               List, Markus",
  abstract  = "Epigenetics studies inheritable and reversible modifications of
               DNA that allow cells to control gene expression throughout their
               development and in response to environmental conditions. In
               computational epigenomics, machine learning is applied to study
               various epigenetic mechanisms genome wide. Its aim is to expand
               our understanding of cell differentiation, that is their
               specialization, in health and disease. Thus far, most efforts
               focus on understanding the functional encoding of the genome and
               on unraveling cell-type heterogeneity. Here, we provide an
               overview of state-of-the-art computational methods and their
               underlying statistical concepts, which range from matrix
               factorization and regularized linear regression to deep learning
               methods. We further show how the rise of single-cell technology
               leads to new computational challenges and creates opportunities
               to further our understanding of epigenetic regulation. Massive
               datasets have been made available to enable systematic studies
               of gene regulation and its control via epigenetic mechanisms. In
               this Review, state-of-the-art computational methods used to
               effectively extract knowledge from these datasets are presented
               and discussed.",
  journal   = "Nature Computational Science",
  publisher = "Nature Publishing Group",
  volume    =  1,
  number    =  3,
  pages     = "183--191",
  month     =  "15~" # mar,
  year      =  2021,
  keywords  = "Transcriptomics ;ML",
  language  = "en",
  issn      = "2662-8457, 2662-8457",
  doi       = "10.1038/s43588-021-00038-7"
}

@ARTICLE{Eraslan2019-kp,
  title    = "Deep learning: new computational modelling techniques for
              genomics",
  author   = "Eraslan, G{\"o}kcen and Avsec, {\v Z}iga and Gagneur, Julien and
              Theis, Fabian J",
  abstract = "As a data-driven science, genomics largely utilizes machine
              learning to capture dependencies in data and derive novel
              biological hypotheses. However, the ability to extract new
              insights from the exponentially increasing volume of genomics
              data requires more expressive machine learning models. By
              effectively leveraging large data sets, deep learning has
              transformed fields such as computer vision and natural language
              processing. Now, it is becoming the method of choice for many
              genomics modelling tasks, including predicting the impact of
              genetic variation on gene regulatory mechanisms such as DNA
              accessibility and splicing.",
  journal  = "Nat. Rev. Genet.",
  volume   =  20,
  number   =  7,
  pages    = "389--403",
  month    =  jul,
  year     =  2019,
  keywords = "ML;Transcriptomics",
  language = "en",
  issn     = "1471-0056, 1471-0064",
  pmid     = "30971806",
  doi      = "10.1038/s41576-019-0122-6"
}

@ARTICLE{Ozcan_Simsek2019-nk,
  title    = "Statistical representation models for mutation information within
              genomic data",
  author   = "{\"O}zcan {\c S}im{\c s}ek, N {\"O}zlem and {\"O}zg{\"u}r,
              Arzucan and G{\"u}rgen, Fikret",
  abstract = "BACKGROUND: As DNA sequencing technologies are improving and
              getting cheaper, genomic data can be utilized for diagnosis of
              many diseases such as cancer. Human raw genome data is huge in
              size for computational systems. Therefore, there is a need for a
              compact and accurate representation of the valuable information
              in DNA. The occurrence of complex genetic disorders often results
              from multiple gene mutations. The effect of each mutation is not
              equal for the development of a disease. Inspired from the field
              of information retrieval, we propose using the term frequency
              (tf) and BM25 term weighting measures with the inverse document
              frequency (idf) and relevance frequency (rf) measures to weight
              genes based on their mutations. The underlying assumption is that
              the more mutations a gene has in patients with a certain disease
              and the less mutations it has in other patients, the more
              discriminative that gene is. RESULTS: We evaluated the proposed
              representations on the task of cancer type classification. We
              applied various machine learning techniques using the tf-idf and
              tf-rf schemes and their BM25 versions. Our results show that the
              BM25-tf-rf representation leads to improved classification
              accuracy and f-score values compared to the other
              representations. The highest accuracy (76.44\%) and f-score
              (76.95\%) are achieved with the BM25-tf-rf based data
              representation. CONCLUSIONS: As a result of our experiments, the
              BM25-tf-rf scheme and the proposed neural network model is shown
              to be the best performing classification system for our case
              study of cancer type classification. This system is further
              utilized for causal gene analysis. Examples from the most
              effective genes that are used for decision making are found to be
              in the literature as target or causal genes.",
  journal  = "BMC Bioinformatics",
  volume   =  20,
  number   =  1,
  pages    = "324",
  month    =  "13~" # jun,
  year     =  2019,
  keywords = "BM25; DNA mutations; Disease classification; Gene weighting;
              Information retrieval; Machine learning; tf-idf;
              tf-rf;Transcriptomics",
  language = "en",
  issn     = "1471-2105",
  pmid     = "31195961",
  doi      = "10.1186/s12859-019-2868-4",
  pmc      = "PMC6567431"
}

@ARTICLE{Cao2020-kh,
  title     = "Ensemble deep learning in bioinformatics",
  author    = "Cao, Yue and Geddes, Thomas Andrew and Yang, Jean Yee Hwa and
               Yang, Pengyi",
  abstract  = "The remarkable flexibility and adaptability of ensemble methods
               and deep learning models have led to the proliferation of their
               application in bioinformatics research. Traditionally, these two
               machine learning techniques have largely been treated as
               independent methodologies in bioinformatics applications.
               However, the recent emergence of ensemble deep
               learning---wherein the two machine learning techniques are
               combined to achieve synergistic improvements in model accuracy,
               stability and reproducibility---has prompted a new wave of
               research and application. Here, we share recent key developments
               in ensemble deep learning and look at how their contribution has
               benefited a wide range of bioinformatics research from basic
               sequence analysis to systems biology. While the application of
               ensemble deep learning in bioinformatics is diverse and
               multifaceted, we identify and discuss the common challenges and
               opportunities in the context of bioinformatics research. We hope
               this Review Article will bring together the broader community of
               machine learning researchers, bioinformaticians and biologists
               to foster future research and development in ensemble deep
               learning, and inspire novel bioinformatics applications that are
               unattainable by traditional methods. Recent developments in
               machine learning have seen the merging of ensemble and deep
               learning techniques. The authors review advances in ensemble
               deep learning methods and their applications in bioinformatics,
               and discuss the challenges and opportunities going forward.",
  journal   = "Nature Machine Intelligence",
  publisher = "Nature Publishing Group",
  volume    =  2,
  number    =  9,
  pages     = "500--508",
  month     =  "17~" # aug,
  year      =  2020,
  keywords  = "ML;Transcriptomics",
  language  = "en",
  issn      = "2522-5839, 2522-5839",
  doi       = "10.1038/s42256-020-0217-y"
}

@ARTICLE{Razaghi-Moghadam2020-dd,
  title    = "Supervised learning of gene-regulatory networks based on graph
              distance profiles of transcriptomics data",
  author   = "Razaghi-Moghadam, Zahra and Nikoloski, Zoran",
  abstract = "Characterisation of gene-regulatory network (GRN) interactions
              provides a stepping stone to understanding how genes affect
              cellular phenotypes. Yet, despite advances in profiling
              technologies, GRN reconstruction from gene expression data
              remains a pressing problem in systems biology. Here, we devise a
              supervised learning approach, GRADIS, which utilises support
              vector machine to reconstruct GRNs based on distance profiles
              obtained from a graph representation of transcriptomics data. By
              employing the data from Escherichia coli and Saccharomyces
              cerevisiae as well as synthetic networks from the DREAM4 and five
              network inference challenges, we demonstrate that our GRADIS
              approach outperforms the state-of-the-art supervised and
              unsupervided approaches. This holds when predictions about target
              genes for individual transcription factors as well as for the
              entire network are considered. We employ experimentally verified
              GRNs from E. coli and S. cerevisiae to validate the predictions
              and obtain further insights in the performance of the proposed
              approach. Our GRADIS approach offers the possibility for usage of
              other network-based representations of large-scale data, and can
              be readily extended to help the characterisation of other
              cellular networks, including protein-protein and
              protein-metabolite interactions.",
  journal  = "NPJ Syst Biol Appl",
  volume   =  6,
  number   =  1,
  pages    = "21",
  month    =  "30~" # jun,
  year     =  2020,
  keywords = "ML;Transcriptomics ;Relevant",
  language = "en",
  issn     = "2056-7189",
  pmid     = "32606380",
  doi      = "10.1038/s41540-020-0140-1",
  pmc      = "PMC7327016"
}

@ARTICLE{Wood2018-fn,
  title    = "A machine learning approach for somatic mutation discovery",
  author   = "Wood, Derrick E and White, James R and Georgiadis, Andrew and Van
              Emburgh, Beth and Parpart-Li, Sonya and Mitchell, Jason and
              Anagnostou, Valsamo and Niknafs, Noushin and Karchin, Rachel and
              Papp, Eniko and McCord, Christine and LoVerso, Peter and Riley,
              David and Diaz, Jr, Luis A and Jones, Si{\^a}n and Sausen, Mark
              and Velculescu, Victor E and Angiuoli, Samuel V",
  abstract = "Variability in the accuracy of somatic mutation detection may
              affect the discovery of alterations and the therapeutic
              management of cancer patients. To address this issue, we
              developed a somatic mutation discovery approach based on machine
              learning that outperformed existing methods in identifying
              experimentally validated tumor alterations (sensitivity of 97\%
              versus 90 to 99\%; positive predictive value of 98\% versus 34 to
              92\%). Analysis of paired tumor-normal exome data from 1368 TCGA
              (The Cancer Genome Atlas) samples using this method revealed
              concordance for 74\% of mutation calls but also identified likely
              false-positive and false-negative changes in TCGA data, including
              in clinically actionable genes. Determination of high-quality
              somatic mutation calls improved tumor mutation load-based
              predictions of clinical outcome for melanoma and lung cancer
              patients previously treated with immune checkpoint inhibitors.
              Integration of high-quality machine learning mutation detection
              in clinical next-generation sequencing (NGS) analyses increased
              the accuracy of test results compared to other clinical
              sequencing analyses. These analyses provide an approach for
              improved identification of tumor-specific mutations and have
              important implications for research and clinical management of
              cancer patients.",
  journal  = "Sci. Transl. Med.",
  volume   =  10,
  number   =  457,
  month    =  "5~" # sep,
  year     =  2018,
  keywords = "ML;Transcriptomics",
  language = "en",
  issn     = "1946-6234, 1946-6242",
  pmid     = "30185652",
  doi      = "10.1126/scitranslmed.aar7939",
  pmc      = "PMC6481619"
}

@ARTICLE{Gu2021-an,
  title    = "cola: an {R/Bioconductor} package for consensus partitioning
              through a general framework",
  author   = "Gu, Zuguang and Schlesner, Matthias and H{\"u}bschmann, Daniel",
  abstract = "Classification of high-throughput genomic data is a powerful
              method to assign samples to subgroups with specific molecular
              profiles. Consensus partitioning is the most widely applied
              approach to reveal subgroups by summarizing a consensus
              classification from a list of individual classifications
              generated by repeatedly executing clustering on random subsets of
              the data. It is able to evaluate the stability of the
              classification. We implemented a new R/Bioconductor package,
              cola, that provides a general framework for consensus
              partitioning. With cola, various parameters and methods can be
              user-defined and easily integrated into different steps of an
              analysis, e.g., feature selection, sample classification or
              defining signatures. cola provides a new method named ATC
              (ability to correlate to other rows) to extract features and
              recommends spherical k-means clustering (skmeans) for subgroup
              classification. We show that ATC and skmeans have better
              performance than other commonly used methods by a comprehensive
              benchmark on public datasets. We also benchmark key parameters in
              the consensus partitioning procedure, which helps users to select
              optimal parameter values. Moreover, cola provides rich
              functionalities to apply multiple partitioning methods in
              parallel and directly compare their results, as well as rich
              visualizations. cola can automate the complete analysis and
              generates a comprehensive HTML report.",
  journal  = "Nucleic Acids Res.",
  volume   =  49,
  number   =  3,
  pages    = "e15",
  month    =  "22~" # feb,
  year     =  2021,
  language = "en",
  issn     = "0305-1048, 1362-4962",
  pmid     = "33275159",
  doi      = "10.1093/nar/gkaa1146",
  pmc      = "PMC7897501"
}

@ARTICLE{Baker2020-eo,
  title    = "Procarcinogen Activation and Mutational Signatures Model the
              Initiation of Carcinogenesis in Human Urothelial Tissues In Vitro",
  author   = "Baker, Simon C and Mason, Andrew S and Southgate, Jennifer",
  abstract = "Disparity between genome-wide mutations in bladder and other
              cancers where smoking is a risk factor raises questions about
              carcinogenesis in different epithelia. To develop an experimental
              model of bladder carcinogenesis, we clonally expanded in vitro
              differentiated normal human urothelial (NHU) cells following
              exposure to an exemplar procarcinogen and used whole-genome DNA
              sequencing to derive mutational signatures. Benzo[a]pyrene (BaP)
              was activated by endogenous cytochrome P450 (cytochrome P450
              family 1 subfamily A member 1 [CYP1A1]) to create genomically
              modified NHU cells. Comparison with the Catalogue of Somatic
              Mutations in Cancer (COSMIC) showed that mutations induced by BaP
              in NHU cells were similar to smoking-associated signatures in
              bladder and other cancers, including single- and doublet-base
              substitution signatures characterised by C > A transversions
              (COSMIC\_SBS4 and COSMIC\_DBS2, respectively), and an
              insertion/deletion signature of C deletions in homopolymer
              regions (COSMIC ID3). Our study provides the first direct
              evidence that BaP is activated locally in the urothelium,
              initiating the well-described smoking-associated mutational
              signatures. An absence of other common bladder cancer
              (BLCA)-associated genomic signatures points strongly to other
              primary causes of BLCA, which the new experimental approach
              described here is well placed to investigate. Mutational
              signatures ignore whether genes are affected, but tissue-specific
              drivers (KMT2D, KMT2C, and CDKN1A) were significantly overmutated
              in this model, providing insight on the emergent selection
              pressures. PATIENT SUMMARY: In a carefully controlled laboratory
              setting, we exposed normal human urothelial tissues to a
              procarcinogen (benzo[a]pyrene) found in cigarette smoke. We show
              that the urothelial tissues activated the carcinogen and led to
              mutations forming across the genome in a characteristic pattern.
              This particular ``mutational signature'' is found in bladder
              tumours and other smoking-induced cancers (eg, lung); however,
              our study highlights that there are other unknown mutational
              processes in bladder cancer that is not the direct result of
              smoke carcinogens, and this will require further investigation.",
  journal  = "Eur. Urol.",
  volume   =  78,
  number   =  2,
  pages    = "143--147",
  month    =  aug,
  year     =  2020,
  keywords = "APOBEC; BaP; Benzo[a]pyrene; Bladder; Bladder cancer; CYP1A1;
              Cytochrome P450; DNA mutation; Urothelium; Whole-genome DNA
              sequencing;Bio-med",
  language = "en",
  issn     = "0302-2838, 1873-7560",
  pmid     = "32349929",
  doi      = "10.1016/j.eururo.2020.03.049",
  pmc      = "PMC7397502"
}

@ARTICLE{Integrin_undated-ez,
  title  = "The Researcher's Guide",
  author = "Integrin, Sqstm1 and Jak, Jak"
}

@ARTICLE{Howard2015-yl,
  title    = "A distributed representation of internal time",
  author   = "Howard, Marc W and Shankar, Karthik H and Aue, William R and
              Criss, Amy H",
  abstract = "This article pursues the hypothesis that a scale-invariant
              representation of history could support performance in a variety
              of learning and memory tasks. This representation maintains a
              conjunctive representation of what happened when that grows
              continuously less accurate for events further and further in the
              past. Simple behavioral models using a few operations, including
              scanning, matching and a ``jump back in time'' that recovers
              previous states of the history, describe a range of behavioral
              phenomena. These behavioral applications include canonical
              results from the judgment of recency task over short and long
              scales, the recency and contiguity effect across scales in
              episodic recall, and temporal mapping phenomena in conditioning.
              A growing body of neural data suggests that neural
              representations in several brain regions have qualitative
              properties predicted by the representation of temporal history.
              Taken together, these results suggest that a scale-invariant
              representation of temporal history may serve as a cornerstone of
              a physical model of cognition in learning and memory.",
  journal  = "Psychol. Rev.",
  volume   =  122,
  number   =  1,
  pages    = "24--53",
  month    =  jan,
  year     =  2015,
  keywords = "Neuroscience / Mind",
  language = "en",
  issn     = "0033-295X, 1939-1471",
  pmid     = "25330329",
  doi      = "10.1037/a0037840"
}

@ARTICLE{Shankar2010-ny,
  title    = "Timing using temporal context",
  author   = "Shankar, Karthik H and Howard, Marc W",
  abstract = "We present a memory model that explicitly constructs and stores
              the temporal information about when a stimulus was encountered in
              the past. The temporal information is constructed from a set of
              temporal context vectors adapted from the temporal context model
              (TCM). These vectors are leaky integrators that could be
              constructed from a population of persistently firing cells. An
              array of temporal context vectors with different decay rates
              calculates the Laplace transform of real time events. Simple
              bands of feedforward excitatory and inhibitory connections from
              these temporal context vectors enable another population of
              cells, timing cells. These timing cells approximately reconstruct
              the entire temporal history of past events. The temporal
              representation of events farther in the past is less accurate
              than for more recent events. This history-reconstruction
              procedure, which we refer to as timing from inverse Laplace
              transform (TILT), displays a scalar property with respect to the
              accuracy of reconstruction. When incorporated into a simple
              associative memory framework, we show that TILT predicts
              well-timed peak responses and the Weber law property, like that
              observed in interval timing tasks and classical conditioning
              experiments.",
  journal  = "Brain Res.",
  volume   =  1365,
  pages    = "3--17",
  month    =  "13~" # dec,
  year     =  2010,
  keywords = "Neuroscience / Mind",
  language = "en",
  issn     = "0006-8993, 1872-6240",
  pmid     = "20654587",
  doi      = "10.1016/j.brainres.2010.07.045",
  pmc      = "PMC2993870"
}

@ARTICLE{Bright2020-fp,
  title    = "A temporal record of the past with a spectrum of time constants
              in the monkey entorhinal cortex",
  author   = "Bright, Ian M and Meister, Miriam L R and Cruzado, Nathanael A
              and Tiganj, Zoran and Buffalo, Elizabeth A and Howard, Marc W",
  abstract = "Episodic memory is believed to be intimately related to our
              experience of the passage of time. Indeed, neurons in the
              hippocampus and other brain regions critical to episodic memory
              code for the passage of time at a range of timescales. The origin
              of this temporal signal, however, remains unclear. Here, we
              examined temporal responses in the entorhinal cortex of macaque
              monkeys as they viewed complex images. Many neurons in the
              entorhinal cortex were responsive to image onset, showing large
              deviations from baseline firing shortly after image onset but
              relaxing back to baseline at different rates. This range of
              relaxation rates allowed for the time since image onset to be
              decoded on the scale of seconds. Further, these neurons carried
              information about image content, suggesting that neurons in the
              entorhinal cortex carry information about not only when an event
              took place but also, the identity of that event. Taken together,
              these findings suggest that the primate entorhinal cortex uses a
              spectrum of time constants to construct a temporal record of the
              past in support of episodic memory.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  117,
  number   =  33,
  pages    = "20274--20283",
  month    =  "18~" # aug,
  year     =  2020,
  keywords = "Laplace transform; entorhinal cortex; memory; time;Neuroscience /
              Mind",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "32747574",
  doi      = "10.1073/pnas.1917197117",
  pmc      = "PMC7443936"
}

@ARTICLE{Tsao2018-ke,
  title    = "Integrating time from experience in the lateral entorhinal cortex",
  author   = "Tsao, Albert and Sugar, J{\o}rgen and Lu, Li and Wang, Cheng and
              Knierim, James J and Moser, May-Britt and Moser, Edvard I",
  abstract = "The encoding of time and its binding to events are crucial for
              episodic memory, but how these processes are carried out in
              hippocampal-entorhinal circuits is unclear. Here we show in
              freely foraging rats that temporal information is robustly
              encoded across time scales from seconds to hours within the
              overall population state of the lateral entorhinal cortex.
              Similarly pronounced encoding of time was not present in the
              medial entorhinal cortex or in hippocampal areas CA3-CA1. When
              animals' experiences were constrained by behavioural tasks to
              become similar across repeated trials, the encoding of temporal
              flow across trials was reduced, whereas the encoding of time
              relative to the start of trials was improved. The findings
              suggest that populations of lateral entorhinal cortex neurons
              represent time inherently through the encoding of experience.
              This representation of episodic time may be integrated with
              spatial inputs from the medial entorhinal cortex in the
              hippocampus, allowing the hippocampus to store a unified
              representation of what, where and when.",
  journal  = "Nature",
  volume   =  561,
  number   =  7721,
  pages    = "57--62",
  month    =  sep,
  year     =  2018,
  keywords = "Neuroscience / Mind",
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "30158699",
  doi      = "10.1038/s41586-018-0459-6"
}

@ARTICLE{Peron2020-sg,
  title    = "Recurrent interactions in local cortical circuits",
  author   = "Peron, Simon and Pancholi, Ravi and Voelcker, Bettina and
              Wittenbach, Jason D and {\'O}lafsd{\'o}ttir, H Freyja and
              Freeman, Jeremy and Svoboda, Karel",
  abstract = "Most cortical synapses are local and excitatory. Local recurrent
              circuits could implement amplification, allowing pattern
              completion and other computations1-4. Cortical circuits contain
              subnetworks that consist of neurons with similar receptive fields
              and increased connectivity relative to the network average5,6.
              Cortical neurons that encode different types of information are
              spatially intermingled and distributed over large brain
              volumes5-7, and this complexity has hindered attempts to probe
              the function of these subnetworks by perturbing them
              individually8. Here we use computational modelling, optical
              recordings and manipulations to probe the function of recurrent
              coupling in layer 2/3 of the mouse vibrissal somatosensory cortex
              during active tactile discrimination. A neural circuit model of
              layer 2/3 revealed that recurrent excitation enhances sensory
              signals by amplification, but only for subnetworks with increased
              connectivity. Model networks with high amplification were
              sensitive to damage: loss of a few members of the subnetwork
              degraded stimulus encoding. We tested this prediction by mapping
              neuronal selectivity7 and photoablating9,10 neurons with specific
              selectivity. Ablation of a small proportion of layer 2/3 neurons
              (10-20, less than 5\% of the total) representing touch markedly
              reduced responses in the spared touch representation, but not in
              other representations. Ablations most strongly affected neurons
              with stimulus responses that were similar to those of the ablated
              population, which is also consistent with network models.
              Recurrence among cortical neurons with similar selectivity
              therefore drives input-specific amplification during behaviour.",
  journal  = "Nature",
  volume   =  579,
  number   =  7798,
  pages    = "256--259",
  month    =  mar,
  year     =  2020,
  keywords = "Neuroscience / Mind",
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "32132709",
  doi      = "10.1038/s41586-020-2062-x"
}

@ARTICLE{Nakahira2019-fr,
  title         = "Diversity-enabled sweet spots in layered architectures and
                   speed-accuracy trade-offs in sensorimotor control",
  author        = "Nakahira, Yorie and Liu, Quanying and Sejnowski, Terrence J
                   and Doyle, John C",
  abstract      = "Nervous systems sense, communicate, compute, and actuate
                   movement using distributed components with trade-offs in
                   speed, accuracy, sparsity, noise, and saturation.
                   Nevertheless, the resulting control can achieve remarkably
                   fast, accurate, and robust performance due to a highly
                   effective layered control architecture. However, there is no
                   theory explaining the effectiveness of layered control
                   architectures that connects speed-accuracy trade-offs (SATs)
                   in neurophysiology to the resulting SATs in sensorimotor
                   control. In this paper, we introduce a theoretical framework
                   that provides a synthetic perspective to explain why there
                   exists extreme diversity across layers and within levels.
                   This framework characterizes how the sensorimotor control
                   SATs are constrained by the hardware SATs of neurons
                   communicating with spikes and their sensory and muscle
                   endpoints, in both stochastic and deterministic models. The
                   theoretical predictions of the model are experimentally
                   confirmed using driving experiments in which the time delays
                   and accuracy of the control input from the wheel are varied.
                   These results show that the appropriate diversity in the
                   properties of neurons and muscles across layers and within
                   levels help create systems that are both fast and accurate
                   despite being built from components that are individually
                   slow or inaccurate. This novel concept, which we call
                   ``diversity-enabled sweet spots'' (DESSs), explains the
                   ubiquity of heterogeneity in the sizes of axons within a
                   nerve as well the resulting superior performance of
                   sensorimotor control.",
  month         =  "18~" # sep,
  year          =  2019,
  keywords      = "Neuroscience / Mind",
  archivePrefix = "arXiv",
  eprint        = "1909.08601",
  primaryClass  = "math.OC",
  arxivid       = "1909.08601"
}

@UNPUBLISHED{Boboeva2020-yl,
  title    = "Free recall scaling laws and short-term memory effects in a
              latching attractor network",
  author   = "Boboeva, Vezha and Pezzotta, Alberto and Clopath, Claudia",
  abstract = "Despite the complexity of human memory, paradigms like free
              recall have revealed robust qualitative and quantitative
              characteristics, such as power laws governing recall capacity.
              Although abstract random matrix models could explain such laws,
              the possibility of their implementation in large networks of
              interacting neurons has so far remained unexplored. We study an
              attractor network model of long-term memory endowed with firing
              rate adaptation and global inhibition. Under appropriate
              conditions, the transitioning behaviour of the network from
              memory to memory is constrained by limit cycles that prevent the
              network from recalling all memories, with scaling similar to what
              has been found in experiments. When the model is supplemented
              with a heteroassociative learning rule, complementing the
              standard autoassociative learning rule, as well as short-term
              synaptic facilitation, our model reproduces other key findings in
              the free recall literature, namely serial position effects,
              contiguity and forward asymmetry effects, as well as the semantic
              effects found to guide memory recall. The model is consistent
              with a broad series of manipulations aimed at gaining a better
              understanding of the variables that affect recall, such as the
              role of rehearsal, presentation rates and
              (continuous/end-of-list) distractor conditions. We predict that
              recall capacity may be increased with the addition of small
              amounts of noise, for example in the form of weak random stimuli
              during recall. Moreover, we predict that although the statistics
              of the encoded memories has a strong effect on the recall
              capacity, the power laws governing recall capacity may still be
              expected to hold. \#\#\# Competing Interest Statement The authors
              have declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2020.12.19.423464",
  month    =  "21~" # dec,
  year     =  2020,
  keywords = "Neuroscience / Mind",
  language = "en",
  doi      = "10.1101/2020.12.19.423464"
}

@ARTICLE{Hassabis2009-kc,
  title    = "The construction system of the brain",
  author   = "Hassabis, Demis and Maguire, Eleanor A",
  abstract = "The ability to construct a hypothetical situation in one's
              imagination prior to it actually occurring may afford greater
              accuracy in predicting its eventual outcome. The recollection of
              past experiences is also considered to be a reconstructive
              process with memories recreated from their component parts.
              Construction, therefore, plays a critical role in allowing us to
              plan for the future and remember the past. Conceptually,
              construction can be broken down into a number of constituent
              processes although little is known about their neural correlates.
              Moreover, it has been suggested that some of these processes may
              be shared by a number of other cognitive functions including
              spatial navigation and imagination. Recently, novel paradigms
              have been developed that allow for the isolation and
              characterization of these underlying processes and their
              associated neuroanatomy. Here, we selectively review this
              fast-growing literature and consider some implications for
              remembering the past and predicting the future.",
  journal  = "Philos. Trans. R. Soc. Lond. B Biol. Sci.",
  volume   =  364,
  number   =  1521,
  pages    = "1263--1271",
  month    =  "12~" # may,
  year     =  2009,
  keywords = "Neuroscience / Mind",
  language = "en",
  issn     = "0962-8436, 1471-2970",
  pmid     = "19528007",
  doi      = "10.1098/rstb.2008.0296",
  pmc      = "PMC2666702"
}

@UNPUBLISHED{Remme2020-zh,
  title    = "Hebbian plasticity in parallel synaptic pathways: A circuit
              mechanism for systems memory consolidation",
  author   = "Remme, Michiel and Bergmann, Urs and Alevi, Denis and Schreiber,
              Susanne and Sprekeler, Henning and Kempter, Richard",
  abstract = "Systems memory consolidation involves a transfer of declarative
              memories that initially depend on the hippocampal formation into
              long-term memory traces in neocortical networks. This
              consolidation process is thought to rely on replay of recently
              acquired memories, but the cellular and network mechanisms that
              mediate the memory transfer are poorly understood. Here, we
              suggest that systems memory consolidation could arise from
              Hebbian plasticity in networks with parallel synaptic pathways
              --- two ubiquitous features of neural circuits in the brain. We
              explore this hypothesis in a computational model to illustrate
              how memories are transferred across circuits and why their
              representations could change. These modelling results are in
              quantitative agreement with lesion studies in rodents. A
              hierarchical iteration of the mechanism yields power-law
              forgetting --- as observed in psychophysical studies in humans.
              The predicted circuit mechanism thus bridges spatial scales from
              single cells to cortical areas and time scales from milliseconds
              to years. \#\#\# Competing Interest Statement The authors have
              declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2020.12.03.408344",
  month    =  "4~" # dec,
  year     =  2020,
  keywords = "SNN",
  language = "en",
  doi      = "10.1101/2020.12.03.408344"
}

@ARTICLE{Hopkins2018-kr,
  title    = "Spiking neural networks for computer vision",
  author   = "Hopkins, Michael and Pineda-Garc{\'\i}a, Garibaldi and Bogdan,
              Petru{\c t} A and Furber, Steve B",
  abstract = "State-of-the-art computer vision systems use frame-based cameras
              that sample the visual scene as a series of high-resolution
              images. These are then processed using convolutional neural
              networks using neurons with continuous outputs. Biological vision
              systems use a quite different approach, where the eyes (cameras)
              sample the visual scene continuously, often with a non-uniform
              resolution, and generate neural spike events in response to
              changes in the scene. The resulting spatio-temporal patterns of
              events are then processed through networks of spiking neurons.
              Such event-based processing offers advantages in terms of
              focusing constrained resources on the most salient features of
              the perceived scene, and those advantages should also accrue to
              engineered vision systems based upon similar principles.
              Event-based vision sensors, and event-based processing
              exemplified by the SpiNNaker (Spiking Neural Network
              Architecture) machine, can be used to model the biological vision
              pathway at various levels of detail. Here we use this approach to
              explore structural synaptic plasticity as a possible mechanism
              whereby biological vision systems may learn the statistics of
              their inputs without supervision, pointing the way to engineered
              vision systems with similar online learning capabilities.",
  journal  = "Interface Focus",
  volume   =  8,
  number   =  4,
  pages    = "20180007",
  month    =  "6~" # aug,
  year     =  2018,
  keywords = "SpiNNaker; computer vision; neuromorphic computing; spiking
              neural networks; structural plasticity;SNN",
  language = "en",
  issn     = "2042-8898",
  pmid     = "29951187",
  doi      = "10.1098/rsfs.2018.0007",
  pmc      = "PMC6015816"
}

@UNPUBLISHED{Chindemi2020-qb,
  title       = "A calcium-based plasticity model predicts long-term
                 potentiation and depression in the neocortex",
  author      = "Chindemi, Giuseppe and Abdellah, Marwan and Amsalem, Oren and
                 Benavides-Piccione, Ruth and Delattre, Vincent and Doron,
                 Michael and Ecker, Andras and King, James and Kumbhar, Pramod
                 and Monney, Caitlin and Perin, Rodrigo and R{\"o}ssert,
                 Christian and Van Geit, Werner and DeFelipe, Javier and
                 Graupner, Michael and Segev, Idan and Markram, Henry and
                 Muller, Eilif",
  abstract    = "Long-term potentiation (LTP) and long-term depression (LTD) of
                 pyramidal cell connections are among the key mechanisms
                 underlying learning and memory in the brain. Despite their
                 important role, only a few of these connections have been
                 characterized in terms of LTP/LTD dynamics, such as the one
                 between layer 5 thick-tufted pyramidal cells (L5-TTPCs).
                 Comparing the available evidence on different pyramidal
                 connection types reveals a large variability of experimental
                 outcomes, possibly indicating the presence of
                 connection-type-specific mechanisms. Here, we show that a
                 calcium-based plasticity rule regulating L5-TTPC synapses
                 holds also for several other pyramidal-to-pyramidal
                 connections in a digital model of neocortical tissue. In
                 particular, we show that synaptic physiology, cell morphology
                 and innervation patterns jointly determine LTP/LTD dynamics
                 without requiring a different model or parameter set for each
                 connection type. We therefore propose that a similar set of
                 plasticity mechanisms is shared by seemingly very different
                 neocortical connections and that only a small number of
                 targeted experiments is required for generating a complete map
                 of synaptic plasticity dynamics in the neocortex.",
  journal     = "bioRxiv",
  institution = "bioRxiv",
  month       =  "20~" # apr,
  year        =  2020,
  keywords    = "SNN",
  doi         = "10.1101/2020.04.19.043117"
}

@UNPUBLISHED{Confavreux2020-mb,
  title    = "A meta-learning approach to (re)discover plasticity rules that
              carve a desired function into a neural network",
  author   = "Confavreux, Basile and Agnes, Everton J and Zenke, Friedemann and
              Lillicrap, Timothy and Vogels, Tim P",
  abstract = "The search for biologically faithful synaptic plasticity rules
              has resulted in a large body of models. They are usually inspired
              by -- and fitted to -- experimental data, but they rarely produce
              neural dynamics that serve complex functions. These failures
              suggest that current plasticity models are still
              under-constrained by existing data. Here, we present an
              alternative approach that uses meta-learning to discover
              plausible synaptic plasticity rules. Instead of experimental
              data, the rules are constrained by the functions they implement
              and the structure they are meant to produce. Briefly, we
              parameterize synaptic plasticity rules by a Volterra expansion
              and then use supervised learning methods (gradient descent or
              evolutionary strategies) to minimize a problem-dependent loss
              function that quantifies how effectively a candidate plasticity
              rule transforms an initially random network into one with the
              desired function. We first validate our approach by
              re-discovering previously described plasticity rules, starting at
              the single-neuron level and ``Oja's rule'', a simple Hebbian
              plasticity rule that captures the direction of most variability
              of inputs to a neuron (i.e., the first principal component). We
              expand the problem to the network level and ask the framework to
              find Oja's rule together with an anti-Hebbian rule such that an
              initially random two-layer firing-rate network will recover
              several principal components of the input space after learning.
              Next, we move to networks of integrate-and-fire neurons with
              plastic inhibitory afferents. We train for rules that achieve a
              target firing rate by countering tuned excitation. Our algorithm
              discovers a specific subset of the manifold of rules that can
              solve this task. Our work is a proof of principle of an automated
              and unbiased approach to unveil synaptic plasticity rules that
              obey biological constraints and can solve complex functions.
              \#\#\# Competing Interest Statement The authors have declared no
              competing interest.",
  journal  = "bioRxiv",
  pages    = "2020.10.24.353409",
  month    =  "25~" # oct,
  year     =  2020,
  keywords = "SNN",
  language = "en",
  doi      = "10.1101/2020.10.24.353409"
}

@ARTICLE{Fekiac2011-pl,
  title     = "A Review Of Methods For Encoding Neural Network Topologies In
               Evolutionary Computation",
  author    = "Fekia{\v c}, Jozef and Zelinka, Ivan and Burguillo, Juan C",
  abstract  = "This paper describes various methods used to encode artificial
               neural networks to chromosomes to be used in evolutionary
               computation. The target of this review is to cover the main
               techniques of network encoding and make it easier to choose one
               when implementing a custom evolutionary algorithm for finding
               the network topology. Most of the encoding methods are mentioned
               in the context of neural networks; however all of them could be
               generalized to automata networks or even oriented graphs. We
               present direct and indirect encoding methods, and given examples
               of their genotypes. We also describe the possibilities of
               applying genetic operators of mutation and crossover to
               genotypes encoded by these methods. Also, the dependencies of
               using special evolutionary algorithms with some of the encodings
               were considered.",
  publisher = "unknown",
  month     =  "7~" # jun,
  year      =  2011,
  keywords  = "EA",
  doi       = "10.7148/2011-0410-0416"
}

@ARTICLE{Markram2011-jh,
  title    = "A history of spike-timing-dependent plasticity",
  author   = "Markram, Henry and Gerstner, Wulfram and Sj{\"o}str{\"o}m, Per
              Jesper",
  abstract = "How learning and memory is achieved in the brain is a central
              question in neuroscience. Key to today's research into
              information storage in the brain is the concept of synaptic
              plasticity, a notion that has been heavily influenced by Hebb's
              (1949) postulate. Hebb conjectured that repeatedly and
              persistently co-active cells should increase connective strength
              among populations of interconnected neurons as a means of storing
              a memory trace, also known as an engram. Hebb certainly was not
              the first to make such a conjecture, as we show in this history.
              Nevertheless, literally thousands of studies into the classical
              frequency-dependent paradigm of cellular learning rules were
              directly inspired by the Hebbian postulate. But in more recent
              years, a novel concept in cellular learning has emerged, where
              temporal order instead of frequency is emphasized. This new
              learning paradigm - known as spike-timing-dependent plasticity
              (STDP) - has rapidly gained tremendous interest, perhaps because
              of its combination of elegant simplicity, biological
              plausibility, and computational power. But what are the roots of
              today's STDP concept? Here, we discuss several centuries of
              diverse thinking, beginning with philosophers such as Aristotle,
              Locke, and Ribot, traversing, e.g., Lugaro's plasticit{\`a} and
              Rosenblatt's perceptron, and culminating with the discovery of
              STDP. We highlight interactions between theoretical and
              experimental fields, showing how discoveries sometimes occurred
              in parallel, seemingly without much knowledge of the other field,
              and sometimes via concrete back-and-forth communication. We point
              out where the future directions may lie, which includes
              interneuron STDP, the functional impact of STDP, its mechanisms
              and its neuromodulatory regulation, and the linking of STDP to
              the developmental formation and continuous plasticity of neuronal
              networks.",
  journal  = "Front. Synaptic Neurosci.",
  volume   =  3,
  pages    = "4",
  month    =  "29~" # aug,
  year     =  2011,
  keywords = "bidirectional plasticity; history; learning; long term
              depression; long term plasticity; memory; spike-timing-dependent
              plasticity; synaptic plasticity;SNN",
  language = "en",
  issn     = "1663-3563",
  pmid     = "22007168",
  doi      = "10.3389/fnsyn.2011.00004",
  pmc      = "PMC3187646"
}

@MISC{Maass1997-yf,
  title    = "Networks of spiking neurons: The third generation of neural
              network models",
  author   = "Maass, Wolfgang",
  journal  = "Neural Networks",
  volume   =  10,
  number   =  9,
  pages    = "1659--1671",
  year     =  1997,
  keywords = "SNN",
  doi      = "10.1016/s0893-6080(97)00011-7"
}

@ARTICLE{Borst1999-ze,
  title    = "Information theory and neural coding",
  author   = "Borst, A and Theunissen, F E",
  abstract = "Information theory quantifies how much information a neural
              response carries about the stimulus. This can be compared to the
              information transferred in particular models of the
              stimulus-response function and to maximum possible information
              transfer. Such comparisons are crucial because they validate
              assumptions present in any neurophysiological analysis. Here we
              review information-theory basics before demonstrating its use in
              neural coding. We show how to use information theory to validate
              simple stimulus-response models of neural coding of dynamic
              stimuli. Because these models require specification of spike
              timing precision, they can reveal which time scales contain
              information in neural coding. This approach shows that dynamic
              stimuli can be encoded efficiently by single neurons and that
              each spike contributes to information transmission. We argue,
              however, that the data obtained so far do not suggest a temporal
              code, in which the placement of spikes relative to each other
              yields additional information.",
  journal  = "Nat. Neurosci.",
  volume   =  2,
  number   =  11,
  pages    = "947--957",
  month    =  nov,
  year     =  1999,
  keywords = "SNN",
  language = "en",
  issn     = "1097-6256",
  pmid     = "10526332",
  doi      = "10.1038/14731"
}

@ARTICLE{Brette2015-mv,
  title    = "Philosophy of the Spike: {Rate-Based} vs. {Spike-Based} Theories
              of the Brain",
  author   = "Brette, Romain",
  abstract = "Does the brain use a firing rate code or a spike timing code?
              Considering this controversial question from an epistemological
              perspective, I argue that progress has been hampered by its
              problematic phrasing. It takes the perspective of an external
              observer looking at whether those two observables vary with
              stimuli, and thereby misses the relevant question: which one has
              a causal role in neural activity? When rephrased in a more
              meaningful way, the rate-based view appears as an ad hoc
              methodological postulate, one that is practical but with
              virtually no empirical or theoretical support.",
  journal  = "Front. Syst. Neurosci.",
  volume   =  9,
  pages    = "151",
  month    =  "10~" # nov,
  year     =  2015,
  keywords = "action potentials; firing rate; information; neural coding;
              neural computation; neural variability; spike timing;SNN",
  language = "en",
  issn     = "1662-5137",
  pmid     = "26617496",
  doi      = "10.3389/fnsys.2015.00151",
  pmc      = "PMC4639701"
}

@ARTICLE{Hassabis2017-vu,
  title    = "{Neuroscience-Inspired} Artificial Intelligence",
  author   = "Hassabis, Demis and Kumaran, Dharshan and Summerfield,
              Christopher and Botvinick, Matthew",
  abstract = "The fields of neuroscience and artificial intelligence (AI) have
              a long and intertwined history. In more recent times, however,
              communication and collaboration between the two fields has become
              less commonplace. In this article, we argue that better
              understanding biological brains could play a vital role in
              building intelligent machines. We survey historical interactions
              between the AI and neuroscience fields and emphasize current
              advances in AI that have been inspired by the study of neural
              computation in humans and other animals. We conclude by
              highlighting shared themes that may be key for advancing future
              research in both fields.",
  journal  = "Neuron",
  volume   =  95,
  number   =  2,
  pages    = "245--258",
  month    =  "19~" # jul,
  year     =  2017,
  keywords = "artificial intelligence; brain; cognition; learning; neural
              network;SNN;Neuroscience / Mind",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "28728020",
  doi      = "10.1016/j.neuron.2017.06.011"
}

@ARTICLE{Cramer2020-vq,
  title    = "The Heidelberg Spiking Data Sets for the Systematic Evaluation of
              Spiking Neural Networks",
  author   = "Cramer, Benjamin and Stradmann, Yannik and Schemmel, Johannes and
              Zenke, Friedemann",
  abstract = "Spiking neural networks are the basis of versatile and
              power-efficient information processing in the brain. Although we
              currently lack a detailed understanding of how these networks
              compute, recently developed optimization techniques allow us to
              instantiate increasingly complex functional spiking neural
              networks in-silico. These methods hold the promise to build more
              efficient non-von-Neumann computing hardware and will offer new
              vistas in the quest of unraveling brain circuit function. To
              accelerate the development of such methods, objective ways to
              compare their performance are indispensable. Presently, however,
              there are no widely accepted means for comparing the
              computational performance of spiking neural networks. To address
              this issue, we introduce two spike-based classification data
              sets, broadly applicable to benchmark both software and
              neuromorphic hardware implementations of spiking neural networks.
              To accomplish this, we developed a general audio-to-spiking
              conversion procedure inspired by neurophysiology. Furthermore, we
              applied this conversion to an existing and a novel speech data
              set. The latter is the free, high-fidelity, and word-level
              aligned Heidelberg digit data set that we created specifically
              for this study. By training a range of conventional and spiking
              classifiers, we show that leveraging spike timing information
              within these data sets is essential for good classification
              accuracy. These results serve as the first reference for future
              performance comparisons of spiking neural networks.",
  journal  = "IEEE Trans Neural Netw Learn Syst",
  volume   = "PP",
  month    =  "30~" # dec,
  year     =  2020,
  keywords = "SNN",
  language = "en",
  issn     = "2162-2388, 2162-237X",
  pmid     = "33378266",
  doi      = "10.1109/TNNLS.2020.3044364"
}

@ARTICLE{Zenke2021-le,
  title    = "Visualizing a joint future of neuroscience and neuromorphic
              engineering",
  author   = "Zenke, Friedemann and Boht{\'e}, Sander M and Clopath, Claudia
              and Com{\c s}a, Iulia M and G{\"o}ltz, Julian and Maass, Wolfgang
              and Masquelier, Timoth{\'e}e and Naud, Richard and Neftci, Emre O
              and Petrovici, Mihai A and Scherr, Franz and Goodman, Dan F M",
  abstract = "Recent research resolves the challenging problem of building
              biophysically plausible spiking neural models that are also
              capable of complex information processing. This advance creates
              new opportunities in neuroscience and neuromorphic engineering,
              which we discussed at an online focus meeting.",
  journal  = "Neuron",
  volume   =  109,
  number   =  4,
  pages    = "571--575",
  month    =  "17~" # feb,
  year     =  2021,
  keywords = "SNN",
  language = "en",
  issn     = "0896-6273, 1097-4199",
  pmid     = "33600754",
  doi      = "10.1016/j.neuron.2021.01.009"
}

@MISC{Lisitsa2017-to,
  title    = "Prospects for the development and application of spiking neural
              networks",
  author   = "Lisitsa, Daria and Zhilenkov, Anton A",
  journal  = "2017 IEEE Conference of Russian Young Researchers in Electrical
              and Electronic Engineering (EIConRus)",
  year     =  2017,
  keywords = "SNN",
  doi      = "10.1109/eiconrus.2017.7910708"
}

@ARTICLE{Isbister2018-lw,
  title    = "A new approach to solving the feature-binding problem in primate
              vision",
  author   = "Isbister, James B and Eguchi, Akihiro and Ahmad, Nasir and
              Galeazzi, Juan M and Buckley, Mark J and Stringer, Simon",
  abstract = "We discuss a recently proposed approach to solve the classic
              feature-binding problem in primate vision that uses neural
              dynamics known to be present within the visual cortex. Broadly,
              the feature-binding problem in the visual context concerns not
              only how a hierarchy of features such as edges and objects within
              a scene are represented, but also the hierarchical relationships
              between these features at every spatial scale across the visual
              field. This is necessary for the visual brain to be able to make
              sense of its visuospatial world. Solving this problem is an
              important step towards the development of artificial general
              intelligence. In neural network simulation studies, it has been
              found that neurons encoding the binding relations between visual
              features, known as binding neurons, emerge during visual training
              when key properties of the visual cortex are incorporated into
              the models. These biological network properties include (i)
              bottom-up, lateral and top-down synaptic connections, (ii)
              spiking neuronal dynamics, (iii) spike timing-dependent
              plasticity, and (iv) a random distribution of axonal transmission
              delays (of the order of several milliseconds) in the propagation
              of spikes between neurons. After training the network on a set of
              visual stimuli, modelling studies have reported observing the
              gradual emergence of polychronization through successive layers
              of the network, in which subpopulations of neurons have learned
              to emit their spikes in regularly repeating spatio-temporal
              patterns in response to specific visual stimuli. Such a
              subpopulation of neurons is known as a polychronous neuronal
              group (PNG). Some neurons embedded within these PNGs receive
              convergent inputs from neurons representing lower- and
              higher-level visual features, and thus appear to encode the
              hierarchical binding relationship between features. Neural
              activity with this kind of spatio-temporal structure robustly
              emerges in the higher network layers even when neurons in the
              input layer represent visual stimuli with spike timings that are
              randomized according to a Poisson distribution. The resulting
              hierarchical representation of visual scenes in such models,
              including the representation of hierarchical binding relations
              between lower- and higher-level visual features, is consistent
              with the hierarchical phenomenology or subjective experience of
              primate vision and is distinct from approaches interested in
              segmenting a visual scene into a finite set of objects.",
  journal  = "Interface Focus",
  volume   =  8,
  number   =  4,
  pages    = "20180021",
  month    =  "6~" # aug,
  year     =  2018,
  keywords = "binding neuron; feature-binding problem; polychronization;
              primate vision; spiking neural network;SNN",
  language = "en",
  issn     = "2042-8898",
  pmid     = "29951198",
  doi      = "10.1098/rsfs.2018.0021",
  pmc      = "PMC6015810"
}

@ARTICLE{Stringer2008-mw,
  title    = "Learning transform invariant object recognition in the visual
              system with multiple stimuli present during training",
  author   = "Stringer, S M and Rolls, E T",
  abstract = "Over successive stages, the visual system develops neurons that
              respond with view, size and position invariance to objects or
              faces. A number of computational models have been developed to
              explain how transform-invariant cells could develop in the visual
              system. However, a major limitation of computer modelling studies
              to date has been that the visual stimuli are typically presented
              one at a time to the network during training. In this paper, we
              investigate how vision models may self-organize when multiple
              stimuli are presented together within each visual image during
              training. We show that as the number of independent stimuli grows
              large enough, standard competitive neural networks can suddenly
              switch from learning representations of the multi-stimulus input
              patterns to representing the individual stimuli. Furthermore, the
              competitive networks can learn transform (e.g. position or view)
              invariant representations of the individual stimuli if the
              network is presented with input patterns containing multiple
              transforming stimuli during training. Finally, we extend these
              results to a multi-layer hierarchical network model (VisNet) of
              the ventral visual system. The network is trained on input images
              containing multiple rotating 3D objects. We show that the network
              is able to develop view-invariant representations of the
              individual objects.",
  journal  = "Neural Netw.",
  volume   =  21,
  number   =  7,
  pages    = "888--903",
  month    =  sep,
  year     =  2008,
  keywords = "SNN",
  language = "en",
  issn     = "0893-6080",
  pmid     = "18440774",
  doi      = "10.1016/j.neunet.2007.11.004"
}

@ARTICLE{Izhikevich2006-yr,
  title    = "Polychronization: computation with spikes",
  author   = "Izhikevich, Eugene M",
  abstract = "We present a minimal spiking network that can polychronize, that
              is, exhibit reproducible time-locked but not synchronous firing
              patterns with millisecond precision, as in synfire braids. The
              network consists of cortical spiking neurons with axonal
              conduction delays and spike-timing-dependent plasticity (STDP); a
              ready-to-use MATLAB code is included. It exhibits sleeplike
              oscillations, gamma (40 Hz) rhythms, conversion of firing rates
              to spike timings, and other interesting regimes. Due to the
              interplay between the delays and STDP, the spiking neurons
              spontaneously self-organize into groups and generate patterns of
              stereotypical polychronous activity. To our surprise, the number
              of coexisting polychronous groups far exceeds the number of
              neurons in the network, resulting in an unprecedented memory
              capacity of the system. We speculate on the significance of
              polychrony to the theory of neuronal group selection (TNGS,
              neural Darwinism), cognitive neural computations, binding and
              gamma rhythm, mechanisms of attention, and consciousness as
              ``attention to memories.''",
  journal  = "Neural Comput.",
  volume   =  18,
  number   =  2,
  pages    = "245--282",
  month    =  feb,
  year     =  2006,
  keywords = "SNN",
  language = "en",
  issn     = "0899-7667",
  pmid     = "16378515",
  doi      = "10.1162/089976606775093882"
}

@ARTICLE{Eguchi2018-li,
  title    = "The emergence of polychronization and feature binding in a
              spiking neural network model of the primate ventral visual system",
  author   = "Eguchi, Akihiro and Isbister, James B and Ahmad, Nasir and
              Stringer, Simon",
  abstract = "We present a hierarchical neural network model, in which
              subpopulations of neurons develop fixed and regularly repeating
              temporal chains of spikes (polychronization), which respond
              specifically to randomized Poisson spike trains representing the
              input training images. The performance is improved by including
              top-down and lateral synaptic connections, as well as introducing
              multiple synaptic contacts between each pair of pre- and
              postsynaptic neurons, with different synaptic contacts having
              different axonal delays. Spike-timing-dependent plasticity thus
              allows the model to select the most effective axonal transmission
              delay between neurons. Furthermore, neurons representing the
              binding relationship between low-level and high-level visual
              features emerge through visually guided learning. This begins to
              provide a way forward to solving the classic feature binding
              problem in visual neuroscience and leads to a new hypothesis
              concerning how information about visual features at every spatial
              scale may be projected upward through successive neuronal layers.
              We name this hypothetical upward projection of information the
              ``holographic principle.'' (PsycINFO Database Record",
  journal  = "Psychol. Rev.",
  volume   =  125,
  number   =  4,
  pages    = "545--571",
  month    =  jul,
  year     =  2018,
  keywords = "SNN",
  language = "en",
  issn     = "0033-295X, 1939-1471",
  pmid     = "29863378",
  doi      = "10.1037/rev0000103"
}

@ARTICLE{Tromans2012-ul,
  title    = "Learning separate visual representations of independently
              rotating objects",
  author   = "Tromans, James Matthew and Page, Hector J I and Stringer, Simon M",
  abstract = "Individual cells that respond preferentially to particular
              objects have been found in the ventral visual pathway. How the
              brain is able to develop neurons that exhibit these object
              selective responses poses a significant challenge for
              computational models of object recognition. Typically, many
              objects make up a complex natural scene and are never presented
              in isolation. Nonetheless, the visual system is able to build
              invariant object selective responses. In this paper, we present a
              model of the ventral visual stream, VisNet, which can solve the
              problem of learning object selective representations even when
              multiple objects are always present during training. Past
              research with the VisNet model has shown that the network can
              operate successfully in a similar training paradigm, but only
              when training comprises many different object pairs. Numerous
              pairings are required for statistical decoupling between objects.
              In this research, we show for the first time that VisNet is
              capable of utilizing the statistics inherent in independent
              rotation to form object selective representations when training
              with just two objects, always presented together. Crucially, our
              results show that in a dependent rotation paradigm, the model
              fails to build object selective representations and responds as
              if the two objects are in fact one. If the objects begin to
              rotate independently, the network forms representations for each
              object separately.",
  journal  = "Network",
  volume   =  23,
  number   = "1-2",
  pages    = "1--23",
  month    =  "24~" # feb,
  year     =  2012,
  keywords = "SNN",
  language = "en",
  issn     = "0093-3341",
  pmid     = "22364581",
  doi      = "10.3109/0954898X.2011.651520"
}

@ARTICLE{Tromans2012-db,
  title    = "Learning view invariant recognition with partially occluded
              objects",
  author   = "Tromans, James M and Higgins, Irina and Stringer, Simon M",
  abstract = "This paper investigates how a neural network model of the ventral
              visual pathway, VisNet, can form separate view invariant
              representations of a number of objects seen rotating together. In
              particular, in the current work one of the rotating objects is
              always partially occluded by the other objects present during
              training. A key challenge for the model is to link together the
              separate partial views of the occluded object into a single view
              invariant representation of that object. We show how this can be
              achieved by Continuous Transformation (CT) learning, which relies
              on spatial similarity between successive views of each object.
              After training, the network had developed cells in the output
              layer which had learned to respond invariantly to particular
              objects over most or all views, with each cell responding to only
              one object. All objects, including the partially occluded object,
              were individually represented by a unique subset of output cells.",
  journal  = "Front. Comput. Neurosci.",
  volume   =  6,
  pages    = "48",
  month    =  "25~" # jul,
  year     =  2012,
  keywords = "continuous transformation; inferior temporal cortex; object
              recognition; occlusion;SNN",
  language = "en",
  issn     = "1662-5188",
  pmid     = "22848200",
  doi      = "10.3389/fncom.2012.00048",
  pmc      = "PMC3404435"
}

@ARTICLE{Eguchi2015-kx,
  title    = "Computational modeling of the neural representation of object
              shape in the primate ventral visual system",
  author   = "Eguchi, Akihiro and Mender, Bedeho M W and Evans, Benjamin D and
              Humphreys, Glyn W and Stringer, Simon M",
  abstract = "Neurons in successive stages of the primate ventral visual
              pathway encode the spatial structure of visual objects. In this
              paper, we investigate through computer simulation how these cell
              firing properties may develop through unsupervised
              visually-guided learning. Individual neurons in the model are
              shown to exploit statistical regularity and temporal continuity
              of the visual inputs during training to learn firing properties
              that are similar to neurons in V4 and TEO. Neurons in V4 encode
              the conformation of boundary contour elements at a particular
              position within an object regardless of the location of the
              object on the retina, while neurons in TEO integrate information
              from multiple boundary contour elements. This representation goes
              beyond mere object recognition, in which neurons simply respond
              to the presence of a whole object, but provides an essential
              foundation from which the brain is subsequently able to recognize
              the whole object.",
  journal  = "Front. Comput. Neurosci.",
  volume   =  9,
  pages    = "100",
  month    =  "4~" # aug,
  year     =  2015,
  keywords = "TEO; V4; hierarchical networks; neural network; shape
              representation; trace learning; ventral visual pathway;SNN",
  language = "en",
  issn     = "1662-5188",
  pmid     = "26300766",
  doi      = "10.3389/fncom.2015.00100",
  pmc      = "PMC4523947"
}

@ARTICLE{Higgins2011-if,
  title    = "The role of independent motion in object segmentation in the
              ventral visual stream: Learning to recognise the separate parts
              of the body",
  author   = "Higgins, I V and Stringer, S M",
  abstract = "This paper investigates how the visual areas of the brain may
              learn to segment the bodies of humans and other animals into
              separate parts. A neural network model of the ventral visual
              pathway, VisNet, was used to study this problem. In particular,
              the current work investigates whether independent motion of body
              parts can be sufficient to enable the visual system to learn
              separate representations of them even when the body parts are
              never seen in isolation. The network was shown to be able to
              separate out the independently moving body parts because the
              independent motion created statistical decoupling between them.",
  journal  = "Vision Res.",
  volume   =  51,
  number   =  6,
  pages    = "553--562",
  month    =  "25~" # mar,
  year     =  2011,
  keywords = "SNN",
  language = "en",
  issn     = "0042-6989, 1878-5646",
  pmid     = "21320521",
  doi      = "10.1016/j.visres.2011.01.016"
}

@MISC{Perez-Nieves2019-sy,
  title    = "Advantages of heterogeneity of parameters in spiking neural
              network training",
  author   = "Perez-Nieves, Nicolas and Leung, Vincent C H and Dragotti, Pier
              Luigi and Goodman, Dan F M",
  journal  = "2019 Conference on Cognitive Computational Neuroscience",
  year     =  2019,
  keywords = "SNN",
  doi      = "10.32470/ccn.2019.1173-0"
}

@ARTICLE{Richards2019-gj,
  title    = "A deep learning framework for neuroscience",
  author   = "Richards, Blake A and Lillicrap, Timothy P and Beaudoin, Philippe
              and Bengio, Yoshua and Bogacz, Rafal and Christensen, Amelia and
              Clopath, Claudia and Costa, Rui Ponte and de Berker, Archy and
              Ganguli, Surya and Gillon, Colleen J and Hafner, Danijar and
              Kepecs, Adam and Kriegeskorte, Nikolaus and Latham, Peter and
              Lindsay, Grace W and Miller, Kenneth D and Naud, Richard and
              Pack, Christopher C and Poirazi, Panayiota and Roelfsema, Pieter
              and Sacramento, Jo{\~a}o and Saxe, Andrew and Scellier, Benjamin
              and Schapiro, Anna C and Senn, Walter and Wayne, Greg and Yamins,
              Daniel and Zenke, Friedemann and Zylberberg, Joel and Therien,
              Denis and Kording, Konrad P",
  abstract = "Systems neuroscience seeks explanations for how the brain
              implements a wide variety of perceptual, cognitive and motor
              tasks. Conversely, artificial intelligence attempts to design
              computational systems based on the tasks they will have to solve.
              In artificial neural networks, the three components specified by
              design are the objective functions, the learning rules and the
              architectures. With the growing success of deep learning, which
              utilizes brain-inspired architectures, these three designed
              components have increasingly become central to how we model,
              engineer and optimize complex artificial learning systems. Here
              we argue that a greater focus on these components would also
              benefit systems neuroscience. We give examples of how this
              optimization-based framework can drive theoretical and
              experimental progress in neuroscience. We contend that this
              principled perspective on systems neuroscience will help to
              generate more rapid progress.",
  journal  = "Nat. Neurosci.",
  volume   =  22,
  number   =  11,
  pages    = "1761--1770",
  month    =  nov,
  year     =  2019,
  keywords = "Bio-med;Neuroscience / Mind ;SNN",
  language = "en",
  issn     = "1097-6256, 1546-1726",
  pmid     = "31659335",
  doi      = "10.1038/s41593-019-0520-2",
  pmc      = "PMC7115933"
}

@ARTICLE{Stimberg2019-us,
  title    = "Brian 2, an intuitive and efficient neural simulator",
  author   = "Stimberg, Marcel and Brette, Romain and Goodman, Dan Fm",
  abstract = "Brian 2 allows scientists to simply and efficiently simulate
              spiking neural network models. These models can feature novel
              dynamical equations, their interactions with the environment, and
              experimental protocols. To preserve high performance when
              defining new models, most simulators offer two options: low-level
              programming or description languages. The first option requires
              expertise, is prone to errors, and is problematic for
              reproducibility. The second option cannot describe all aspects of
              a computational experiment, such as the potentially complex logic
              of a stimulation protocol. Brian addresses these issues using
              runtime code generation. Scientists write code with simple and
              concise high-level descriptions, and Brian transforms them into
              efficient low-level code that can run interleaved with their
              code. We illustrate this with several challenging examples: a
              plastic model of the pyloric network, a closed-loop sensorimotor
              model, a programmatic exploration of a neuron model, and an
              auditory model with real-time input.",
  journal  = "Elife",
  volume   =  8,
  month    =  "20~" # aug,
  year     =  2019,
  keywords = "computational neuroscience; neuroscience; none; simulation;
              software;SNN",
  language = "en",
  issn     = "2050-084X",
  pmid     = "31429824",
  doi      = "10.7554/eLife.47314",
  pmc      = "PMC6786860"
}

@ARTICLE{Masquelier2008-rv,
  title    = "Spike timing dependent plasticity finds the start of repeating
              patterns in continuous spike trains",
  author   = "Masquelier, Timoth{\'e}e and Guyonneau, Rudy and Thorpe, Simon J",
  abstract = "Experimental studies have observed Long Term synaptic
              Potentiation (LTP) when a presynaptic neuron fires shortly before
              a postsynaptic neuron, and Long Term Depression (LTD) when the
              presynaptic neuron fires shortly after, a phenomenon known as
              Spike Timing Dependent Plasticity (STDP). When a neuron is
              presented successively with discrete volleys of input spikes STDP
              has been shown to learn 'early spike patterns', that is to
              concentrate synaptic weights on afferents that consistently fire
              early, with the result that the postsynaptic spike latency
              decreases, until it reaches a minimal and stable value. Here, we
              show that these results still stand in a continuous regime where
              afferents fire continuously with a constant population rate. As
              such, STDP is able to solve a very difficult computational
              problem: to localize a repeating spatio-temporal spike pattern
              embedded in equally dense 'distractor' spike trains. STDP thus
              enables some form of temporal coding, even in the absence of an
              explicit time reference. Given that the mechanism exposed here is
              simple and cheap it is hard to believe that the brain did not
              evolve to use it.",
  journal  = "PLoS One",
  volume   =  3,
  number   =  1,
  pages    = "e1377",
  month    =  "2~" # jan,
  year     =  2008,
  keywords = "SNN",
  language = "en",
  issn     = "1932-6203",
  pmid     = "18167538",
  doi      = "10.1371/journal.pone.0001377",
  pmc      = "PMC2147052"
}

@UNPUBLISHED{Stimberg2018-bm,
  title    = "{Brian2GeNN}: a system for accelerating a large variety of
              spiking neural networks with graphics hardware",
  author   = "Stimberg, Marcel and Goodman, Dan F M and Nowotny, Thomas",
  abstract = "``Brian'' is a popular Python-based simulator for spiking neural
              networks, commonly used in computational neuroscience. GeNN is a
              C++-based meta-compiler for accelerating spiking neural network
              simulations using consumer or high performance grade graphics
              processing units (GPUs). Here we introduce a new software
              package, Brian2GeNN, that connects the two systems so that users
              can make use of GeNN GPU acceleration when developing their
              models in Brian, without requiring any technical knowledge about
              GPUs, C++ or GeNN. The new Brian2GeNN software uses a pipeline of
              code generation to translate Brian scripts into C++ code that can
              be used as input to GeNN, and subsequently can be run on suitable
              NVIDIA GPU accelerators. From the user's perspective, the entire
              pipeline is invoked by adding two simple lines to their Brian
              scripts. We have shown that using Brian2GeNN, typical models can
              run tens to hundreds of times faster than on CPU.",
  journal  = "bioRxiv",
  pages    = "448050",
  month    =  "20~" # oct,
  year     =  2018,
  keywords = "SNN",
  language = "en",
  doi      = "10.1101/448050"
}

@ARTICLE{Brette_undated-qz,
  title    = "Vectorised algorithms for spiking neural network simulation",
  author   = "Brette, Romain and Goodman, Dan F M",
  keywords = "SNN"
}

@ARTICLE{Capecci2020-uj,
  title    = "Modelling gene interaction networks from time-series gene
              expression data using evolving spiking neural networks",
  author   = "Capecci, Elisa and Lobo, Jesus L and La{\~n}a, Ibai and
              Espinosa-Ramos, Josafath I and Kasabov, Nikola",
  abstract = "The genetic mechanisms responsible for the differentiation,
              metabolism, morphology and function of a cell in both normal and
              abnormal conditions can be uncovered by the analysis of
              transcriptomes. Mining big data such as the information encoded
              in nucleic acids, proteins, and metabolites has challenged
              researchers for several years now. Even though bioinformatics and
              system biology techniques have improved greatly and many
              improvements have been done in these fields of research, most of
              the processes that influence gene interaction over time are still
              unknown. In this study, we apply state-of-the art spiking neural
              network techniques to model, analyse and extract information
              about the regulatory processes of gene expression over time. A
              case study of microarray profiling in human skin during
              elicitation of eczema is used to examine the temporal association
              of genes involved in the inflammatory response, by means of a
              gene interaction network. Spiking neural network techniques are
              able to learn the interaction between genes using information
              encoded from the time-series gene expression data as spikes. The
              temporal interaction is learned, and the patterns of activity
              extracted and analysed with a gene interaction network. Results
              demonstrated that useful knowledge can be extracted from the data
              by using spiking neural network, unlocking some of the possible
              mechanisms involved in the regulatory process of gene expression.",
  journal  = "Evolving Systems",
  volume   =  11,
  number   =  4,
  pages    = "599--613",
  month    =  "1~" # dec,
  year     =  2020,
  keywords = "SNN;Bio-med;EA;Transcriptomics",
  issn     = "1868-6486",
  doi      = "10.1007/s12530-019-09269-6"
}

@UNPUBLISHED{Perez-Nieves2021-uj,
  title    = "Neural heterogeneity promotes robust learning",
  author   = "Perez-Nieves, Nicolas and Leung, Vincent C H and Dragotti, Pier
              Luigi and Goodman, Dan F M",
  abstract = "The brain has a hugely diverse, heterogeneous structure. Whether
              or not heterogeneity at the neural level plays a functional role
              remains unclear, and has been relatively little explored in
              models which are often highly homogeneous. We compared the
              performance of spiking neural networks trained to carry out tasks
              of real-world difficulty, with varying degrees of heterogeneity,
              and found that it substantially improved task performance.
              Learning was more stable and robust, particularly for tasks with
              a rich temporal structure. In addition, the distribution of
              neuronal parameters in the trained networks closely matches those
              observed experimentally. We suggest that the heterogeneity
              observed in the brain may be more than just the byproduct of
              noisy processes, but rather may serve an active and important
              role in allowing animals to learn in changing environments.
              Summary Neural heterogeneity is metabolically efficient for
              learning, and optimal parameter distribution matches experimental
              data. \#\#\# Competing Interest Statement The authors have
              declared no competing interest.",
  journal  = "bioRxiv",
  pages    = "2020.12.18.423468",
  month    =  "22~" # mar,
  year     =  2021,
  keywords = "SNN",
  language = "en",
  doi      = "10.1101/2020.12.18.423468"
}

@MISC{Cutsuridis2013-gs,
  title    = "Cognitive models of the perception-action cycle: A view from the
              brain",
  author   = "Cutsuridis, Vassilis",
  journal  = "The 2013 International Joint Conference on Neural Networks
              (IJCNN)",
  year     =  2013,
  keywords = "SNN",
  doi      = "10.1109/ijcnn.2013.6706713"
}

@ARTICLE{Der2015-au,
  title    = "Novel plasticity rule can explain the development of sensorimotor
              intelligence",
  author   = "Der, Ralf and Martius, Georg",
  abstract = "Grounding autonomous behavior in the nervous system is a
              fundamental challenge for neuroscience. In particular,
              self-organized behavioral development provides more questions
              than answers. Are there special functional units for curiosity,
              motivation, and creativity? This paper argues that these features
              can be grounded in synaptic plasticity itself, without requiring
              any higher-level constructs. We propose differential extrinsic
              plasticity (DEP) as a new synaptic rule for self-learning systems
              and apply it to a number of complex robotic systems as a test
              case. Without specifying any purpose or goal, seemingly
              purposeful and adaptive rhythmic behavior is developed,
              displaying a certain level of sensorimotor intelligence. These
              surprising results require no system-specific modifications of
              the DEP rule. They rather arise from the underlying mechanism of
              spontaneous symmetry breaking, which is due to the tight brain
              body environment coupling. The new synaptic rule is biologically
              plausible and would be an interesting target for neurobiological
              investigation. We also argue that this neuronal mechanism may
              have been a catalyst in natural evolution.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  112,
  number   =  45,
  pages    = "E6224--32",
  month    =  "10~" # nov,
  year     =  2015,
  keywords = "development; neural plasticity; robotics; self-organization;
              sensorimotor intelligence;SNN",
  language = "en",
  issn     = "0027-8424, 1091-6490",
  pmid     = "26504200",
  doi      = "10.1073/pnas.1508400112",
  pmc      = "PMC4653169"
}

@ARTICLE{Hazan2018-ro,
  title         = "Unsupervised Learning with {Self-Organizing} Spiking Neural
                   Networks",
  author        = "Hazan, Hananel and Saunders, Daniel J and Sanghavi, Darpan T
                   and Siegelmann, Hava T and Kozma, Robert",
  abstract      = "We present a system comprising a hybridization of
                   self-organized map (SOM) properties with spiking neural
                   networks (SNNs) that retain many of the features of SOMs.
                   Networks are trained in an unsupervised manner to learn a
                   self-organized lattice of filters via excitatory-inhibitory
                   interactions among populations of neurons. We develop and
                   test various inhibition strategies, such as growing with
                   inter-neuron distance and two distinct levels of inhibition.
                   The quality of the unsupervised learning algorithm is
                   evaluated using examples with known labels. Several
                   biologically-inspired classification tools are proposed and
                   compared, including population-level confidence rating, and
                   n-grams using spike motif algorithm. Using the optimal
                   choice of parameters, our approach produces improvements
                   over state-of-art spiking neural networks.",
  month         =  "24~" # jul,
  year          =  2018,
  keywords      = "SNN",
  archivePrefix = "arXiv",
  eprint        = "1807.09374",
  primaryClass  = "cs.NE",
  arxivid       = "1807.09374",
  doi           = "10.1162/neco.1995.7.3.425"
}

@ARTICLE{Taherkhani2020-re,
  title    = "A review of learning in biologically plausible spiking neural
              networks",
  author   = "Taherkhani, Aboozar and Belatreche, Ammar and Li, Yuhua and
              Cosma, Georgina and Maguire, Liam P and McGinnity, T M",
  abstract = "Artificial neural networks have been used as a powerful
              processing tool in various areas such as pattern recognition,
              control, robotics, and bioinformatics. Their wide applicability
              has encouraged researchers to improve artificial neural networks
              by investigating the biological brain. Neurological research has
              significantly progressed in recent years and continues to reveal
              new characteristics of biological neurons. New technologies can
              now capture temporal changes in the internal activity of the
              brain in more detail and help clarify the relationship between
              brain activity and the perception of a given stimulus. This new
              knowledge has led to a new type of artificial neural network, the
              Spiking Neural Network (SNN), that draws more faithfully on
              biological properties to provide higher processing abilities. A
              review of recent developments in learning of spiking neurons is
              presented in this paper. First the biological background of SNN
              learning algorithms is reviewed. The important elements of a
              learning algorithm such as the neuron model, synaptic plasticity,
              information encoding and SNN topologies are then presented. Then,
              a critical review of the state-of-the-art learning algorithms for
              SNNs using single and multiple spikes is presented. Additionally,
              deep spiking neural networks are reviewed, and challenges and
              opportunities in the SNN field are discussed.",
  journal  = "Neural Netw.",
  volume   =  122,
  pages    = "253--272",
  month    =  feb,
  year     =  2020,
  keywords = "Learning; Spiking neural network (SNN); Synaptic plasticity;SNN",
  language = "en",
  issn     = "0893-6080, 1879-2782",
  pmid     = "31726331",
  doi      = "10.1016/j.neunet.2019.09.036"
}

@ARTICLE{Bao2020-rx,
  title    = "A map of object space in primate inferotemporal cortex",
  author   = "Bao, Pinglei and She, Liang and McGill, Mason and Tsao, Doris Y",
  abstract = "The inferotemporal (IT) cortex is responsible for object
              recognition, but it is unclear how the representation of visual
              objects is organized in this part of the brain. Areas that are
              selective for categories such as faces, bodies, and scenes have
              been found1-5, but large parts of IT cortex lack any known
              specialization, raising the question of what general principle
              governs IT organization. Here we used functional MRI,
              microstimulation, electrophysiology, and deep networks to
              investigate the organization of macaque IT cortex. We built a
              low-dimensional object space to describe general objects using a
              feedforward deep neural network trained on object
              classification6. Responses of IT cells to a large set of objects
              revealed that single IT cells project incoming objects onto
              specific axes of this space. Anatomically, cells were clustered
              into four networks according to the first two components of their
              preferred axes, forming a map of object space. This map was
              repeated across three hierarchical stages of increasing view
              invariance, and cells that comprised these maps collectively
              harboured sufficient coding capacity to approximately reconstruct
              objects. These results provide a unified picture of IT
              organization in which category-selective regions are part of a
              coarse map of object space whose dimensions can be extracted from
              a deep network.",
  journal  = "Nature",
  volume   =  583,
  number   =  7814,
  pages    = "103--108",
  month    =  jul,
  year     =  2020,
  keywords = "Neuroscience / Mind ;ML;SNN",
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "32494012",
  doi      = "10.1038/s41586-020-2350-5"
}

@ARTICLE{DiGiovanna_2009-od,
  title    = "Coadaptive {Brain--Machine} Interface via Reinforcement Learning",
  author   = "DiGiovanna $^*$, J and Mahmoudi, B and Fortes, J and Principe, J
              C and Sanchez, J C",
  abstract = "This paper introduces and demonstrates a novel brain-machine
              interface (BMI) architecture based on the concepts of
              reinforcement learning (RL), coadaptation, and shaping. RL allows
              the BMI control algorithm to learn to complete tasks from
              interactions with the environment, rather than an explicit
              training signal. Coadaption enables continuous, synergistic
              adaptation between the BMI control algorithm and BMI user working
              in changing environments. Shaping is designed to reduce the
              learning curve for BMI users attempting to control a prosthetic.
              Here, we present the theory and in vivo experimental paradigm to
              illustrate how this BMI learns to complete a reaching task using
              a prosthetic arm in a 3-D workspace based on the user's neuronal
              activity. This semisupervised learning framework does not require
              user movements. We quantify BMI performance in closed-loop brain
              control over six to ten days for three rats as a function of
              increasing task difficulty. All three subjects coadapted with
              their BMI control algorithms to control the prosthetic
              significantly above chance at each level of difficulty.",
  journal  = "IEEE Transactions on Biomedical Engineering",
  volume   =  56,
  number   =  1,
  pages    = "54--64",
  month    =  jan,
  year     =  2009,
  keywords = "Prosthetics;In vivo;Neural prosthesis;Biomedical
              engineering;Kinematics;Lifting equipment;Shape
              control;Semisupervised learning;Rats;Organisms;Brain--machine
              interface (BMI);coadaptation;neuroprosthetic;reinforcement
              learning (RL);Brain-Machine Interfaces;Reinforcement
              Learning;Co-adaptation;Neuroprosthetic;SNN",
  issn     = "1558-2531",
  doi      = "10.1109/TBME.2008.926699"
}

@ARTICLE{Schuman2017-mp,
  title         = "A Survey of Neuromorphic Computing and Neural Networks in
                   Hardware",
  author        = "Schuman, Catherine D and Potok, Thomas E and Patton, Robert
                   M and Douglas Birdwell, J and Dean, Mark E and Rose, Garrett
                   S and Plank, James S",
  abstract      = "Neuromorphic computing has come to refer to a variety of
                   brain-inspired computers, devices, and models that contrast
                   the pervasive von Neumann computer architecture. This
                   biologically inspired approach has created highly connected
                   synthetic neurons and synapses that can be used to model
                   neuroscience theories as well as solve challenging machine
                   learning problems. The promise of the technology is to
                   create a brain-like ability to learn and adapt, but the
                   technical challenges are significant, starting with an
                   accurate neuroscience model of how the brain works, to
                   finding materials and engineering breakthroughs to build
                   devices to support these models, to creating a programming
                   framework so the systems can learn, to creating applications
                   with brain-like capabilities. In this work, we provide a
                   comprehensive survey of the research and motivations for
                   neuromorphic computing over its history. We begin with a
                   35-year review of the motivations and drivers of
                   neuromorphic computing, then look at the major research
                   areas of the field, which we define as neuro-inspired
                   models, algorithms and learning approaches, hardware and
                   devices, supporting systems, and finally applications. We
                   conclude with a broad discussion on the major research
                   topics that need to be addressed in the coming years to see
                   the promise of neuromorphic computing fulfilled. The goals
                   of this work are to provide an exhaustive review of the
                   research conducted in neuromorphic computing since the
                   inception of the term, and to motivate further work by
                   illuminating gaps in the field where new research is needed.",
  month         =  "19~" # may,
  year          =  2017,
  keywords      = "SNN",
  archivePrefix = "arXiv",
  eprint        = "1705.06963",
  primaryClass  = "cs.NE",
  arxivid       = "1705.06963"
}

@UNPUBLISHED{Sezener2021-kn,
  title    = "A rapid and efficient learning rule for biological neural
              circuits",
  author   = "Sezener, Eren and Grabska-Barwi{\'n}ska, Agnieszka and
              Kostadinov, Dimitar and Beau, Maxime and Krishnagopal, Sanjukta
              and Budden, David and Hutter, Marcus and Veness, Joel and
              Botvinick, Matthew and Clopath, Claudia and H{\"a}usser, Michael
              and Latham, Peter E",
  abstract = "The dominant view in neuroscience is that changes in synaptic
              weights underlie learning. It is unclear, however, how the brain
              is able to determine which synapses should change, and by how
              much. This uncertainty stands in sharp contrast to deep learning,
              where changes in weights are explicitly engineered to optimize
              performance. However, the main tool for doing that,
              backpropagation, is not biologically plausible, and networks
              trained with this rule tend to forget old tasks when learning new
              ones. Here we introduce the Dendritic Gated Network (DGN), a
              variant of the Gated Linear Network [[1][1], [2][2]], which
              offers a biologically plausible alternative to backpropagation.
              DGNs combine dendritic ``gating'' (whereby interneurons target
              dendrites to shape neuronal response) with local learning rules
              to yield provably efficient performance. They are significantly
              more data efficient than conventional artificial networks and are
              highly resistant to forgetting, and we show that they perform
              well on a variety of tasks, in some cases better than
              backpropagation. The DGN bears similarities to the cerebellum,
              where there is evidence for shaping of Purkinje cell responses by
              interneurons. It also makes several experimental predictions, one
              of which we validate with in vivo cerebellar imaging of mice
              performing a motor task. \#\#\# Competing Interest Statement The
              authors have declared no competing interest. [1]: \#ref-1 [2]:
              \#ref-2",
  journal  = "bioRxiv",
  pages    = "2021.03.10.434756",
  month    =  "12~" # mar,
  year     =  2021,
  keywords = "SNN",
  language = "en",
  doi      = "10.1101/2021.03.10.434756"
}

@ARTICLE{McInnes2018-dz,
  title         = "{UMAP}: Uniform Manifold Approximation and Projection for
                   Dimension Reduction",
  author        = "McInnes, Leland and Healy, John and Melville, James",
  abstract      = "UMAP (Uniform Manifold Approximation and Projection) is a
                   novel manifold learning technique for dimension reduction.
                   UMAP is constructed from a theoretical framework based in
                   Riemannian geometry and algebraic topology. The result is a
                   practical scalable algorithm that applies to real world
                   data. The UMAP algorithm is competitive with t-SNE for
                   visualization quality, and arguably preserves more of the
                   global structure with superior run time performance.
                   Furthermore, UMAP has no computational restrictions on
                   embedding dimension, making it viable as a general purpose
                   dimension reduction technique for machine learning.",
  month         =  "9~" # feb,
  year          =  2018,
  keywords      = "ML",
  archivePrefix = "arXiv",
  eprint        = "1802.03426",
  primaryClass  = "stat.ML",
  arxivid       = "1802.03426"
}

@MISC{noauthor_undated-fh,
  title = "intro-pca.pdf"
}

@ARTICLE{Harris2020-bm,
  title    = "Array programming with {NumPy}",
  author   = "Harris, Charles R and Millman, K Jarrod and van der Walt,
              St{\'e}fan J and Gommers, Ralf and Virtanen, Pauli and
              Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg,
              Sebastian and Smith, Nathaniel J and Kern, Robert and Picus,
              Matti and Hoyer, Stephan and van Kerkwijk, Marten H and Brett,
              Matthew and Haldane, Allan and Del R{\'\i}o, Jaime Fern{\'a}ndez
              and Wiebe, Mark and Peterson, Pearu and G{\'e}rard-Marchant,
              Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren
              and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E",
  abstract = "Array programming provides a powerful, compact and expressive
              syntax for accessing, manipulating and operating on data in
              vectors, matrices and higher-dimensional arrays. NumPy is the
              primary array programming library for the Python language. It has
              an essential role in research analysis pipelines in fields as
              diverse as physics, chemistry, astronomy, geoscience, biology,
              psychology, materials science, engineering, finance and
              economics. For example, in astronomy, NumPy was an important part
              of the software stack used in the discovery of gravitational
              waves1 and in the first imaging of a black hole2. Here we review
              how a few fundamental array concepts lead to a simple and
              powerful programming paradigm for organizing, exploring and
              analysing scientific data. NumPy is the foundation upon which the
              scientific Python ecosystem is constructed. It is so pervasive
              that several projects, targeting audiences with specialized
              needs, have developed their own NumPy-like interfaces and array
              objects. Owing to its central position in the ecosystem, NumPy
              increasingly acts as an interoperability layer between such array
              computation libraries and, together with its application
              programming interface (API), provides a flexible framework to
              support the next decade of scientific and industrial analysis.",
  journal  = "Nature",
  volume   =  585,
  number   =  7825,
  pages    = "357--362",
  month    =  sep,
  year     =  2020,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "32939066",
  doi      = "10.1038/s41586-020-2649-2",
  pmc      = "PMC7759461"
}

@MISC{noauthor_undated-yc,
  title = "computational\_theory\_of\_mind.pdf"
}

@MISC{noauthor_undated-bt,
  title = "causal\_resoning\_ml.pdf",
  doi   = "10.1145/nnnnnnn.nnnnnnn"
}

@ARTICLE{Man2019-st,
  title     = "Homeostasis and soft robotics in the design of feeling machines",
  author    = "Man, Kingson and Damasio, Antonio",
  abstract  = "Attempts to create machines that behave intelligently often
               conceptualize intelligence as the ability to achieve goals,
               leaving unanswered a crucial question: whose goals? In a dynamic
               and unpredictable world, an intelligent agent should hold its
               own meta-goal of self-preservation, like living organisms whose
               survival relies on homeostasis: the regulation of body states
               aimed at maintaining conditions compatible with life. In
               organisms capable of mental states, feelings are a mental
               expression of the state of life in the body and play a critical
               role in regulating behaviour. Our goal here is to inquire about
               conditions that would potentially allow machines to care about
               what they do or think. Under certain conditions, machines
               capable of implementing a process resembling homeostasis might
               also acquire a source of motivation and a new means to evaluate
               behaviour, akin to that of feelings in living organisms. Drawing
               on recent developments in soft robotics and multisensory
               abstraction, we propose a new class of machines inspired by the
               principles of homeostasis. The resulting machines would (1)
               exhibit equivalents to feeling; (2) improve their functionality
               across a range of environments; and (3) constitute a platform
               for investigating consciousness, intelligence and the feeling
               process itself. Robots and machines are generally designed to
               perform specific tasks. Unlike humans, they lack the ability to
               generate feelings based on interactions with the world. The
               authors propose a new class of machines with evaluation
               processes akin to feelings, based on the principles of
               homeostasis and developments in soft robotics and multisensory
               integration.",
  journal   = "Nature Machine Intelligence",
  publisher = "Nature Publishing Group",
  volume    =  1,
  number    =  10,
  pages     = "446--452",
  month     =  "9~" # oct,
  year      =  2019,
  keywords  = "Bio-med",
  language  = "en",
  issn      = "2522-5839, 2522-5839",
  doi       = "10.1038/s42256-019-0103-7"
}

@ARTICLE{Mitchell2021-kh,
  title         = "Abstraction and {Analogy-Making} in Artificial Intelligence",
  author        = "Mitchell, Melanie",
  abstract      = "Conceptual abstraction and analogy-making are key abilities
                   underlying humans' abilities to learn, reason, and robustly
                   adapt their knowledge to new domains. Despite of a long
                   history of research on constructing AI systems with these
                   abilities, no current AI system is anywhere close to a
                   capability of forming humanlike abstractions or analogies.
                   This paper reviews the advantages and limitations of several
                   approaches toward this goal, including symbolic methods,
                   deep learning, and probabilistic program induction. The
                   paper concludes with several proposals for designing
                   challenge tasks and evaluation measures in order to make
                   quantifiable and generalizable progress in this area.",
  month         =  "22~" # feb,
  year          =  2021,
  keywords      = "Neuroscience / Mind ;ML;EA",
  archivePrefix = "arXiv",
  eprint        = "2102.10717",
  primaryClass  = "cs.AI",
  arxivid       = "2102.10717"
}

@ARTICLE{Senior2020-ze,
  title    = "Improved protein structure prediction using potentials from deep
              learning",
  author   = "Senior, Andrew W and Evans, Richard and Jumper, John and
              Kirkpatrick, James and Sifre, Laurent and Green, Tim and Qin,
              Chongli and {\v Z}{\'\i}dek, Augustin and Nelson, Alexander W R
              and Bridgland, Alex and Penedones, Hugo and Petersen, Stig and
              Simonyan, Karen and Crossan, Steve and Kohli, Pushmeet and Jones,
              David T and Silver, David and Kavukcuoglu, Koray and Hassabis,
              Demis",
  abstract = "Protein structure prediction can be used to determine the
              three-dimensional shape of a protein from its amino acid
              sequence1. This problem is of fundamental importance as the
              structure of a protein largely determines its function2; however,
              protein structures can be difficult to determine experimentally.
              Considerable progress has recently been made by leveraging
              genetic information. It is possible to infer which amino acid
              residues are in contact by analysing covariation in homologous
              sequences, which aids in the prediction of protein structures3.
              Here we show that we can train a neural network to make accurate
              predictions of the distances between pairs of residues, which
              convey more information about the structure than contact
              predictions. Using this information, we construct a potential of
              mean force4 that can accurately describe the shape of a protein.
              We find that the resulting potential can be optimized by a simple
              gradient descent algorithm to generate structures without complex
              sampling procedures. The resulting system, named AlphaFold,
              achieves high accuracy, even for sequences with fewer homologous
              sequences. In the recent Critical Assessment of Protein Structure
              Prediction5 (CASP13)-a blind assessment of the state of the
              field-AlphaFold created high-accuracy structures (with template
              modelling (TM) scores6 of 0.7 or higher) for 24 out of 43 free
              modelling domains, whereas the next best method, which used
              sampling and contact information, achieved such accuracy for only
              14 out of 43 domains. AlphaFold represents a considerable advance
              in protein-structure prediction. We expect this increased
              accuracy to enable insights into the function and malfunction of
              proteins, especially in cases for which no structures for
              homologous proteins have been experimentally determined7.",
  journal  = "Nature",
  volume   =  577,
  number   =  7792,
  pages    = "706--710",
  month    =  jan,
  year     =  2020,
  keywords = "Bio-med",
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "31942072",
  doi      = "10.1038/s41586-019-1923-7"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Singh2020-fw,
  title    = "Robust Detection of Parkinson's Disease Using Harvested
              Smartphone Voice Data: A Telemedicine Approach",
  author   = "Singh, Sanjana and Xu, Wenyao",
  abstract = "Introduction: Parkinson's disease affects over 10 million people
              globally, and 20\% of patients with Parkinson's disease have not
              been diagnosed as such. The clinical diagnosis is costly: there
              are no specific tests or biomarkers and it can take days to
              diagnose as it relies on a holistic evaluation of the
              individual's symptoms. Existing research either predicts a
              Unified Parkinson Disease Rating Scale rating, uses other key
              Parkinsonian features such as tapping, gait, and tremor to
              diagnose an individual, or focuses on different audio features.
              Methods: In this article, we present a classification approach
              implemented as an iOS App to detect whether an individual has
              Parkinson's using 10-s audio clips of the individual saying
              ``aaah'' into a smartphone. Results: The 1,000 voice samples
              analyzed were obtained from the mPower (mobile Parkinson Disease)
              study, which collected 65,022 voice samples from 5,826 unique
              participants. Conclusions: The experimental results comparing 12
              different methods indicate that our approach achieves 99.0\%
              accuracy in under a second, which significantly outperforms both
              prior diagnosis methods in the accuracy achieved and the
              efficiency of clinical diagnoses.",
  journal  = "Telemed. J. E. Health.",
  volume   =  26,
  number   =  3,
  pages    = "327--334",
  month    =  mar,
  year     =  2020,
  keywords = "Parkinson's disease; home health monitoring; m-Health; sensor
              technology; telemedicine",
  language = "en",
  issn     = "1530-5627, 1556-3669",
  pmid     = "31033397",
  doi      = "10.1089/tmj.2018.0271",
  pmc      = "PMC7071066"
}

@ARTICLE{Evans2021-iq,
  title    = "Making sense of sensory input",
  author   = "Evans, Richard and Hern{\'a}ndez-Orallo, Jos{\'e} and Welbl,
              Johannes and Kohli, Pushmeet and Sergot, Marek",
  abstract = "This paper attempts to answer a central question in unsupervised
              learning: what does it mean to ``make sense'' of a sensory
              sequence? In our formalization, making sense involves
              constructing a symbolic causal theory that both explains the
              sensory sequence and also satisfies a set of unity conditions.
              The unity conditions insist that the constituents of the causal
              theory -- objects, properties, and laws -- must be integrated
              into a coherent whole. On our account, making sense of sensory
              input is a type of program synthesis, but it is unsupervised
              program synthesis. Our second contribution is a computer
              implementation, the Apperception Engine, that was designed to
              satisfy the above requirements. Our system is able to produce
              interpretable human-readable causal theories from very small
              amounts of data, because of the strong inductive bias provided by
              the unity conditions. A causal theory produced by our system is
              able to predict future sensor readings, as well as retrodict
              earlier readings, and impute (fill in the blanks of) missing
              sensory readings, in any combination. In fact, it is able to do
              all three tasks simultaneously. We tested the engine in a diverse
              variety of domains, including cellular automata, rhythms and
              simple nursery tunes, multi-modal binding problems, occlusion
              tasks, and sequence induction intelligence tests. In each domain,
              we test our engine's ability to predict future sensor values,
              retrodict earlier sensor values, and impute missing sensory data.
              The Apperception Engine performs well in all these domains,
              significantly out-performing neural net baselines. We note in
              particular that in the sequence induction intelligence tests, our
              system achieved human-level performance. This is notable because
              our system is not a bespoke system designed specifically to solve
              intelligence tests, but a general-purpose system that was
              designed to make sense of any sensory sequence.",
  journal  = "Artif. Intell.",
  volume   =  293,
  pages    = "103438",
  month    =  "1~" # apr,
  year     =  2021,
  keywords = "Learning dynamical models; Unsupervised program synthesis",
  issn     = "0004-3702",
  doi      = "10.1016/j.artint.2020.103438"
}

@MISC{noauthor_undated-yw,
  title = "{Oxford\_proposal\_VladUng.pdf}"
}

@ARTICLE{Moldoveanu_undated-pt,
  title  = "Rate Distortion",
  author = "Moldoveanu, Matei"
}

@ARTICLE{Turner_undated-dl,
  title    = "Evolving Artificial Neural Networks using Cartesian Genetic
              Programming",
  author   = "Turner, Andrew James",
  keywords = "EA"
}

@ARTICLE{Yu2019-ax,
  title         = "Reinforcement Learning in Healthcare: A Survey",
  author        = "Yu, Chao and Liu, Jiming and Nemati, Shamim",
  abstract      = "As a subfield of machine learning, reinforcement learning
                   (RL) aims at empowering one's capabilities in behavioural
                   decision making by using interaction experience with the
                   world and an evaluative feedback. Unlike traditional
                   supervised learning methods that usually rely on one-shot,
                   exhaustive and supervised reward signals, RL tackles with
                   sequential decision making problems with sampled, evaluative
                   and delayed feedback simultaneously. Such distinctive
                   features make RL technique a suitable candidate for
                   developing powerful solutions in a variety of healthcare
                   domains, where diagnosing decisions or treatment regimes are
                   usually characterized by a prolonged and sequential
                   procedure. This survey discusses the broad applications of
                   RL techniques in healthcare domains, in order to provide the
                   research community with systematic understanding of
                   theoretical foundations, enabling methods and techniques,
                   existing challenges, and new insights of this emerging
                   paradigm. By first briefly examining theoretical foundations
                   and key techniques in RL research from efficient and
                   representational directions, we then provide an overview of
                   RL applications in healthcare domains ranging from dynamic
                   treatment regimes in chronic diseases and critical care,
                   automated medical diagnosis from both unstructured and
                   structured clinical data, as well as many other control or
                   scheduling domains that have infiltrated many aspects of a
                   healthcare system. Finally, we summarize the challenges and
                   open issues in current research, and point out some
                   potential solutions and directions for future research.",
  month         =  "22~" # aug,
  year          =  2019,
  archivePrefix = "arXiv",
  eprint        = "1908.08796",
  primaryClass  = "cs.LG",
  arxivid       = "1908.08796"
}

@ARTICLE{May2021-jf,
  title    = "Eight ways machine learning is assisting medicine",
  author   = "May, Mike",
  journal  = "Nat. Med.",
  volume   =  27,
  number   =  1,
  pages    = "2--3",
  month    =  jan,
  year     =  2021,
  language = "en",
  issn     = "1078-8956, 1546-170X",
  pmid     = "33442003",
  doi      = "10.1038/s41591-020-01197-2"
}

@MISC{noauthor_undated-sx,
  title = "{Dissertation\_VladUngureanu.pdf}"
}

@MISC{noauthor_undated-ig,
  title = "{York\_proposal\_VladUng.pdf}"
}

@ARTICLE{Roughgarden2018-gw,
  title         = "Complexity Theory, Game Theory, and Economics: The Barbados
                   Lectures",
  author        = "Roughgarden, Tim",
  abstract      = "This document collects the lecture notes from my mini-course
                   ``Complexity Theory, Game Theory, and Economics,'' taught at
                   the Bellairs Research Institute of McGill University,
                   Holetown, Barbados, February 19--23, 2017, as the 29th
                   McGill Invitational Workshop on Computational Complexity.
                   The goal of this mini-course is twofold: (i) to explain how
                   complexity theory has helped illuminate several barriers in
                   economics and game theory; and (ii) to illustrate how
                   game-theoretic questions have led to new and interesting
                   complexity theory, including recent several breakthroughs.
                   It consists of two five-lecture sequences: the Solar
                   Lectures, focusing on the communication and computational
                   complexity of computing equilibria; and the Lunar Lectures,
                   focusing on applications of complexity theory in game theory
                   and economics. No background in game theory is assumed.",
  month         =  "2~" # jan,
  year          =  2018,
  archivePrefix = "arXiv",
  eprint        = "1801.00734",
  primaryClass  = "cs.CC",
  arxivid       = "1801.00734"
}

@ARTICLE{Smith_undated-kl,
  title    = "Lecture 4: Cartesian Genetic Programming",
  author   = "Smith, Stephen",
  keywords = "EA"
}

@ARTICLE{Smith_undated-nh,
  title    = "Lecture 3: Genetic Programming",
  author   = "Smith, Stephen",
  keywords = "EA"
}

@MISC{noauthor_undated-mt,
  title = "{BIC-20-21-Lect-2.pdf}"
}

@MISC{noauthor_undated-qo,
  title = "{BICLab2-20.pdf}"
}

@ARTICLE{Smith_undated-sn,
  title    = "Lecture 1: Introduction to Biologically Inspired Computing",
  author   = "Smith, Stephen",
  keywords = "EA"
}

@MISC{noauthor_undated-pp,
  title = "{BICLab1-20v3.pdf}"
}

@ARTICLE{Masoudi-Sobhanzadeh2019-ua,
  title    = "{FeatureSelect}: a software for feature selection based on
              machine learning approaches",
  author   = "Masoudi-Sobhanzadeh, Yosef and Motieghader, Habib and
              Masoudi-Nejad, Ali",
  abstract = "BACKGROUND: Feature selection, as a preprocessing stage, is a
              challenging problem in various sciences such as biology,
              engineering, computer science, and other fields. For this
              purpose, some studies have introduced tools and softwares such as
              WEKA. Meanwhile, these tools or softwares are based on filter
              methods which have lower performance relative to wrapper methods.
              In this paper, we address this limitation and introduce a
              software application called FeatureSelect. In addition to filter
              methods, FeatureSelect consists of optimisation algorithms and
              three types of learners. It provides a user-friendly and
              straightforward method of feature selection for use in any kind
              of research, and can easily be applied to any type of balanced
              and unbalanced data based on several score functions like
              accuracy, sensitivity, specificity, etc. RESULTS: In addition to
              our previously introduced optimisation algorithm (WCC), a total
              of 10 efficient, well-known and recently developed algorithms
              have been implemented in FeatureSelect. We applied our software
              to a range of different datasets and evaluated the performance of
              its algorithms. Acquired results show that the performances of
              algorithms are varying on different datasets, but WCC, LCA, FOA,
              and LA are suitable than others in the overall state. The results
              also show that wrapper methods are better than filter methods.
              CONCLUSIONS: FeatureSelect is a feature or gene selection
              software application which is based on wrapper methods.
              Furthermore, it includes some popular filter methods and
              generates various comparison diagrams and statistical
              measurements. It is available from GitHub (
              https://github.com/LBBSoft/FeatureSelect ) and is free open
              source software under an MIT license.",
  journal  = "BMC Bioinformatics",
  volume   =  20,
  number   =  1,
  pages    = "170",
  month    =  "3~" # apr,
  year     =  2019,
  keywords = "Classification; Feature selection; Gene selection; Machine
              learning; Regression",
  language = "en",
  issn     = "1471-2105",
  pmid     = "30943889",
  doi      = "10.1186/s12859-019-2754-0",
  pmc      = "PMC6446290"
}

@MISC{noauthor_undated-ee,
  title = "what's expected of us.pdf"
}

@ARTICLE{Sloss2019-hs,
  title         = "2019 Evolutionary Algorithms Review",
  author        = "Sloss, Andrew N and Gustafson, Steven",
  abstract      = "Evolutionary algorithm research and applications began over
                   50 years ago. Like other artificial intelligence techniques,
                   evolutionary algorithms will likely see increased use and
                   development due to the increased availability of
                   computation, more robust and available open source software
                   libraries, and the increasing demand for artificial
                   intelligence techniques. As these techniques become more
                   adopted and capable, it is the right time to take a
                   perspective of their ability to integrate into society and
                   the human processes they intend to augment. In this review,
                   we explore a new taxonomy of evolutionary algorithms and
                   resulting classifications that look at five main areas: the
                   ability to manage the control of the environment with
                   limiters, the ability to explain and repeat the search
                   process, the ability to understand input and output
                   causality within a solution, the ability to manage algorithm
                   bias due to data or user design, and lastly, the ability to
                   add corrective measures. These areas are motivated by
                   today's pressures on industry to conform to both societies
                   concerns and new government regulatory rules. As many
                   reviews of evolutionary algorithms exist, after motivating
                   this new taxonomy, we briefly classify a broad range of
                   algorithms and identify areas of future research.",
  month         =  "3~" # jun,
  year          =  2019,
  keywords      = "EA",
  archivePrefix = "arXiv",
  eprint        = "1906.08870",
  primaryClass  = "cs.NE",
  arxivid       = "1906.08870"
}

@INPROCEEDINGS{Morse2016-sr,
  title     = "Simple Evolutionary Optimization Can Rival Stochastic Gradient
               Descent in Neural Networks",
  booktitle = "Proceedings of the Genetic and Evolutionary Computation
               Conference 2016",
  author    = "Morse, Gregory and Stanley, Kenneth O",
  abstract  = "While evolutionary algorithms (EAs) have long offered an
               alternative approach to optimization, in recent years
               backpropagation through stochastic gradient descent (SGD) has
               come to dominate the fields of neural network optimization and
               deep learning. One hypothesis for the absence of EAs in deep
               learning is that modern neural networks have become so high
               dimensional that evolution with its inexact gradient cannot
               match the exact gradient calculations of backpropagation.
               Furthermore, the evaluation of a single individual in evolution
               on the big data sets now prevalent in deep learning would
               present a prohibitive obstacle towards efficient optimization.
               This paper challenges these views, suggesting that EAs can be
               made to run significantly faster than previously thought by
               evaluating individuals only on a small number of training
               examples per generation. Surprisingly, using this approach with
               only a simple EA (called the limited evaluation EA or LEEA) is
               competitive with the performance of the state-of-the-art SGD
               variant RMSProp on several benchmarks with neural networks with
               over 1,000 weights. More investigation is warranted, but these
               initial results suggest the possibility that EAs could be the
               first viable training alternative for deep learning outside of
               SGD, thereby opening up deep learning to all the tools of
               evolutionary computation.",
  publisher = "Association for Computing Machinery",
  pages     = "477--484",
  series    = "GECCO '16",
  month     =  "20~" # jul,
  year      =  2016,
  address   = "New York, NY, USA",
  keywords  = "neural networks, pattern recognition and classification, deep
               learning, artificial intelligence, machine learning;EA",
  location  = "Denver, Colorado, USA",
  isbn      = "9781450342063",
  doi       = "10.1145/2908812.2908916"
}

@ARTICLE{Beyer2002-li,
  title   = "A comprehensive introduction",
  author  = "Beyer, Hans-Georg and Schwefel, Hans-Paul",
  journal = "Nat. Comput.",
  volume  =  1,
  pages   = "3--52",
  year    =  2002,
  issn    = "1567-7818"
}

@ARTICLE{Espejo2010-xv,
  title    = "A Survey on the Application of Genetic Programming to
              Classification",
  author   = "Espejo, P G and Ventura, S and Herrera, F",
  abstract = "Classification is one of the most researched questions in machine
              learning and data mining. A wide range of real problems have been
              stated as classification problems, for example credit scoring,
              bankruptcy prediction, medical diagnosis, pattern recognition,
              text categorization, software quality assessment, and many more.
              The use of evolutionary algorithms for training classifiers has
              been studied in the past few decades. Genetic programming (GP) is
              a flexible and powerful evolutionary technique with some features
              that can be very valuable and suitable for the evolution of
              classifiers. This paper surveys existing literature about the
              application of genetic programming to classification, to show the
              different ways in which this evolutionary algorithm can help in
              the construction of accurate and reliable classifiers.",
  journal  = "IEEE Trans. Syst. Man Cybern. C Appl. Rev.",
  volume   =  40,
  number   =  2,
  pages    = "121--144",
  month    =  mar,
  year     =  2010,
  keywords = "Genetic programming;Unsupervised learning;Supervised
              learning;Machine learning;Data mining;Evolutionary
              computation;Decision trees;Classification tree analysis;Computer
              science;Medical diagnosis;Classification;decision trees;ensemble
              classifiers;feature construction;feature selection;genetic
              programming (GP);rule-based systems;EA",
  issn     = "1094-6977, 1558-2442",
  doi      = "10.1109/TSMCC.2009.2033566"
}

@BOOK{Miller2011-ko,
  title     = "Cartesian Genetic Programming",
  editor    = "Miller, Julian F",
  publisher = "Springer, Berlin, Heidelberg",
  year      =  2011,
  keywords  = "EA",
  doi       = "10.1007/978-3-642-17310-3"
}

@ARTICLE{Guidotti2018-vd,
  title         = "A Survey Of Methods For Explaining Black Box Models",
  author        = "Guidotti, Riccardo and Monreale, Anna and Ruggieri,
                   Salvatore and Turini, Franco and Pedreschi, Dino and
                   Giannotti, Fosca",
  abstract      = "In the last years many accurate decision support systems
                   have been constructed as black boxes, that is as systems
                   that hide their internal logic to the user. This lack of
                   explanation constitutes both a practical and an ethical
                   issue. The literature reports many approaches aimed at
                   overcoming this crucial weakness sometimes at the cost of
                   scarifying accuracy for interpretability. The applications
                   in which black box decision systems can be used are various,
                   and each approach is typically developed to provide a
                   solution for a specific problem and, as a consequence,
                   delineating explicitly or implicitly its own definition of
                   interpretability and explanation. The aim of this paper is
                   to provide a classification of the main problems addressed
                   in the literature with respect to the notion of explanation
                   and the type of black box system. Given a problem
                   definition, a black box type, and a desired explanation this
                   survey should help the researcher to find the proposals more
                   useful for his own work. The proposed classification of
                   approaches to open black box models should also be useful
                   for putting the many research open questions in perspective.",
  month         =  "6~" # feb,
  year          =  2018,
  keywords      = "Explainable AI",
  archivePrefix = "arXiv",
  eprint        = "1802.01933",
  primaryClass  = "cs.CY",
  arxivid       = "1802.01933"
}

@ARTICLE{Roscher2019-pt,
  title         = "Explainable Machine Learning for Scientific Insights and
                   Discoveries",
  author        = "Roscher, Ribana and Bohn, Bastian and Duarte, Marco F and
                   Garcke, Jochen",
  abstract      = "Machine learning methods have been remarkably successful for
                   a wide range of application areas in the extraction of
                   essential information from data. An exciting and relatively
                   recent development is the uptake of machine learning in the
                   natural sciences, where the major goal is to obtain novel
                   scientific insights and discoveries from observational or
                   simulated data. A prerequisite for obtaining a scientific
                   outcome is domain knowledge, which is needed to gain
                   explainability, but also to enhance scientific consistency.
                   In this article we review explainable machine learning in
                   view of applications in the natural sciences and discuss
                   three core elements which we identified as relevant in this
                   context: transparency, interpretability, and explainability.
                   With respect to these core elements, we provide a survey of
                   recent scientific works that incorporate machine learning
                   and the way that explainable machine learning is used in
                   combination with domain knowledge from the application
                   areas.",
  month         =  "21~" # may,
  year          =  2019,
  keywords      = "Explainable AI",
  archivePrefix = "arXiv",
  eprint        = "1905.08883",
  primaryClass  = "cs.LG",
  arxivid       = "1905.08883"
}

@ARTICLE{Montavon2018-mq,
  title    = "Methods for interpreting and understanding deep neural networks",
  author   = "Montavon, Gr{\'e}goire and Samek, Wojciech and M{\"u}ller,
              Klaus-Robert",
  abstract = "This paper provides an entry point to the problem of interpreting
              a deep neural network model and explaining its predictions. It is
              based on a tutorial given at ICASSP 2017. As a tutorial paper,
              the set of methods covered here is not exhaustive, but
              sufficiently representative to discuss a number of questions in
              interpretability, technical challenges, and possible
              applications. The second part of the tutorial focuses on the
              recently proposed layer-wise relevance propagation (LRP)
              technique, for which we provide theory, recommendations, and
              tricks, to make most efficient use of it on real data.",
  journal  = "Digit. Signal Process.",
  volume   =  73,
  pages    = "1--15",
  month    =  "1~" # feb,
  year     =  2018,
  keywords = "Deep neural networks; Activation maximization; Sensitivity
              analysis; Taylor decomposition; Layer-wise relevance
              propagation;Explainable AI",
  issn     = "1051-2004",
  doi      = "10.1016/j.dsp.2017.10.011"
}

@ARTICLE{Leavitt2020-zl,
  title         = "Towards falsifiable interpretability research",
  author        = "Leavitt, Matthew L and Morcos, Ari",
  abstract      = "Methods for understanding the decisions of and mechanisms
                   underlying deep neural networks (DNNs) typically rely on
                   building intuition by emphasizing sensory or semantic
                   features of individual examples. For instance, methods aim
                   to visualize the components of an input which are
                   ``important'' to a network's decision, or to measure the
                   semantic properties of single neurons. Here, we argue that
                   interpretability research suffers from an over-reliance on
                   intuition-based approaches that risk-and in some cases have
                   caused-illusory progress and misleading conclusions. We
                   identify a set of limitations that we argue impede
                   meaningful progress in interpretability research, and
                   examine two popular classes of interpretability
                   methods-saliency and single-neuron-based approaches-that
                   serve as case studies for how overreliance on intuition and
                   lack of falsifiability can undermine interpretability
                   research. To address these concerns, we propose a strategy
                   to address these impediments in the form of a framework for
                   strongly falsifiable interpretability research. We encourage
                   researchers to use their intuitions as a starting point to
                   develop and test clear, falsifiable hypotheses, and hope
                   that our framework yields robust, evidence-based
                   interpretability methods that generate meaningful advances
                   in our understanding of DNNs.",
  month         =  "22~" # oct,
  year          =  2020,
  keywords      = "Explainable AI",
  archivePrefix = "arXiv",
  eprint        = "2010.12016",
  primaryClass  = "cs.CY",
  arxivid       = "2010.12016",
  doi           = "10.1007/s13244-018-0639-9"
}

@MISC{noauthor_undated-gi,
  title = "processing\_info\_structure.pdf"
}

@ARTICLE{Brameier2001-sz,
  title     = "A comparison of linear genetic programming and neural networks
               in medical data mining",
  author    = "Brameier, M and Banzhaf, W",
  journal   = "IEEE Trans. Evol. Comput.",
  publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
  volume    =  5,
  number    =  1,
  pages     = "17--26",
  year      =  2001,
  keywords  = "EA",
  issn      = "1089-778X, 1941-0026",
  doi       = "10.1109/4235.910462"
}

@BOOK{dummy_key,
  title     = "The Amazing Journey of Reason: from {DNA} to Artificial
               Intelligence",
  author    = "Alemi, Mario",
  abstract  = "The Amazing Journey analyzes the latest results in chemistry,
               biology, neuroscience, anthropology and sociology under the
               light of the evolution of intelligence, seen as the ability of
               processing information.",
  publisher = "Springer International Publishing",
  series    = "SpringerBriefs in Computer Science",
  year      =  2020,
  address   = "Cham, Switzerland",
  keywords  = "Read;Misc",
  isbn      = "9783030259617",
  doi       = "10.1007/978-3-030-25962-4"
}

@ARTICLE{dummy_key,
  title    = "Ten simple rules for writing research papers",
  author   = "Zhang, Weixiong",
  abstract = "The importance of writing well can never be overstated for a
              successful professional career, and the ability to write solid
              papers is an essential trait of a productive researcher. Writing
              and publishing a paper has its own life cycle; properly following
              a course of action and avoiding missteps can be vital to the
              overall success not only of a paper but of the underlying
              research as well. Here, we offer ten simple rules for writing and
              publishing research papers.",
  journal  = "PLoS Comput. Biol.",
  volume   =  10,
  number   =  1,
  pages    = "e1003453",
  month    =  jan,
  year     =  2014,
  keywords = "Relevant;Methods",
  language = "en",
  issn     = "1553-734X, 1553-7358",
  pmid     = "24499936",
  doi      = "10.1371/journal.pcbi.1003453",
  pmc      = "PMC3907284"
}

@INCOLLECTION{dummy_key,
  title     = "The Core Concept of Statistics",
  booktitle = "Understanding Statistics and Experimental Design: How not to lie
               with statistics",
  author    = "Herzog, Michael and Francis, Gregory and Clarke, Aaron",
  publisher = "Springer International Publishing",
  pages     = "23--50",
  year      =  2019,
  address   = "Cham, Switzerland",
  keywords  = "Statistics;Methods",
  isbn      = "9783030034993"
}
